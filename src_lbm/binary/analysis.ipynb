{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import fft\n",
    "\n",
    "import scipy\n",
    "from scipy.optimize import newton, curve_fit\n",
    "from scipy.ndimage import center_of_mass\n",
    "from skimage import filters, measure, draw, morphology\n",
    "\n",
    "from numba import njit\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import yt\n",
    "\n",
    "figures = \"figures/\"\n",
    "figheight = 4\n",
    "os.makedirs(figures, exist_ok = True)\n",
    "DPI = 300\n",
    "\n",
    "import imageio.v3 as iio\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to characterize the data obtained to validate the implementation of thermodynamically consistent fluctuations within a multicomponent lattice boltzmann method based on a free energy formulation. The implementation is written in C++ based on AMReX. The free energy formulation is built using the free energy model proposed in [Swift et al. 1996](https://journals.aps.org/pre/pdf/10.1103/PhysRevE.54.5041) which utilizes a square gradient free energy functional and a bulk free energy defined as two ideal fluids interacting with each other. The modified equilibrium distribution proposed in Swift et al. is utilized.\n",
    "\n",
    "We follow the procedure to develop a formalism fo the fluctuations using the process detailed in [Gross et al. 2010](https://journals.aps.org/pre/pdf/10.1103/PhysRevE.82.056714). They propose spatial correlations of the noise in k space, resulting in a better match to theory especially at higher k values. They state an ansatz which specifies the form of the structure factor of the noise, allowing for the calculation of a covariance matrix that is dependent upon the thermodynamic model utilized. \n",
    "\n",
    "To validate the implementation, the equilibration ratios of the density, order parameter and velocity are calculated for a mixed system of equal volume fractions of each fluid. Next, the interfacial fluctuations are calculated using Eqaution 3.11 in calculated by [Grant and Desai 1983](https://journals.aps.org/pra/pdf/10.1103/PhysRevA.27.2577). Finally, the surface tension calculated from the fluctuations of the shape of a droplet will be compared to that calculated using the Young-Laplace equation as defined in [Benayad et al. 2020](https://doi.org/10.1021/acs.jctc.0c01064)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_data`\n",
    "\n",
    "AMReX can output datafiles with type `h5`. There are 38 fields of data representing the 19 moments of each distribution equation used to describe the hydrodynamics and non-ideal mixing. The ordering of these moments are, $\\rho, \\phi, v_x, v_y, v_z, \\phi v_x, \\phi v_y, \\phi v_z, mf4 ... mf18, mg4 ... mg18$\n",
    "\n",
    "**Input**\n",
    "1. `h5_filepath`: `str` where the `.h5` file as output from AMReX is located\n",
    "2. `dims`: Dimensions of the simulation box input as a `list` or `np.array`\n",
    "3. `begin`: `int` defining the index upon which to start reading the moment fields. \n",
    "4. `end`: `int` defining the index upon which to end reading the moment fields (non inclusive).\n",
    "5. `nVars`: `int` defining the number of data fields that the output file contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(h5_filepath, dims, begin = 0, end = 1, nVars = 38):\n",
    "    if type(dims) == list:\n",
    "        dims = np.array(dims)\n",
    "\n",
    "    with h5py.File(h5_filepath,'r') as h5f:\n",
    "        keys = list(h5f.keys())\n",
    "        test = h5f[keys[-1]]\n",
    "        keys = list(test.keys())\n",
    "        \n",
    "        # boxDims = test[keys[1]][()]\n",
    "        # # print(boxDims)\n",
    "        domain_decomp = test[keys[1]][()]\n",
    "        data = test[keys[2]][()]\n",
    "    \n",
    "    output = np.zeros((end - begin, *dims))\n",
    "    decomp_box_size = [int(domain_decomp[0][5]-domain_decomp[0][2]+1),\n",
    "                       int(domain_decomp[0][4]-domain_decomp[0][1]+1),\n",
    "                       int(domain_decomp[0][3]-domain_decomp[0][0]+1)]\n",
    "    sz = 1\n",
    "    for i in decomp_box_size: sz *= i\n",
    "    revdims = np.flip(dims)\n",
    "\n",
    "    for i in range(begin, end):\n",
    "        currVar = np.zeros(revdims)\n",
    "        for j in range(0, len(domain_decomp)):\n",
    "            curr_decomp = domain_decomp[j]\n",
    "            slc = np.s_[curr_decomp[2]:curr_decomp[5]+1, curr_decomp[1]:curr_decomp[4]+1, curr_decomp[0]:curr_decomp[3]+1]\n",
    "            currVar[slc] = data[(i + j*nVars)*sz:(i+1 + j*nVars)*sz].reshape(*decomp_box_size)\n",
    "    \n",
    "        output[i - begin] = np.moveaxis(currVar, [0, -1], [-1, 0])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBM and thermodynamic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lattice_fourier_laplacian`\n",
    "\n",
    "This function defines the laplacian operator as it appears in k space, defined as the fourier transform of the expression $\\sum_{i \\neq 0} [\\rho(r + c_i) + \\rho(r - c_i) - 2\\rho(r)]/c_s^2$ where $c_s^2$ represents the speed of sound of the lattice kernel used. In practice, this expression becomes, $\\frac{\\frac{2}{9}[\\cos{kx} + \\cos{ky} + \\cos{kz}] + \\frac{2}{9}[\\cos{kx}\\cos{ky} + \\cos{ky}\\cos{kz} + \\cos{kx}\\cos{kz}] - \\frac{4}{3}}{c_s^2}$. To be used as a substitute for any term that contains $\\nabla^2$ in real space.\n",
    "\n",
    "**Input**\n",
    "1. `kx`: Wave vector in the x direction. Can be passed as a `float` or `np.array`\n",
    "1. `ky`: Wave vector in the y direction. Can be passed as a `float` or `np.array`\n",
    "1. `kz`: Wave vector in the z direction. Can be passed as a `float` or `np.array`\n",
    "\n",
    "**Output**\n",
    "1. `k2`: Lattice laplacian value in k space. Output as `float` or `np.array` depending on input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lattice_fourier_laplacian(kx, ky, kz):\n",
    "    expr1 = np.cos(kx) + np.cos(ky) + np.cos(kz)\n",
    "    expr2 = np.cos(kx)*np.cos(ky) + np.cos(ky)*np.cos(kz) + np.cos(kx)*np.cos(kz)\n",
    "    out = 2/9*expr1 + 2/9*expr2 - 4/3\n",
    "    cs2 = 1/3\n",
    "    k2 = -out/cs2\n",
    "    return k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `swift_et_al_1996_thermodynamic_model`\n",
    "\n",
    "Defines the thermodynamic parameters of the swift et al. thermodynamic model as defined in [Swift et al. 1996](https://journals.aps.org/pre/pdf/10.1103/PhysRevE.54.5041).\n",
    "\n",
    "**Input**\n",
    "1. `density`: `float` representing the density of the system\n",
    "2. `C0`: `float` representing the order parameter value\n",
    "3. `chi`: `float` a value corresponding to the width of the double well\n",
    "4. `T`: `float` representing the depth of the double well\n",
    "5. `kappa`: `float` representing the strength of non ideal mixing\n",
    "\n",
    "**Output**\n",
    "1. `model class` with various operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swift_et_al_1996_thermodynamic_model:\n",
    "    def __init__(self, density = 1, C0 = 0, chi = 0.4, T = 0.25, kappa = 0.01):\n",
    "        self.chi = chi\n",
    "        self.T = T\n",
    "        self.kappa = kappa\n",
    "        self.rho = density\n",
    "        self.C0 = C0\n",
    "\n",
    "    def sound_speed_square(self):\n",
    "        out = self.T\n",
    "        return out\n",
    "\n",
    "    def cs2k(self, kx = 0, ky = 0, kz = 0):\n",
    "        thermal_cs2 = self.sound_speed_square()\n",
    "        k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "        out = thermal_cs2 + k2*self.kappa\n",
    "        return out\n",
    "    \n",
    "    def calculate_df_dphi(self):\n",
    "        rho = self.rho\n",
    "        phi = self.C0\n",
    "        chi = self.chi\n",
    "        T   = self.T\n",
    "        out = -chi/2.*(phi/rho) + T/2.*np.log((1. + phi/rho)/(1. - phi/rho))\n",
    "        return out\n",
    "\n",
    "    def calculate_dmup_drho(self):\n",
    "        rho = self.rho\n",
    "        phi = self.C0\n",
    "        chi = self.chi\n",
    "        T   = self.T\n",
    "        out = -T*phi/(rho**2 - phi**2) + chi/2*phi/(rho**2)\n",
    "        return out\n",
    "\n",
    "    def calculate_dmup_dphi(self):\n",
    "        rho = self.rho\n",
    "        phi = self.C0\n",
    "        chi = self.chi\n",
    "        T   = self.T\n",
    "        out = T*rho/(rho**2 - phi**2) - chi/(2*rho)\n",
    "        return out\n",
    "    \n",
    "    def mu_ck(self, kx = 0, ky = 0, kz = 0):\n",
    "        ref_state = self.calculate_dmup_dphi()\n",
    "        k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "        out = ref_state + k2*self.kappa\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `interface_height`\n",
    "\n",
    "To calculate the interface height, three methods are defined in separate functions. These detail three ways to calculate the interface height fluctuations. The first, termed `direct` fits the point before and after the location of the interface to a linear expression, followed by identifying the root of the linear expression. The final variant termed `profile-fit`, fits the profile of the order parameter to a profile, $\\phi = \\phi_0\\tanh{\\frac{x - b}{\\sqrt{2} \\xi}}$ profile and uses the fit parameter for $b$. `interface_height` wraps these 3 implementations into a single function so as to make using each implementation easier.\n",
    "\n",
    "**Input**\n",
    "\n",
    "1. `density`: `1D np.array` of the order parameter at each slice of the 3D array\n",
    "2. `chi`: `float` a value corresponding to the width of the double well\n",
    "3. `T`: `float` representing the depth of the double well\n",
    "4. `kappa`: `float` representing the strength of non ideal mixing\n",
    "5. `method`: `str` of which method to use to calculate the interface height. Throws a valueError if invalid method is input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb(phi, l, T, rho = 1):\n",
    "    model = swift_et_al_1996_thermodynamic_model(rho, phi, l, T, kappa = 0)\n",
    "    out = model.calculate_df_dphi()\n",
    "    return out\n",
    "\n",
    "def ih_direct(profile):\n",
    "    nx, ny, nz = profile.shape\n",
    "    out = np.zeros((ny, nz))\n",
    "    for y in range(ny):\n",
    "        out[y] = measure.find_contours(profile[:, y, :])[0][:, 0]\n",
    "    return out\n",
    "\n",
    "def ih_profile_fit(profile, chi, T, kappa):\n",
    "    nx, ny, nz = profile.shape\n",
    "    out = np.zeros((ny, nz))\n",
    "    phi0 = np.sqrt(3*(chi/2 - T)/(chi/2))\n",
    "    phi0 = newton(fb, x0 = (phi0), args = (chi, T))\n",
    "    fit_func = lambda x, b, xi:phi0*np.tanh((x - b)/(np.sqrt(2)*xi))\n",
    "\n",
    "    xraw = np.arange(0, nx, 1)\n",
    "\n",
    "    for y in range(ny):\n",
    "        for z in range(nz):\n",
    "            slc = profile[:, y, z]\n",
    "            popt, pcov = curve_fit(fit_func, xraw, slc, p0 = [nx//2, 1])\n",
    "            # print(popt[1])\n",
    "            out[y, z] = popt[0]\n",
    "    return out\n",
    "\n",
    "def interface_height(density, chi, T, kappa, method = \"direct\", zero = False):\n",
    "    nx, ny, nz = density.shape\n",
    "    height_func = np.zeros((ny, nz))\n",
    "\n",
    "    yraw = density.copy()\n",
    "    zero_factor = (nx - 1)/2\n",
    "\n",
    "    if method == 'direct':\n",
    "        height_func = ih_direct(yraw)\n",
    "    elif method == \"profile_fit\":\n",
    "        height_func = ih_profile_fit(yraw, chi, T, kappa)\n",
    "    else:\n",
    "        raise ValueError(f'{method} is invalid to calculate interface height')\n",
    "    \n",
    "    height_func = height_func - zero_factor if zero else height_func\n",
    "    \n",
    "    return height_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spherically_averaged_structure_factor`\n",
    "\n",
    "**Input**\n",
    "1. `data`: `np.array` containing the structure factor data for for a moment\n",
    "2. `thermo_model`: `thermodynamics class` for calculation of various parameters directly relevant to the thermodynamic model to be utilized\n",
    "3. `scale_factor`: `float` or `np.array` that the data is divided by\n",
    "4. `func`: `lambda function` that defines some further operations to scale data. Used for spatial correlations\n",
    "5. `shift`: `bool` whether to shift the zero point of the frequencies calculated by `np.fft.fftfreq` to the same order as numpy arrays or as the output of fftw\n",
    "6. `cs`: `bool` whether to use the speed of sound or chemical potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spherically_averaged_structure_factor(data, thermo_model, scale_factor = 1, func = None, shift = True, cs = True):\n",
    "    L = min(data.shape)\n",
    "    S = data.copy()\n",
    "\n",
    "    if shift:\n",
    "        freqs = fft.fftshift(fft.fftfreq(L))\n",
    "    else:\n",
    "        freqs = fft.fftfreq(L)\n",
    "    if len(data.shape) == 3:\n",
    "        kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "        k = np.stack([kx, ky, kz], axis = -1)\n",
    "    elif len(data.shape) == 2:\n",
    "        kx, ky = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L]]), indexing='ij')\n",
    "        k = np.stack([kx, ky], axis = -1)\n",
    "     \n",
    "    k1 = np.linalg.norm(k, axis=-1).flatten()\n",
    "    \n",
    "    if func is not None:\n",
    "        if cs:\n",
    "            S = func(S, thermo_model.cs2k(kx, ky, kz))\n",
    "        else:\n",
    "            S = func(S, thermo_model.mu_ck(kx, ky, kz))\n",
    "    S /= scale_factor\n",
    "\n",
    "    # test[slc] /= test.sum()\n",
    "    # S[L//2, L//2, L//2] /= S.sum()\n",
    "\n",
    "    S1 = S.flatten()\n",
    "    kmin = 2*np.pi/L # sampling frequency\n",
    "    where = np.s_[:]#np.where(k1<=kmax)\n",
    "    bins = np.arange(L//2+1)*kmin # kmax+1 for bin_edges: len(bins)=len(hist)+1\n",
    "    \n",
    "    shells = np.histogram(k1[where], bins, weights=S1[where])[0]\n",
    "    counts = np.histogram(k1[where], bins)[0]\n",
    "    return (bins[:-1]+bins[1:])/2, shells/counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `radial_equilibration`\n",
    "\n",
    "**Input**\n",
    "1. `data`: `np.array` containing the structure factor data for for a moment\n",
    "2. `thermo_model`: `thermodynamics class` for calculation of various parameters directly relevant to the thermodynamic model to be utilized\n",
    "3. `scale_factor`: `float` or `np.array` that the data is divided by\n",
    "4. `func`: `lambda function` that defines some further operations to scale data. Used for spatial correlations\n",
    "5. `shift`: `bool` whether to shift the zero point of the frequencies calculated by `np.fft.fftfreq` to the same order as numpy arrays or as the output of fftw\n",
    "6. `cs`: `bool` whether to use the speed of sound or chemical potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2sph(x,y,z):\n",
    "    azimuth = np.arctan2(y,x)\n",
    "    elevation = np.arctan2(z,np.sqrt(x**2 + y**2))\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    return r, azimuth, elevation\n",
    "\n",
    "def sph2cart(azimuth,elevation,r):\n",
    "    x = r * np.cos(elevation) * np.cos(azimuth)\n",
    "    y = r * np.cos(elevation) * np.sin(azimuth)\n",
    "    z = r * np.sin(elevation)\n",
    "    return x, y, z\n",
    "\n",
    "def radial_equilibration(data, thermo_model, radius = 1, scale_factor = 1, func = None, cs = True):\n",
    "    S = data.copy()\n",
    "    L = min(S.shape)\n",
    "    freqs = fft.fftshift(fft.fftfreq(L))\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "\n",
    "    r, t, p = cart2sph(kx, ky, kz)\n",
    "\n",
    "    if func is not None:\n",
    "        if cs:\n",
    "            S = func(S, thermo_model.cs2k(kx, ky, kz))\n",
    "        else:\n",
    "            S = func(S, thermo_model.mu_ck(kx, ky, kz))\n",
    "    S /= scale_factor\n",
    "    # S[L//2, L//2, L//2] /= S.sum()\n",
    "    \n",
    "    idxs = np.isclose(r, radius, atol = 2*np.pi/L)\n",
    "    t = t[idxs]\n",
    "    p = p[idxs]\n",
    "    out = S[idxs]\n",
    "\n",
    "    return t, p, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `make_bins`\n",
    "\n",
    "**Input**\n",
    "1. `to_bin1`: `np.array` containing data of a list to be binned\n",
    "2. `binsize`: `int` defining how many size of the output array. `len(to_bin1)/binsize` is the number of points averaged over to generate the output\n",
    "3. `to_bin2`: `np.array` containing a 2nd list to be be binned (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bins(to_bin1, binsize, to_bin2 = None):\n",
    "    bins = np.linspace(to_bin1.min(), to_bin1.max(), binsize)\n",
    "\n",
    "    out1 = np.zeros(binsize)\n",
    "    shell = np.digitize(to_bin1, bins = bins, right = True)\n",
    "    np.add.at(out1, shell, to_bin1)\n",
    "    unique, counts = np.unique(shell, return_counts=True)\n",
    "    out1 = out1[unique]\n",
    "    out1 /= counts\n",
    "\n",
    "    if to_bin2 is None:\n",
    "        return bins, out1\n",
    "    else:\n",
    "        out2 = np.zeros(binsize)\n",
    "        np.add.at(out2, shell, to_bin2)\n",
    "        unique, counts = np.unique(shell, return_counts=True)\n",
    "        out2 = out2[unique]\n",
    "        out2 /= counts\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pressure_tensor`\n",
    "\n",
    "**Input**\n",
    "1. `profile`: `np.array` of shape (nx, ny, nz, 2) containing density and order parameter data in the 0th and 1st index of the last dimension respectively\n",
    "2. `T`: `float` defining a thermodynamic parameter\n",
    "3. `kappa`: `float` defining a thermodynamic parameter related to surface tension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pressure_tensor(profile, T, kappa):\n",
    "    rho = profile[0]\n",
    "    phi = profile[1]\n",
    "    dims = len(rho.shape)\n",
    "\n",
    "    out = np.zeros((*rho.shape, dims, dims))\n",
    "\n",
    "    for i in range(dims):\n",
    "        for j in range(dims):\n",
    "            out[..., i, j] += kappa*np.gradient(rho, axis = i)*np.gradient(rho, axis = j) + kappa*np.gradient(phi, axis = i)*np.gradient(phi, axis = j)\n",
    "            if i == j:\n",
    "\n",
    "                laplacian = rho*np.sum([np.gradient(rho, 2, axis = ax) for ax in range(dims)], axis = 0) + phi*np.sum([np.gradient(phi, 2, axis = ax) for ax in range(dims)], axis = 0)\n",
    "                gradients = np.sum([np.gradient(rho, 1, axis = ax)**2 for ax in range(dims)], axis = 0) + np.sum([np.gradient(phi, 1, axis = ax)**2 for ax in range(dims)], axis = 0)\n",
    "                out[..., i, j] += rho*T - kappa*laplacian - kappa/2*gradients\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pressure_jump`\n",
    "\n",
    "**Input**\n",
    "1. `pressure`: `np.ndarray` of shape `[nx, ny, nz]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pressure_jump(pressure):\n",
    "    nx, ny, nz = pressure.shape\n",
    "    center_slc = np.s_[nx//2-1:nx//2+2, ny//2-1:ny//2+2, nz//2-1:nz//2+2]\n",
    "    edge_slc = np.s_[0:nx:nx-1, 0:ny:ny-1, 0:nz:nz-1]\n",
    "    dP = pressure[center_slc].mean() - pressure[edge_slc].mean()\n",
    "    return dP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `droplet_mass`\n",
    "\n",
    "**Input**\n",
    "1. `OutArray`: `np.ndarray` of shape `[nx, ny, nz]`\n",
    "\n",
    "**Output**\n",
    "1. `sum`: `float` representing the droplet mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_mass(OutArray):\n",
    "    sum = np.sum(OutArray)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `droplet_radius_mass`\n",
    "\n",
    "**Input**\n",
    "1. `density`: `np.ndarray` of shape `[nx, ny, nz]` which holds order parameter data of the droplet\n",
    "2. `Vp`: `float` of particle volume if particles are used\n",
    "3. `np_sphere`: `float` of number of particles if particles are used\n",
    "4. `rho_sphere`: `float` of particle density if particles are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_radius_mass(density, Vp = 0, np_sphere = 0, rho_sphere = 1):\n",
    "    nx, ny, nz = density.shape\n",
    "    center_slc = np.s_[nx//2-1:nx//2+2, ny//2-1:ny//2+2, nz//2-1:nz//2+2]\n",
    "    edge_slc = np.s_[0:nx:nx-1, 0:ny:ny-1, 0:nz:nz-1]\n",
    "    if isinstance(density, int):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # center = tuple([ l//2 for l in density.shape ])\n",
    "        rho_d = density[center_slc].mean()\n",
    "        rho_m = density[edge_slc].mean()\n",
    "        # mass = np.sum(density - rho_m) + 0.5*Vp*np_sphere*rho_sphere\n",
    "        mass = droplet_mass(density - rho_m) + 0.5*Vp*np_sphere*rho_sphere\n",
    "        R = (3./4./np.pi*mass/(rho_d-rho_m))**(1./3.)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `droplet_radius_iso`\n",
    "\n",
    "**Input**\n",
    "1. `density`: `np.ndarray` of shape `[nx, ny, nz]` which holds order parameter data of the droplet\n",
    "2. `level`: `float` of isocontour to calculate radius from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_radius_iso(density, level = None):\n",
    "    if level is None:\n",
    "        level = filters.threshold_otsu(density)\n",
    "    verts, faces, normals, values = measure.marching_cubes(density, level = level)\n",
    "    cm = center_of_mass(density)\n",
    "    ri_s = np.linalg.norm(verts - cm, axis = 1)\n",
    "    R = np.mean(ri_s)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `inertia_tensor`\n",
    "\n",
    "**Input**\n",
    "1. `cm`: `np.ndarray` of size `3` which defines the center of mass of the droplet\n",
    "2. `OutArray`: `np.ndarray` of order parameter data that has been pre-processed such that all other points are 0 except anything defining the droplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inertia_tensor(cm,OutArray):\n",
    "    ind = np.transpose(np.indices(OutArray.shape), axes=(1,2,3,0))\n",
    "    pos = ind - cm\n",
    "    r2 = np.einsum('ijkl,ijkl->ijk',pos,pos)          # inner product\n",
    "    rr = np.einsum('ijkm,ijkn->ijkmn',pos,pos)        # outer product\n",
    "    r2 = np.einsum('ijk,mn->ijkmn',r2,np.identity(3)) # multiply with unit matrix\n",
    "    I = np.einsum('ijk,ijkmn->mn',OutArray,r2-rr)     # sum m*(r2-rr)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `radii_pca`\n",
    "\n",
    "**Input**\n",
    "1. `eigvals`: `np.ndarray` of size `3` which defines the eigenvalues of the intertia tensor\n",
    "2. `mass`: `float` describing the droplet mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radii_pca(eigvals, mass):\n",
    "    a = np.sqrt((5/(2*mass))*(eigvals[1]+eigvals[2]-eigvals[0]))\n",
    "    b = np.sqrt((5/(2*mass))*(eigvals[0]+eigvals[2]-eigvals[1]))\n",
    "    c = np.sqrt((5/(2*mass))*(eigvals[0]+eigvals[1]-eigvals[2]))\n",
    "\n",
    "    return np.array([a, b, c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `gyration_tensor`\n",
    "\n",
    "**Input**\n",
    "1. `cm`: `np.ndarray` of size `3` which defines the center of mass of the droplet\n",
    "2. `OutArray`: `np.ndarray` of order parameter data that has been pre-processed such that all other points are 0 except anything defining the droplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gyration_tensor(cm,OutArray):\n",
    "    ind = np.transpose(np.indices(OutArray.shape), axes=(1,2,3,0))\n",
    "    pos = ind - cm\n",
    "    rr = np.einsum('...m,...n->...mn',pos,pos)\n",
    "    S = np.einsum('ijk,ijk...',OutArray,rr)/np.sum(OutArray)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `droplet_fluctuations`\n",
    "\n",
    "(fluctuations, temp = 1e-7)\n",
    "\n",
    "**Input**\n",
    "1. `fluctuations`: `np.ndarray` of size `[data_size, 3]` which defines the fluctuations of the principle radii of the droplet\n",
    "2. `temp`: `float` of the temperature used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_fluctuations(fluctuations, temp = 1e-7):\n",
    "    sums = 0\n",
    "    difs = 0\n",
    "\n",
    "    for i in range(0, 2):\n",
    "        for j in range(i+1, 3):\n",
    "            sums += np.mean(np.power(fluctuations[:, i] + fluctuations[:, j], 2))\n",
    "            difs += np.mean(np.power(fluctuations[:, i] - fluctuations[:, j], 2))\n",
    "\n",
    "    sums *= 1/3\n",
    "    difs *= 1/3\n",
    "\n",
    "    y20 = 5*temp/(16*np.pi*sums)\n",
    "    y22 = 15*temp/(16*np.pi*difs)\n",
    "\n",
    "    return [y20, y22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneous system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 64\n",
    "boxDims = [L, L, L]\n",
    "use_hdf5 = False\n",
    "\n",
    "chi = 0.4\n",
    "T = 0.25\n",
    "kappa = 0.01\n",
    "kbt = 1e-7\n",
    "\n",
    "rho0 = 1.0\n",
    "phi0 = 0.0\n",
    "thermo_vars = swift_et_al_1996_thermodynamic_model(rho0, phi0, chi, T, kappa)\n",
    "\n",
    "# noise_type = \"spatially_independent\"\n",
    "noise_type = \"spatially_dependent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "# save_dir = \"./\"\n",
    "binsize_avg = 16\n",
    "binsize_radial = 16\n",
    "\n",
    "freqs = fft.fftshift(fft.fftfreq(L))\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if use_hdf5:\n",
    "#     paths = sorted(glob.glob(f\"{save_dir}/hydro*.h5\"))[1:]\n",
    "\n",
    "#     S_rho = np.zeros(([L]*3), dtype = complex)\n",
    "#     S_phi = np.zeros([L]*3, dtype = complex)\n",
    "#     S_v = np.zeros((*[L]*3,3,3), dtype = complex)\n",
    "\n",
    "#     for i, h5_filepath in enumerate(paths):\n",
    "#         conserved_moments = extract_data(h5_filepath, boxDims, begin = 0, end = 5, nVars = 38)\n",
    "\n",
    "#         var = conserved_moments[0]\n",
    "#         vark = fft.fftn(var)\n",
    "#         S_rho += vark*np.conj(vark)\n",
    "\n",
    "#         var = conserved_moments[1]\n",
    "#         vark = fft.fftn(var)\n",
    "#         S_phi += vark*np.conj(vark)\n",
    "\n",
    "#         var = conserved_moments[2:]\n",
    "#         vark = fft.fftn(var, axes = [1, 2, 3])\n",
    "#         S_v += np.einsum('i..., j...->...ij',vark, np.conj(vark))\n",
    "\n",
    "\n",
    "#     S_rho /= (len(paths)*L**3*kbt)\n",
    "#     S_phi /= (len(paths)*L**3*kbt)\n",
    "#     S_v /= (len(paths)*L**3*kbt)\n",
    "\n",
    "#     data_rho = [S_rho.real]\n",
    "#     data_phi = [S_phi.real]\n",
    "#     data_v = [S_v[..., 0, 0].real, S_v[..., 1, 1].real, S_v[..., 2, 2].real]\n",
    "# else:\n",
    "#     ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "#     ds = ts[-1]\n",
    "#     ad = ds.all_data()\n",
    "\n",
    "#     data_rho = [np.array(ad[('boxlib', 'struct_fact_density_density')]).reshape(boxDims)/kbt]\n",
    "#     data_phi = [np.array(ad[('boxlib', 'struct_fact_phi_phi')]).reshape(boxDims)/kbt]\n",
    "#     data_v = [np.array(ad[('boxlib', 'struct_fact_ux_ux')]).reshape(boxDims)/kbt, \n",
    "#               np.array(ad[('boxlib', 'struct_fact_uy_uy')]).reshape(boxDims)/kbt,\n",
    "#               np.array(ad[('boxlib', 'struct_fact_uz_uz')]).reshape(boxDims)/kbt]\n",
    "\n",
    "#     # ds.field_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_independent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_rho = [np.array(ad[('boxlib', 'struct_fact_density_density')]).reshape(boxDims)/kbt]\n",
    "\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_rho\n",
    "experiment_muck = thermo_vars.cs2k(kx, ky, kz)\n",
    "\n",
    "test = data[0].copy()\n",
    "# test /= kbt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "ax = axs[0]\n",
    "test *= (experiment_muck)\n",
    "# test[slc] /= test.sum()\n",
    "im = ax.imshow(test[L//2, :, :])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.imshow(test[:, L//2, :])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(test[:, :, L//2])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc = np.s_[L//2, L//2, L//2]\n",
    "\n",
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$\\rho$\"]\n",
    "\n",
    "rho_scale = lambda a, c: a*c\n",
    "scale_factor = 1\n",
    "\n",
    "for d in data:\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = 1, func = rho_scale)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[0], color = colors[0],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[0])\n",
    "\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim([0.93, 1.07])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/rho-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1.5, 2.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "\n",
    "# rho_scale = None\n",
    "# scale_factor = 1/cs2\n",
    "\n",
    "for d in data:\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        # t, p, sf = radial_equilibration(d, rho0, phi0, radius = r, func=rho_scale, scale_factor = scale_factor)\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r, func=rho_scale, scale_factor = scale_factor)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "    ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", va = \"bottom\", ha = 'right', fontsize = 14, rotation = 'horizontal')\n",
    "    ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig(f\"./{figures}/rho-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/rho-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_dependent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_rho = [np.array(ad[('boxlib', 'struct_fact_density_density')]).reshape(boxDims)/kbt]\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_rho\n",
    "experiment_muck = thermo_vars.cs2k(kx, ky, kz)\n",
    "\n",
    "test = data[0].copy()\n",
    "# test /= kbt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "ax = axs[0]\n",
    "test *= (experiment_muck)\n",
    "# test[slc] /= test.sum()\n",
    "im = ax.imshow(test[L//2, :, :])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.imshow(test[:, L//2, :])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(test[:, :, L//2])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc = np.s_[L//2, L//2, L//2]\n",
    "\n",
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$\\rho$\"]\n",
    "\n",
    "rho_scale = lambda a, c: a*c\n",
    "scale_factor = 1\n",
    "\n",
    "for d in data:\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = 1, func = rho_scale)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[0], color = colors[0],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[0])\n",
    "\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim([0.93, 1.07])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/rho-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1.5, 2.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "binsize_temp = 16\n",
    "\n",
    "# rho_scale = None\n",
    "# scale_factor = 1/cs2\n",
    "\n",
    "for d in data:\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        # t, p, sf = radial_equilibration(d, rho0, phi0, radius = r, func=rho_scale, scale_factor = scale_factor)\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r, func=rho_scale, scale_factor = scale_factor)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "    ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", va = \"bottom\", ha = 'right', fontsize = 14, rotation = 'horizontal')\n",
    "    ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig(f\"./{figures}/rho-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/rho-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_independent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_phi = [np.array(ad[('boxlib', 'struct_fact_phi_phi')]).reshape(boxDims)/kbt]\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_phi\n",
    "\n",
    "# freqs = fft.fftshift(fft.fftfreq(L))\n",
    "# kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "# k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "experiment_muck = thermo_vars.mu_ck(kx, ky, kz)\n",
    "\n",
    "test = data[0].copy()\n",
    "# test[slc] = (test.sum() - test[slc])/(L**3)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "ax = axs[0]\n",
    "# test[slc] = (test.sum() - test[slc])/32**3\n",
    "test *= (experiment_muck)\n",
    "# test /= kbt\n",
    "im = ax.imshow(test[L//2, :, :])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.imshow(test[:, L//2, :])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(test[:, :, L//2])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$\\phi$\"]\n",
    "\n",
    "rho_func = lambda a, c: a*c\n",
    "scale_factor = 1\n",
    "\n",
    "for d in data:\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = scale_factor, func = rho_func, cs = False)\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[0], color = colors[0],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[0])\n",
    "\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "# print(x, y)\n",
    "# ax.set_ylim([0.9, 1.1])\n",
    "ax.set_ylim([0.93, 1.07])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/phi-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1.5, 2.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "binsize_temp = 16\n",
    "\n",
    "# rho_scale = None\n",
    "# scale_factor = 1/cs2\n",
    "\n",
    "for d in data:\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r, func=rho_scale, scale_factor = scale_factor, cs = False)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "    ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", va = \"bottom\", ha = 'right', fontsize = 14, rotation = 'horizontal')\n",
    "    ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig(f\"./{figures}/phi-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/phi-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_dependent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_phi = [np.array(ad[('boxlib', 'struct_fact_phi_phi')]).reshape(boxDims)/kbt]\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_phi\n",
    "\n",
    "# freqs = fft.fftshift(fft.fftfreq(L))\n",
    "# kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "# k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "experiment_muck = thermo_vars.mu_ck(kx, ky, kz)\n",
    "\n",
    "test = data[0].copy()\n",
    "# test[slc] = (test.sum() - test[slc])/(L**3)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "ax = axs[0]\n",
    "# test[slc] = (test.sum() - test[slc])/32**3\n",
    "test *= (experiment_muck)\n",
    "# test /= kbt\n",
    "im = ax.imshow(test[L//2, :, :])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.imshow(test[:, L//2, :])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(test[:, :, L//2])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$\\phi$\"]\n",
    "\n",
    "rho_func = lambda a, c: a*c\n",
    "scale_factor = 1\n",
    "\n",
    "for d in data:\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = scale_factor, func = rho_func, cs = False)\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[0], color = colors[0],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[0])\n",
    "\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "# print(x, y)\n",
    "ax.set_ylim([0.93, 1.07])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/phi-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1.5, 2.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "\n",
    "# rho_scale = None\n",
    "# scale_factor = 1/cs2\n",
    "\n",
    "for d in data:\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r, func=rho_scale, scale_factor = scale_factor, cs = False)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "    ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", va = \"bottom\", ha = 'right', fontsize = 14, rotation = 'horizontal')\n",
    "    ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig(f\"./{figures}/phi-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/phi-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_independent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_v = [np.array(ad[('boxlib', 'struct_fact_ux_ux')]).reshape(boxDims)/kbt, \n",
    "          np.array(ad[('boxlib', 'struct_fact_uy_uy')]).reshape(boxDims)/kbt,\n",
    "          np.array(ad[('boxlib', 'struct_fact_uz_uz')]).reshape(boxDims)/kbt]\n",
    "\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_v\n",
    "slc_s = [np.s_[L//2, :, :], np.s_[:, L//2, :], np.s_[:, :, L//2]]\n",
    "labels = ['yz', 'xz', 'xy']\n",
    "fig, axs = plt.subplots(3, 3, figsize = (9, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    d = data[i].copy()\n",
    "    # d /= kbt\n",
    "    # d[slc] = (d.sum() - d[slc])/(L**3)\n",
    "    for j in range(3):\n",
    "        ax = axs[i, j]\n",
    "        im = ax.imshow(d[slc_s[j]], vmin = 0.8, vmax = 1.2)\n",
    "        plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "        ax.set_title(f\"$S_{{u_{chr(120+i)}u_{chr(120+i)}}}$ {labels[j]}\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "binsize = 8\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$u_x$\", r\"$u_y$\", r\"$u_z$\"]\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = 1)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[i], color = colors[i],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[i])\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | u_{\\alpha}(k) | ^2 \\rangle }{\\rho_{0}k_b T}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim([0.93, 1.07])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/vel-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "# fig1, tax = plt.subplots(1, 3, figsize = (sz*3, sz), subplot_kw={'projection': 'polar'})\n",
    "# fig2, pax = plt.subplots(1, 3, figsize = (sz*3, sz), subplot_kw={'projection': 'polar'})\n",
    "data = data_v[:1]\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1, 1.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "\n",
    "for j, d in enumerate(data):\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        # t, p, sf = radial_equilibration(d, rho0, phi0, radius = r)\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | u_{x} | ^2 \\rangle }{\\rho_0 k_B T}$\", fontsize = 14)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | u_{x} | ^2 \\rangle }{\\rho_0 k_B T}$\", fontsize = 14, ha = 'right', va = \"top\", rotation = 'horizontal')\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "\n",
    "fig1.savefig(f\"./{figures}/vel-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/vel-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_dependent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_v = [np.array(ad[('boxlib', 'struct_fact_ux_ux')]).reshape(boxDims)/kbt, \n",
    "          np.array(ad[('boxlib', 'struct_fact_uy_uy')]).reshape(boxDims)/kbt,\n",
    "          np.array(ad[('boxlib', 'struct_fact_uz_uz')]).reshape(boxDims)/kbt]\n",
    "\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_v\n",
    "slc_s = [np.s_[L//2, :, :], np.s_[:, L//2, :], np.s_[:, :, L//2]]\n",
    "labels = ['yz', 'xz', 'xy']\n",
    "fig, axs = plt.subplots(3, 3, figsize = (9, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    d = data[i].copy()\n",
    "    # d /= kbt\n",
    "    # d[slc] = (d.sum() - d[slc])/(L**3)\n",
    "    for j in range(3):\n",
    "        ax = axs[i, j]\n",
    "        im = ax.imshow(d[slc_s[j]], vmin = 0.8, vmax = 1.2)\n",
    "        plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "        ax.set_title(f\"$S_{{u_{chr(120+i)}u_{chr(120+i)}}}$ {labels[j]}\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$u_x$\", r\"$u_y$\", r\"$u_z$\"]\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = 1)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN        \n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[i], color = colors[i],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[i])\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | u_{\\alpha}(k) | ^2 \\rangle }{\\rho_{0}k_b T}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim([0.93, 1.07])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/vel-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "# fig1, tax = plt.subplots(1, 3, figsize = (sz*3, sz), subplot_kw={'projection': 'polar'})\n",
    "# fig2, pax = plt.subplots(1, 3, figsize = (sz*3, sz), subplot_kw={'projection': 'polar'})\n",
    "data = data_v[:1]\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1, 1.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "\n",
    "for j, d in enumerate(data):\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        # t, p, sf = radial_equilibration(d, rho0, phi0, radius = r)\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | u_{x} | ^2 \\rangle }{\\rho_0 k_B T}$\", fontsize = 14)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | u_{x} | ^2 \\rangle }{\\rho_0 k_B T}$\", fontsize = 14, ha = 'right', va = \"top\", rotation = 'horizontal')\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "\n",
    "fig1.savefig(f\"./{figures}/vel-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/vel-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure compositing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent composited figure\n",
    "# %%capture\n",
    "fig, axs = plt.subplots(2, 3, figsize=(3*figheight, 2*figheight))\n",
    "\n",
    "noise_type = \"spatially_independent\"\n",
    "ordering = ['rho', 'phi', 'vel']\n",
    "\n",
    "downsize = 2\n",
    "for i, ax in enumerate(axs[0]):\n",
    "    pic_path = f\"{figures}/{ordering[i]}-ER-{noise_type}-avg.png\"\n",
    "    img = iio.imread(pic_path)\n",
    "    if downsize is not None:\n",
    "        img = ski.transform.resize(img, (img.shape[0]//downsize, img.shape[1]//downsize), anti_aliasing=True)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.0, 0.9, f\"({chr(97+i)})\", transform=ax.transAxes)\n",
    "\n",
    "paths = [f\"{figures}/rho-ER-{noise_type}-polar.png\", f\"{figures}/phi-ER-{noise_type}-polar.png\", f\"{figures}/vel-ER-{noise_type}-polar.png\"]\n",
    "\n",
    "for i, ax in enumerate(axs[1]):\n",
    "    pic_path = paths[i]\n",
    "    # print(pic_path)\n",
    "    img = iio.imread(pic_path)\n",
    "    if downsize is not None:\n",
    "        img = ski.transform.resize(img, (img.shape[0]//downsize, img.shape[1]//downsize), anti_aliasing=True)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.0, 0.9, f\"({chr(97+3+i)})\", transform=ax.transAxes)\n",
    "\n",
    "fig.subplots_adjust(wspace=-0.1, hspace=0)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figures}/{noise_type}-summary.png\", dpi=DPI)#, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependent composited figure\n",
    "# %%capture\n",
    "fig, axs = plt.subplots(2, 3, figsize=(3*figheight, 2*figheight))\n",
    "\n",
    "noise_type = \"spatially_dependent\"\n",
    "ordering = ['rho', 'phi', 'vel']\n",
    "\n",
    "downsize = None\n",
    "for i, ax in enumerate(axs[0]):\n",
    "    pic_path = f\"{figures}/{ordering[i]}-ER-{noise_type}-avg.png\"\n",
    "    img = iio.imread(pic_path)\n",
    "    if downsize is not None:\n",
    "        img = ski.transform.resize(img, (img.shape[0]//downsize, img.shape[1]//downsize), anti_aliasing=True)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.0, 0.9, f\"({chr(97+i)})\", transform=ax.transAxes)\n",
    "\n",
    "paths = [f\"{figures}/rho-ER-{noise_type}-polar.png\", f\"{figures}/phi-ER-{noise_type}-polar.png\", f\"{figures}/vel-ER-{noise_type}-polar.png\"]\n",
    "\n",
    "for i, ax in enumerate(axs[1]):\n",
    "    pic_path = paths[i]\n",
    "    # print(pic_path)\n",
    "    img = iio.imread(pic_path)\n",
    "    if downsize is not None:\n",
    "        img = ski.transform.resize(img, (img.shape[0]//downsize, img.shape[1]//downsize), anti_aliasing=True)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.0, 0.9, f\"({chr(97+3+i)})\", transform=ax.transAxes)\n",
    "\n",
    "fig.subplots_adjust(wspace=-0.1, hspace=0)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figures}/{noise_type}-summary.png\", dpi=DPI)#, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfacial fluctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists no literature on the theoretical values of what $\\sigma$, $xi$ and $\\phi_0$ are for the swift et al. 1996 model. We will utilize the theory derived in [Cahn and Hilliard 1958](https://doi.org/10.1063/1.1744102) to identify these expressions. The surface tension is defined as the difference between the free energy and the bulk free energy, \n",
    "\n",
    "$$\\sigma = \\int_{-\\infty}^{\\infty} f_0(\\mathbf{r}) + \\frac{\\kappa}{2}(\\nabla \\rho)^2 + \\frac{\\kappa}{2}(\\nabla \\phi)^2 - f_0^{crit} d\\mathbf{r}$$\n",
    "\n",
    "We will also define the chemical potential of the system for $\\rho$ and $\\phi$, as $\\mu_\\rho = \\frac{\\partial f_0}{\\partial \\rho}$ and $\\mu_\\phi = \\frac{\\partial f_0}{\\partial \\phi}$. Some assumptions I will be making are that, $\\rho = 1$ at all points, meaning that $\\nabla\\rho = 0$. We will also assume that the temperature of the system is around the critical point, $T \\sim T_c$. \n",
    "\n",
    "The Gibbs Duhem relation for our system is defined as $f_0 = \\rho\\mu_\\rho + \\phi\\mu_\\phi$. From our first assumption, we can simplify this to $f_0 = \\phi\\mu_\\phi$. At the critical point, $f_0^{crit} = \\phi\\mu_\\phi(1, \\phi_0)$. We can also express $f_0(\\mathbf{r})$ in this fashion, redefining it as $f_0(\\mathbf{r}) = \\phi\\mu_\\phi(1, \\phi(\\mathbf{r}))$. Rewriting Equation 1 to calculate the difference in value from the bulk and local free energies after substitution of the Gibbs Duhem relation we have\n",
    "\n",
    "$$\\sigma = \\int_{-\\infty}^{\\infty} \\Delta f_0(\\mathbf{r}) + \\frac{\\kappa}{2}(\\nabla \\phi)^2 d\\mathbf{r}$$\n",
    "\n",
    "where $\\Delta f_0(\\mathbf{r}) = \\phi(\\mu_\\phi(1, \\phi(\\mathbf{r})) - \\mu_\\phi(1, \\phi_0))$\n",
    "\n",
    "Using Euler-Lagrange, $\\Delta f_0(\\mathbf{r}) = \\kappa(\\nabla \\phi)^2$ as $x \\rightarrow \\infty$. We substitute this solution into the above expression to get, \n",
    "\n",
    "$$\\sigma = 2\\int_{-\\infty}^{\\infty} \\Delta f_0(\\mathbf{r}) d\\mathbf{r}$$\n",
    "\n",
    "If we substitude the Euler lagrange relation into the surface tension, we obtain an expression for surface tension as a function of $\\phi$\n",
    "\n",
    "$$\\sigma = \\sqrt{2} \\int_{-\\phi_0}^{\\phi_0} \\sqrt{\\kappa \\Delta f_0} d\\phi$$\n",
    "\n",
    "Writing down our free energy definitions again, we have \n",
    "\n",
    "$$ f_0 = \\frac{\\chi}{4}(1 - \\phi^2) - T + \\frac{T}{2}[(1 + \\phi)\\ln{\\frac{1 + \\phi}{2}} + (1 - \\phi)\\ln{\\frac{1 - \\phi}{2}}]$$\n",
    "\n",
    "$$ \\mu_{\\phi} = -\\frac{\\chi}{2}(\\phi) +\\frac{T}{2}\\ln{\\frac{1 + \\phi}{1 - \\phi}}$$\n",
    "\n",
    "We Taylor expand $f_0$ around the critical order parameter and temperature, $\\phi_c$ and $T_c$ and obtain the following expression, identical to that from [Cahn and Hilliard 1958](https://doi.org/10.1063/1.1744102). $\\phi_c = 0$ in the model that we are using.\n",
    "\n",
    "$$\\Delta f_0 = \\Delta f(\\phi, T) - \\Delta f(\\phi_0, T) = -\\beta(T_c - T)(\\phi^2 - \\phi_0^2) + \\gamma(\\phi^4 - \\phi_0^4)$$\n",
    "\n",
    "The coefficients of the expansion, $\\beta$ and $\\gamma$, are defined as\n",
    "\n",
    "$$\\beta = \\frac{\\partial^3 f_0}{\\partial T \\partial \\phi^2 2!} = \\frac{1}{2(1 - \\phi_c^2)} = 0.5$$\n",
    "\n",
    "$$\\gamma = \\frac{\\partial^4 f_0}{\\partial \\phi^4 4!} = \\frac{2T_c(3\\phi_c^2 + 1)}{(1 - \\phi_c)^2} = \\frac{T_c}{12}$$\n",
    "\n",
    "These subsitutions then lead to the solution for $\\phi_0$\n",
    "\n",
    "$$\\phi_0 = \\pm \\sqrt{\\frac{\\beta (T_c - T)}{2\\gamma}} = \\sqrt{\\frac{3(T_c - T)}{T_c}}$$\n",
    "\n",
    "$$\\Delta f_0 = \\frac{T_c}{12}(\\phi_0^2 - \\phi)^2$$\n",
    "\n",
    "Substituting the expressions above into the integral for surface tension, we can calculate a theoretical expression for the surface tension, \n",
    "\n",
    "$$\\sigma = \\frac{2\\sqrt{\\kappa}}{3\\gamma}(\\beta (T_c - T))^{1.5} = \\frac{8\\sqrt{\\kappa}}{T_c}(\\frac{(T_c - T)}{2})^{1.5}$$\n",
    "\n",
    "To calculate the interface width, we begin with solving the euler lagrange relation\n",
    "\n",
    "$$\\frac{\\partial \\phi}{\\partial x} = \\sqrt{\\frac{2 \\Delta f_0}{\\kappa}}$$\n",
    "\n",
    "Once we integrate the differential equation above, we obtain the solution to the profile of the interface, \n",
    "\n",
    "$$\\phi = \\phi_0 \\tanh{\\sqrt{\\frac{2\\gamma}{\\kappa}}\\phi_0 x} = \\phi_0 \\tanh{\\sqrt{\\frac{T_c - T}{2 \\kappa}}x}$$\n",
    "\n",
    "This results in predicted properties of the coexistence order parameter $\\phi_0$, surface tension $\\sigma$ and the interface width $\\xi$\n",
    "\n",
    "$$\\phi_0 = \\pm \\sqrt{\\frac{3(T_c - T)}{T_c}}$$\n",
    "\n",
    "$$\\sigma = \\frac{8\\sqrt{\\kappa}}{T_c}\\left(\\frac{T_c - T}{2}\\right)^{1.5}$$\n",
    "\n",
    "$$\\xi = \\sqrt{\\frac{\\kappa}{T_c - T}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 256\n",
    "ny = 1\n",
    "nz = 2048\n",
    "noise_type = \"spatially_independent\"\n",
    "# noise_type = \"spatially_dependent\"\n",
    "savedir = f\"./validation/interface/{noise_type}\"\n",
    "\n",
    "# nx = 32\n",
    "# ny = 4\n",
    "# nz = 256\n",
    "# savedir = \"./\"\n",
    "\n",
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "kappa = 0.03\n",
    "kbt = 1e-7\n",
    "u0 = 0\n",
    "cs2 = 1/3\n",
    "gamma = 1.0\n",
    "\n",
    "chi = 0.5\n",
    "T = 0.2\n",
    "\n",
    "idx = -1\n",
    "\n",
    "output_file = \"hydro_plt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "# profile = extract_data(savedir + sorted(glob.glob(\"./*.h5\"))[-1], [nx, ny, nz], begin = 1, end = 2, nVars = 38)\n",
    "path = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[idx]\n",
    "profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38)\n",
    "\n",
    "# ts = yt.load(f\"{savedir}/{output_file}*\")\n",
    "# ds = ts[-1]\n",
    "# ad = ds.all_data()\n",
    "# profile = np.array([np.array(ad[('boxlib', 'density')]).reshape(boxDim), np.array(ad[('boxlib', 'phi')]).reshape(boxDim)])\n",
    "\n",
    "phi0 = np.sqrt(3*(chi/2 - T)/(chi/2))\n",
    "phi0 = newton(fb, x0 = (phi0), args = (chi, T))\n",
    "# xi = np.sqrt((0.142*kappa)/((chi/2 - T)-0.31*T*(phi0**2)))\n",
    "# xi = np.sqrt(kappa/(chi/2 - T))\n",
    "xi = 0.69\n",
    "fit_func = lambda x, b:phi0*np.tanh((x - b)/(np.sqrt(2)*xi))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize = (8, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "ax = axs[0]\n",
    "im = ax.imshow(profile[0, :, : , nz//2])\n",
    "ax.set_xlabel(\"y\")\n",
    "ax.set_ylabel(\"x\")\n",
    "plt.colorbar(im, ax = ax, label = r\"$\\rho$\")\n",
    "\n",
    "ax = axs[1]\n",
    "x = np.arange(nx//4, 3*nx//4, 1)\n",
    "im = ax.plot(x, profile[0, nx//4:3*nx//4, ny//2 , nz//2], 'rx', label = \"profile\")\n",
    "ax.plot(x, np.ones(x.size), 'ko', label = \"reference\", markerfacecolor=\"None\")    \n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(r\"$\\rho$\")\n",
    "ax.legend(ncol = 1, fontsize = 'small')\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(profile[1, :, : , nz//2])\n",
    "ax.set_xlabel(\"y\")\n",
    "ax.set_ylabel(\"x\")\n",
    "plt.colorbar(im, ax = ax, label = r\"$\\phi$\")\n",
    "\n",
    "ax = axs[3]\n",
    "x = np.arange(nx//4, 3*nx//4, 1)\n",
    "im = ax.plot(x, profile[1, nx//4:3*nx//4, ny//2 , nz//2], 'rx', label = \"profile\")\n",
    "\n",
    "x = np.linspace(0, nx - 1, nx)\n",
    "y = fit_func(x, (nx - 1)/2)\n",
    "ax.plot(x, y, 'ko', label = \"referece\", markerfacecolor=\"None\")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "ax.legend(ncol = 1, fontsize = 'small')\n",
    "\n",
    "t = int(path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "fig.suptitle(f\"$\\kappa$ = {kappa}, $\\chi = {chi}, T = {T}, t = {t}$\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[1]\n",
    "profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38)\n",
    "\n",
    "methods = [\"direct\", \"profile_fit\"]\n",
    "xi = np.power(kappa/(chi/2 - T), 0.5)\n",
    "# shift = [1/xi, 1]\n",
    "shift = [1, 1]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (5, 4))\n",
    "\n",
    "colors = ['tab:orange', 'black', 'red']\n",
    "ls = []\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    h = interface_height(profile[1], chi, T, kappa, method = method, zero = True)\n",
    "    print(h.shape)\n",
    "    h = np.mean(h, axis = 0)\n",
    "    ax.plot(h*shift[i], label = method, color = colors[i])\n",
    "    ls.append(h)\n",
    "\n",
    "ax.set_ylabel(\"Height fluctuations\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"direct\"\n",
    "# method = \"profile_fit\"\n",
    "fft_mode = 'forward'\n",
    "\n",
    "heights_k = np.zeros((nz), dtype = np.complex128)\n",
    "# h5_paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[102:]\n",
    "data_paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[1:102]\n",
    "\n",
    "# data_paths = yt.load(f\"{savedir}/{output_file}*\")[1:]\n",
    "# ds = ts[-1]\n",
    "# ad = ds.all_data()\n",
    "# profile = np.array([np.array(ad[('boxlib', 'density')]).reshape(boxDim), np.array(ad[('boxlib', 'phi')]).reshape(boxDim)])\n",
    "\n",
    "\n",
    "for path in data_paths:\n",
    "    phi = extract_data(path, boxDim, begin = 1, end = 2, nVars = 38)[0]\n",
    "    # ad = path.all_data()\n",
    "    # phi = np.array(ad[('boxlib', 'phi')]).reshape(boxDim)\n",
    "    \n",
    "    h = interface_height(phi, chi, T, kappa, method = method, zero = True)\n",
    "    h = np.mean(h, axis = 0)\n",
    "    \n",
    "    h_k = fft.fft(h, norm = fft_mode)\n",
    "\n",
    "    heights_k += h_k*h_k.conjugate()\n",
    "    # t = int(path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "    # print(f\"Timestep {t} processed\")\n",
    "\n",
    "heights_k = np.abs(heights_k)\n",
    "heights_k /= len(data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = fft.fftfreq(L)*2*np.pi\n",
    "S1 = heights_k.copy()\n",
    "\n",
    "plt.plot(k1, S1, label = \"Raw data\", marker = 'x', color = 'r', lw = 1, markerfacecolor = \"None\", ls = \"None\")\n",
    "plt.plot(k1, S1*2, label = \"Doubled Raw data\", marker = 'o', color = 'b', lw = 1, markerfacecolor = \"None\", ls = \"None\")\n",
    "\n",
    "x_test = k1[1:L//2]\n",
    "y_test = S1[1:L//2].copy()\n",
    "y_test += np.flip(S1[L//2+1:])\n",
    "\n",
    "plt.plot(x_test, y_test, label = \"Adding -ve x to +ve x\", marker = '^', color = 'k', lw = 1, markerfacecolor = \"None\", ls = \"None\")\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPERIMENTAL RESULTS ##\n",
    "L = nz\n",
    "k1 = fft.fftfreq(L)*2*np.pi\n",
    "S1 = heights_k.copy()\n",
    "\n",
    "slc = slice(1, L//2)\n",
    "xraw = k1[slc].copy()\n",
    "yraw = S1[slc].copy()\n",
    "yraw *= 2 if method == 'direct' else yraw # accounting for addition of negative k power spectrum\n",
    "# yraw += np.flip(S1[L//2+1:]) # accounting for addition of negative k power spectrum\n",
    "\n",
    "binsize = 128\n",
    "kmin = 2*np.pi/binsize\n",
    "bins = np.arange(binsize//2+1)*kmin # kmax+1 for bin_edges: len(bins)=len(hist)+1\n",
    "shells = np.histogram(xraw, bins, weights=yraw)[0]\n",
    "counts = np.histogram(xraw, bins)[0]\n",
    "\n",
    "xbin = (bins[:-1]+bins[1:])/2\n",
    "ybin = shells/counts\n",
    "## EXPERIMENTAL RESULTS ##\n",
    "\n",
    "## THEORETICAL RESULTS ##\n",
    "sigma = 0.0172\n",
    "# sigma = 8*np.sqrt(kappa)/(chi/2)*np.power((chi/2 - T)/2, 1.5)\n",
    "freqs_theory = np.linspace(xraw[0], xraw[-1], 1001)\n",
    "interface_fluct_theory = kbt/(sigma*np.power(freqs_theory, 2))\n",
    "interface_fluct_theory /= ny*nz\n",
    "## THEORETICAL RESULTS ##\n",
    "\n",
    "sz = figheight\n",
    "ar = 1.25\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "# ax.loglog(xraw, yraw, \"ks\", label = \"Simulation raw\", ms = 5, markerfacecolor = \"None\")\n",
    "ax.loglog(xbin, ybin, \"bo\", label = \"Simulation\", ms = 3)\n",
    "ax.loglog(freqs_theory, interface_fluct_theory, 'r-', lw = 2, label = \"Theory\")\n",
    "\n",
    "ax.set_xlim(left = 1e-2)\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 15)\n",
    "ax.set_ylabel(r\"$\\langle |h(k)|^2 \\rangle$\", fontsize = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "ax.legend(fontsize = 12, loc = 'lower left')\n",
    "# # ax.set_title(f\"L = {nz}\")\n",
    "# ax.set_title(f\"{method}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figures}/interface_height_flucuations-{noise_type}.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droplet fluctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources\n",
    "1. [Simulation of FUS Protein Condensates with an adapted coarse grained model](https://pubs.acs.org/doi/10.1021/acs.jctc.0c01064)\n",
    "2. [Effect of nanoparticles and surfactants on droplets in shear flows](https://doi.org/10.1039/C2SM25209K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing analysis routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing a sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 4.5\n",
    "ar = 1.3\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "R_s = np.arange(10, 55, 5, dtype = float)\n",
    "\n",
    "R_iso = np.zeros_like(R_s)\n",
    "R_mass = np.zeros_like(R_s)\n",
    "\n",
    "colors = ['r', 'b', 'k']\n",
    "markers = ['^', 's', 'o']\n",
    "\n",
    "for i,R in enumerate(R_s):\n",
    "    test_ellipse = draw.ellipsoid(R, R, R, levelset=False)\n",
    "    test_ellipse = np.where(test_ellipse == True, 1, 0)\n",
    "    R_mass[i] = droplet_radius_mass(test_ellipse)\n",
    "    R_iso[i] = droplet_radius_iso(test_ellipse)\n",
    "\n",
    "ax.plot(R_s, R_s, label = r\"$R_{theory}$\", color = colors[0], marker = markers[0], markerfacecolor = \"None\", ls = \"-\", ms = 10)\n",
    "ax.plot(R_s, R_iso, label = r\"$R_{iso}$\", color = colors[1], marker = markers[1], markerfacecolor = \"None\", ls = \"None\", ms = 10)\n",
    "ax.plot(R_s, R_mass, label = r\"$R_{m}$\", color = colors[2], marker = markers[2], markerfacecolor = \"None\", ls = \"None\", ms = 10)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel(\"R supplied\")\n",
    "ax.set_ylabel(\"R calculated\")\n",
    "ax.set_title(\"Comparing the theoretical radius to the calculated\\n radius using the droplet mass and iso-surface methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = 20\n",
    "# ar = 1.5\n",
    "\n",
    "sphere = [7.9, 7.9, 7.9]\n",
    "prolate = [12.6, 6.3, 6.3]\n",
    "oblate = [5, 10, 10]\n",
    "\n",
    "test_ellipse = draw.ellipsoid(*sphere, levelset=False)\n",
    "test_ellipse = np.where(test_ellipse == True, 1, 0)\n",
    "\n",
    "nx, ny, nz = test_ellipse.shape\n",
    "\n",
    "plt.imshow(test_ellipse[:, 5, :])\n",
    "plt.colorbar()\n",
    "\n",
    "print(f\"R_sphere:7.9, R_mass:{droplet_radius_mass(test_ellipse):.3f}, R_iso:{droplet_radius_iso(test_ellipse):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nk_com(mat):\n",
    "    cm = np.zeros(3)\n",
    "    mass = np.sum(mat)\n",
    "\n",
    "    indexes = np.indices(mat.shape)\n",
    "    \n",
    "    for i in range(3):\n",
    "        cm[i] = np.sum(mat*indexes[i])\n",
    "\n",
    "    cm /= mass\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radii_fluct_gpt(field):\n",
    "    level = filters.threshold_otsu(field)\n",
    "    verts, faces, normals, values = measure.marching_cubes(field, level = level)\n",
    "    [x_c, y_c, z_c] = center_of_mass(field)\n",
    "\n",
    "    radii = np.sqrt((verts[:, 0] - x_c)**2 +\n",
    "                (verts[:, 1] - y_c)**2 +\n",
    "                (verts[:, 2] - z_c)**2)\n",
    "    R = np.mean(radii)\n",
    "\n",
    "    delta_r = radii - R\n",
    "    delta_x = delta_r * (verts[:, 0] - x_c) / radii\n",
    "    delta_y = delta_r * (verts[:, 1] - y_c) / radii\n",
    "    delta_z = delta_r * (verts[:, 2] - z_c) / radii\n",
    "\n",
    "    radiis = np.array([delta_x, delta_y, delta_z])\n",
    "    radiis = radiis.T\n",
    "\n",
    "    return radiis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "R = 2**4\n",
    "sd = 1e-1\n",
    "x = np.linspace(-3*sd, 3*sd, 100)\n",
    "norm_dist = stats.norm.pdf(x, 0, sd)\n",
    "\n",
    "reps_ls = 10**np.arange(1, 5, 1)\n",
    "\n",
    "sigma_reps = np.zeros_like(reps_ls, dtype = float)\n",
    "R_refs = np.zeros_like(reps_ls, dtype = float)\n",
    "\n",
    "rows = 2\n",
    "cols = int(np.ceil(reps_ls.size/rows))\n",
    "sz = 3\n",
    "ar = 1\n",
    "fig, axs = plt.subplots(rows, cols, figsize = (sz*ar*cols, sz*rows))\n",
    "axs = axs.flatten()\n",
    "\n",
    "colors = ['tab:blue', 'tab:green', 'tab:orange']\n",
    "linestyles = [\"-\", \":\", \"--\"]\n",
    "\n",
    "for idx, reps in enumerate(reps_ls):\n",
    "    R_ref = 0\n",
    "    radiis = np.zeros((reps, 3))\n",
    "\n",
    "    for i in range(reps):\n",
    "        delta = np.random.normal(loc = 0, scale = sd, size = 3)\n",
    "        R_curr = R + delta\n",
    "\n",
    "        field = draw.ellipsoid(*R_curr, levelset=False)\n",
    "        field = np.where(field == True, 1, 0)\n",
    "\n",
    "        R_ref += droplet_radius_mass(field)\n",
    "        cm = center_of_mass(field)\n",
    "        # cm = nk_com(field)\n",
    "\n",
    "        # gyration tensor method #\n",
    "        gr = gyration_tensor(cm, field)\n",
    "        egr = np.linalg.eigvals(gr)\n",
    "\n",
    "        da = np.power(egr[0], 1/3)/np.power(np.prod(egr[[1,2]]), 1/6)\n",
    "        db = np.power(egr[1], 1/3)/np.power(np.prod(egr[[0,2]]), 1/6)\n",
    "        dc = np.power(egr[2], 1/3)/np.power(np.prod(egr[[0,1]]), 1/6)\n",
    "        curr_dr = np.array([da, db, dc])\n",
    "        radiis[i] = curr_dr\n",
    "        # gyration tensor method #\n",
    "\n",
    "    R_ref /= reps\n",
    "    R_refs[idx] = R_ref\n",
    "    # radiis = R_ref*(radiis - 1)\n",
    "    radiis -= 1\n",
    "    radiis *= R_ref\n",
    "\n",
    "    for i in range(3): \n",
    "        counts, bin, patch = axs[idx].hist(radiis[:, i], label = r\"$\\delta$\"+chr(120+i), bins = 25, density = True, color = colors[i], alpha = 1)\n",
    "        r_mean = np.mean(radiis[:, i])\n",
    "        axs[idx].plot([r_mean, r_mean], [0, counts.max()*1.5], color = colors[i], lw = 1.5, ls = linestyles[i])\n",
    "\n",
    "    axs[idx].plot(x, norm_dist, 'k-', label = \"norm dist\", lw = 2)\n",
    "    \n",
    "    axs[idx].set_xlabel(r\"$\\delta a$\")\n",
    "    axs[idx].set_ylabel(r\"pdf\")\n",
    "    axs[idx].set_title(f\"reps = {reps}\")\n",
    "    axs[idx].legend(ncol = 2)\n",
    "\n",
    "    sigma_fluct = droplet_fluctuations(radiis, temp = 1e-7)\n",
    "    sigma_reps[idx] = np.mean(sigma_fluct)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 4\n",
    "ar = 1.25\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "ls = []\n",
    "\n",
    "ln, = ax.plot(reps_ls, sigma_reps, 'rx--', ms = 10, markerfacecolor = \"None\", label = r\"$\\sigma$\")\n",
    "ls.append(ln)\n",
    "ax2 = ax.twinx()\n",
    "ln, = ax2.plot(reps_ls, R_refs, 'bs:', ms = 10, markerfacecolor = \"None\", label = r\"$R_{ref}$\")\n",
    "ls.append(ln)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlabel(\"Repetitions\")\n",
    "ax.set_ylabel(r\"$\\sigma_{calc}$\")\n",
    "ax2.set_ylabel(r\"$R_{ref}$\")\n",
    "\n",
    "ax.legend(handles = ls)#, loc = 'upper left')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Young Laplace fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 64\n",
    "ny = 64\n",
    "nz = 64\n",
    "\n",
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "chi = 0.5\n",
    "T = 0.23\n",
    "kappa = 0.03\n",
    "kbt = 1e-7\n",
    "\n",
    "u0 = 0\n",
    "cs2 = 1/3\n",
    "gamma = 1.0\n",
    "\n",
    "idx = -1\n",
    "# savedir = f\"./validation/droplet_fluctuations/young_laplace/chi_{chi}-T_{T}-k_{kappa}/\"\n",
    "savedir = f\"./validation/droplet_fluctuations/young_laplace/\"\n",
    "# chi_0.5-T_0.2-k_0.03\n",
    "# R_s = [\"0.2\", \"0.25\", \"0.3\", \"0.35\"]\n",
    "R_s = [\"0.25\", \"0.3\", \"0.35\"]\n",
    "output_file = \"hydro_plt\"\n",
    "savedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_radii = []\n",
    "all_times = []\n",
    "all_press = []\n",
    "\n",
    "for R in R_s:\n",
    "    paths = sorted(glob.glob(f\"{savedir}/R_{R}/{output_file}*.h5\"))\n",
    "\n",
    "    curr_radii = np.zeros(len(paths))    \n",
    "    curr_times = np.zeros(len(paths))\n",
    "    curr_press = np.zeros(len(paths))\n",
    "    for i, path in enumerate(paths):\n",
    "        t = int(path.split(\"_\")[-1].split(\".\")[0])    \n",
    "        curr_times[i] = t\n",
    "\n",
    "        profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38)\n",
    "\n",
    "        curr_radii[i] = droplet_radius_mass(profile[1])\n",
    "\n",
    "        # pressure = pressure_tensor(profile, T, kappa)\n",
    "        # scalar_pressure = np.einsum('ijkmn,mn->ijk',pressure,np.identity(boxDim.size))/3\n",
    "        # # scalar_pressure = (pressure[..., 0, 0] + pressure[..., 1, 1] + pressure[..., 2, 2])/3\n",
    "        # curr_press[i] = pressure_jump(scalar_pressure)\n",
    "\n",
    "        scalar_pressure = (extract_data(path, boxDim, begin = 8, end = 9, nVars = 38)[0] + profile[0])/3\n",
    "        curr_press[i] = pressure_jump(scalar_pressure)\n",
    "        \n",
    "    \n",
    "    all_radii.append(curr_radii)\n",
    "    all_times.append(curr_times)\n",
    "    all_press.append(curr_press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 4\n",
    "ar = 1.25\n",
    "fig, axs = plt.subplots(1, 2, figsize = (sz*ar*2, sz))\n",
    "axs2 = [ax.twinx() for ax in axs]\n",
    "\n",
    "cols = ['r', 'b', 'k', 'g']\n",
    "markers = ['s', 'o', '^', '*']\n",
    "linestyles = ['-', '--', ':', 'dashdot']\n",
    "\n",
    "for i, R in enumerate(R_s):\n",
    "    x = all_times[i]\n",
    "    y = all_radii[i]\n",
    "    y2 = all_press[i]\n",
    "    if len(x) > 1:\n",
    "        plotx = x[1:]\n",
    "        ploty = y[1:]\n",
    "        ploty2 = y2[1:]\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.plot(plotx, ploty, label = f'R = {R}', marker = markers[i], linestyle = \"None\", color = cols[i], markerfacecolor = \"None\", ms = 8)\n",
    "\n",
    "        ax2 = axs2[0]\n",
    "        ax2.plot(plotx, ploty2, label = f'R = {R}', marker = \"None\", linestyle = linestyles[i], color = cols[i], markerfacecolor = \"None\", ms = 8)\n",
    "\n",
    "        ax = axs[1]\n",
    "        ploty = (ploty - ploty.min())/(ploty.max() - ploty.min())\n",
    "        ax.plot(plotx, ploty, label = f'R = {R}', marker = markers[i], linestyle = \"None\", color = cols[i], markerfacecolor = \"None\", ms = 8)\n",
    "\n",
    "        ax2 = axs2[1]\n",
    "        ploty = (ploty2 - ploty2.min())/(ploty2.max() - ploty2.min())\n",
    "        ax2.plot(plotx, ploty, label = f'R = {R}', marker = \"None\", linestyle = linestyles[i], color = cols[i], markerfacecolor = \"None\", ms = 8)\n",
    "    \n",
    "ax = axs[0]\n",
    "\n",
    "ax.set_xlabel(\"Timesteps\")\n",
    "ax.set_ylabel(r\"$R$\")\n",
    "ax.set_xscale(\"log\")\n",
    "# ax.legend(loc = 'center right')\n",
    "\n",
    "ax2 = axs2[0]\n",
    "ax2.set_ylabel(r\"$\\Delta P$\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_xlabel(\"Timesteps\")\n",
    "ax.set_ylabel(r\"$\\frac{R - R_{min}}{R_{max} - R_{min}}$\")\n",
    "ax.set_xscale(\"log\")\n",
    "# ax.legend(loc = 'center right')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "\n",
    "ax2 = axs2[1]\n",
    "ax2.set_ylabel(r\"$\\frac{\\Delta P - \\Delta P_{min}}{\\Delta P_{max} - \\Delta P_{min}}$\")\n",
    "\n",
    "\n",
    "fig.suptitle(\"Droplet radius evolution over time\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "young_laplace = lambda x, sigma: sigma*x\n",
    "\n",
    "xraw = []\n",
    "yraw = []\n",
    "for i in range(0, len(R_s)):\n",
    "    ls = all_radii[i]\n",
    "    if len(ls) > 1:\n",
    "        xraw.append(2/all_radii[i][-1])\n",
    "        yraw.append(all_press[i][-1])\n",
    "\n",
    "sz = figheight\n",
    "ar = 1.25\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "ax.plot(xraw, yraw, 'bo', ms = 8, linestyle = \"None\", label =\"Raw data\", markerfacecolor = \"None\")\n",
    "\n",
    "guess = 8*np.sqrt(kappa)/(chi/2)*np.power((chi/2 - T)/2, 1.5)\n",
    "popt, pcov = curve_fit(young_laplace, xraw, yraw, p0 = [guess])\n",
    "xfit = np.linspace(min(xraw), max(xraw), 101)\n",
    "yfit = young_laplace(xfit, *popt)\n",
    "ax.plot(xfit, yfit, 'r-', lw = 1, label = \"Fit data\")\n",
    "\n",
    "ax.text(xraw[1], 0.9*yraw[1], r\"$\\sigma$=\"+f\"{popt[0]:.4f}\", fontsize = 12)\n",
    "print(r\"$\\sigma$=\"+f\"{popt[0]:.4f} $\\sigma_t = {guess:.4f}$\")\n",
    "ax.set_ylabel(r\"$\\Delta P$\", fontsize = 15)\n",
    "ax.set_xlabel(r\"$\\frac{2}{R_d}$\", fontsize = 15)\n",
    "# ax.set_title(f\"$\\chi$={chi}, $T$={T}, $\\kappa$={kappa}\", fontsize = 18)\n",
    "# ax.legend(fontsize = 12)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figures}/young_laplace_sigma.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluctuations of droplet shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details box dimensions and thermodynamic information used to conduct simulations\n",
    "nx = 32\n",
    "ny = 32\n",
    "nz = 32\n",
    "\n",
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "kappa = 0.03\n",
    "kbt = 1e-7\n",
    "u0 = 0\n",
    "cs2 = 1/3\n",
    "gamma = 1.0\n",
    "\n",
    "chi = 0.5\n",
    "T = 0.2\n",
    "\n",
    "idx = 0\n",
    "\n",
    "# noise_type = \"spatially_dependent\"\n",
    "noise_type = \"spatially_independent\"\n",
    "# savedir = f\"./validation/droplet_fluctuations/{noise_type}\"\n",
    "savedir = f\"./validation/droplet_fluctuations/{noise_type}_{nx}-T_{T}\"\n",
    "output_file = \"hydro_plt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the droplet in the system as well as the \n",
    "\n",
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "path = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[idx]\n",
    "profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize = (8, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "ax = axs[0]\n",
    "im = ax.imshow(profile[0, :, : , nz//2])\n",
    "ax.set_xlabel(\"y\")\n",
    "ax.set_ylabel(\"x\")\n",
    "plt.colorbar(im, ax = ax, label = r\"$\\rho$\")\n",
    "\n",
    "ax = axs[1]\n",
    "x = np.arange(0, nx, 1)\n",
    "im = ax.plot(x, profile[0, :, ny//2 , nz//2], 'rx', label = \"profile\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(r\"$\\rho$\")\n",
    "ax.legend(ncol = 1, fontsize = 'small')\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(profile[1, :, : , nz//2])\n",
    "ax.set_xlabel(\"y\")\n",
    "ax.set_ylabel(\"x\")\n",
    "plt.colorbar(im, ax = ax, label = r\"$\\phi$\")\n",
    "\n",
    "ax = axs[3]\n",
    "x = np.arange(0, nx, 1)\n",
    "im = ax.plot(x, profile[1, :, ny//2 , nz//2], 'rx', label = \"profile\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "ax.legend(ncol = 1, fontsize = 'small')\n",
    "\n",
    "t = int(path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "fig.suptitle(f\"$\\kappa$ = {kappa}, $\\chi = {chi}, T = {T}, t = {t}$\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplet_radius_mass(profile[1]), center_of_mass(profile[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[:41]\n",
    "\n",
    "R_s = np.zeros(len(paths))\n",
    "times = np.zeros(len(paths))\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    t = int(path.split(\"_\")[-1].split(\".\")[0])    \n",
    "    times[i] = t\n",
    "    \n",
    "    profile = extract_data(path, boxDim, begin = 1, end = 2, nVars = 38)[0]\n",
    "    field = profile.copy()\n",
    "\n",
    "    R_s[i] = droplet_radius_mass(field)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (4, 3))\n",
    "\n",
    "ls = []\n",
    "ln, = ax.plot(times[1:], R_s[1:], 'bo', markerfacecolor = \"None\", ms = 8, label = 'R')\n",
    "ls.append(ln)\n",
    "\n",
    "print(R_s[-1])\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Timesteps\")\n",
    "ax.set_ylabel(r\"$R_{mass}$\")\n",
    "ax.set_title(f\"t = {t}\")\n",
    "\n",
    "ax.legend(handles = ls)\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/droplet_radius.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[40:141]\n",
    "\n",
    "R_s = np.zeros(len(paths))\n",
    "times = np.zeros(len(paths))\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    t = int(path.split(\"_\")[-1].split(\".\")[0])    \n",
    "    times[i] = t\n",
    "    \n",
    "    profile = extract_data(path, boxDim, begin = 1, end = 2, nVars = 38)[0]\n",
    "    field = profile.copy()\n",
    "\n",
    "    R_s[i] = droplet_radius_mass(field)\n",
    "\n",
    "\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid')/w\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (4, 3))\n",
    "\n",
    "ls = []\n",
    "\n",
    "# radii_moving = moving_average(R_s, 5)\n",
    "# time_moving = moving_average(times, 5)\n",
    "\n",
    "ln, = ax.plot(times, R_s, 'b-', markerfacecolor = \"None\", ms = 8, label = 'R')\n",
    "ls.append(ln)\n",
    "\n",
    "ax.set_xlabel(\"Timesteps\")\n",
    "ax.set_ylabel(r\"$R_{mass}$\")\n",
    "ax.set_title(f\"Thermalized droplet Radius\")\n",
    "\n",
    "ax.legend(handles = ls)\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/droplet_radius_fluct.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))\n",
    "slc = slice(140, len(paths))\n",
    "paths = paths[slc]\n",
    "cutoff = 0 # cutoff for setting where the droplet is\n",
    "\n",
    "times = np.zeros(len(paths))\n",
    "radiis = np.zeros((len(paths), 3))\n",
    "R_refs = np.zeros(len(paths))\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    t = int(path.split(\"_\")[-1].split(\".\")[0])    \n",
    "    times[i] = t\n",
    "\n",
    "    profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38) # data extraction from output files. rho (c1 + c2) and phi (c1 - c2) are in index 0 and 1 respectively\n",
    "    field = profile[1].copy() # Slicing phi from the output file\n",
    "    # cutoff = filters.threshold_otsu(field) # cutoff for setting where the droplet is\n",
    "    field = np.where(field > cutoff, field, 0) # selecting only the droplet from the output file. Droplet has phi > 0\n",
    "    # field = morphology.label(field)\n",
    "\n",
    "    cm = center_of_mass(field) # Calculating the center of mass of the droplet\n",
    "    \n",
    "    R_ref = droplet_radius_mass(field) # Calculating the droplet radius to be used for further calculations using the mass method\n",
    "    R_refs[i] = R_ref\n",
    "\n",
    "    # GYRATION TENSOR METHOD ##\n",
    "    gr = gyration_tensor(cm, field) # Calculating the gyration tensor of the droplet\n",
    "    egr = np.linalg.eigvals(gr) # calculating the unordered eigenvalues of the gyration tensor\n",
    "    da = np.power(egr[0], 1/3)/np.power(np.prod(egr[[1,2]]), 1/6) # calculating the variations in dx\n",
    "    db = np.power(egr[1], 1/3)/np.power(np.prod(egr[[0,2]]), 1/6) # calculating the variations in dy\n",
    "    dc = np.power(egr[2], 1/3)/np.power(np.prod(egr[[0,1]]), 1/6) # calculating the variations in dz        \n",
    "\n",
    "    radiis[i] = [da,db,dc]\n",
    "    # GYRATION TENSOR METHOD ##\n",
    "\n",
    "    # # GYRATION TENSOR METHOD ##\n",
    "    # gr = gyration_tensor(cm, field) # Calculating the gyration tensor of the droplet\n",
    "    # egr = np.linalg.eigvals(gr) # calculating the unordered eigenvalues of the gyration tensor\n",
    "    # radiis[i] = np.sqrt(egr)\n",
    "    # GYRATION TENSOR METHOD ##\n",
    "\n",
    "R_ref = np.mean(R_refs)\n",
    "drs = R_ref*(radiis - 1)\n",
    "# drs = radiis - np.mean(radiis, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_indices(nx, ny, nz):\n",
    "    idxs_test = np.zeros((3, nx, ny, nz))\n",
    "    for x in range(nx):\n",
    "        for y in range(ny):\n",
    "            for z in range(nz):\n",
    "                idxs_test[0, x, y, z] = x\n",
    "                idxs_test[1, x, y, z] = y\n",
    "                idxs_test[2, x, y, z] = z\n",
    "    \n",
    "    return idxs_test\n",
    "\n",
    "def com(OutArray):\n",
    "    total_mass = np.sum(OutArray)\n",
    "    com = np.zeros(3)\n",
    "    idxs = get_indices(nx, ny, nz)\n",
    "    \n",
    "    for i in range(3):\n",
    "        field1 = idxs[0]\n",
    "        com[i] = np.sum(field1*OutArray)/total_mass\n",
    "    return com\n",
    "\n",
    "def gyration_tensor_new(cm, OutArray):\n",
    "    nx, ny, nz = OutArray.shape\n",
    "    idxs = get_indices(nx, ny, nz)\n",
    "    total_mass = np.sum(OutArray)\n",
    "    S = np.zeros(9)\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            curr_i = idxs[i].copy()\n",
    "            curr_j = idxs[j].copy()\n",
    "\n",
    "            curr_i -= cm[i]\n",
    "            curr_j -= cm[j]\n",
    "\n",
    "            curr_gyr = OutArray*curr_i*curr_j/total_mass\n",
    "\n",
    "            S[i*3+j] = curr_gyr.sum()\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com(profile[1]), center_of_mass(profile[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = center_of_mass(profile[1])\n",
    "\n",
    "gyration_tensor(cm, profile[1]), gyration_tensor_new(cm, profile[1]).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_radius_mass(density, Vp = 0, np_sphere = 0, rho_sphere = 1):\n",
    "    nx, ny, nz = density.shape\n",
    "    center_slc = np.s_[nx//2-1:nx//2+2, ny//2-1:ny//2+2, nz//2-1:nz//2+2]\n",
    "    edge_slc = np.s_[0:nx:nx-1, 0:ny:ny-1, 0:nz:nz-1]\n",
    "    if isinstance(density, int):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # center = tuple([ l//2 for l in density.shape ])\n",
    "        rho_d = density[center_slc].mean()\n",
    "        rho_m = density[edge_slc].mean()\n",
    "        print(rho_d, rho_m)\n",
    "        # mass = np.sum(density - rho_m) + 0.5*Vp*np_sphere*rho_sphere\n",
    "        print(rho_d, rho_m)\n",
    "        mass = droplet_mass(density - rho_m) + 0.5*Vp*np_sphere*rho_sphere\n",
    "        print(droplet_mass(density))\n",
    "        R = (3./4./np.pi*mass/(rho_d-rho_m))**(1./3.)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(profile[1, 16] - profile[1, 0, 0, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplet_radius_mass(profile[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(profile[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['tab:blue', 'tab:green', 'tab:orange']\n",
    "linestyles = [\"-\", \"-\", \"-\"]\n",
    "\n",
    "sz = 4\n",
    "ar = 1.25\n",
    "fig, axs = plt.subplots(1, 2, figsize = (sz*ar*2, sz))\n",
    "\n",
    "time_corr = times - times[0]\n",
    "counts, bin, patch = axs[0].hist(R_refs, density = True)\n",
    "axs[0].plot([R_ref, R_ref], [0, counts.max()], 'k--', lw = 1)\n",
    "axs[0].set_xlabel(r\"Droplet radius\")\n",
    "axs[0].set_ylabel(r\"pdf\")\n",
    "axs[0].set_title(\"Droplet radius\")\n",
    "\n",
    "for i in range(3): \n",
    "    counts, bin, patch = axs[1].hist(drs[:, i], label = r\"$\\delta$\"+chr(120+i), bins = 25, density = True, color = colors[i], alpha = 1)\n",
    "    r_mean = np.mean(drs[:, i])\n",
    "    print(r_mean)\n",
    "    axs[1].plot([r_mean, r_mean], [0, counts.max()*1.5], color = colors[i], lw = 2, ls = linestyles[i])\n",
    "\n",
    "axs[1].set_xlabel(r\"$\\delta_a$\")\n",
    "axs[1].set_title(\"Radius fluctuations in principal axes\")\n",
    "axs[1].legend()\n",
    "\n",
    "guess = 8*np.sqrt(kappa)/(chi/2)*np.power((chi/2 - T)/2, 1.5)\n",
    "sigma_fluct = droplet_fluctuations(drs, temp = kbt) # y20 y22\n",
    "print(r\"$\\sigma_{20}$=\"+f\"{sigma_fluct[0]:.4f}\" + r\" $\\sigma_{22}$=\"+f\"{sigma_fluct[1]:.4f}\" + r\" $\\sigma_{YL}$=\"+str(guess))\n",
    "print(np.mean(sigma_fluct), guess/np.mean(sigma_fluct)) # mean surface tension calculated from the spherical harmonics method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.eigvals(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((3, 3))\n",
    "# scipy.linalg.lapack.dgels(gr, gr)[0]\n",
    "scipy.linalg.lapack.dgeev(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenvalues_nk(M):\n",
    "    # https://math.stackexchange.com/questions/4107951/all-tricks-to-find-eigenvalues-in-3x3-in-a-faster-way\n",
    "    # coefficients for characteristic polynomial: l^3 + a2*l^2 + a1*l + a0 = 0\n",
    "    # 1. 1 for the cubic term, \n",
    "    # 2. -tr(M) for square term, \n",
    "    # 3. (tr^2(M) - tr(M^2))/2 for the linear term\n",
    "    # 4. -det(M) for the constant term\n",
    "\n",
    "    a2 = -np.trace(M)\n",
    "    a1 = (np.trace(M) ** 2 - np.trace(np.dot(M, M)))/2\n",
    "    a0 = -np.linalg.det(M)\n",
    "\n",
    "    # Solve cubic equation ^3 + a2*^2 + a1* + a0 = 0\n",
    "    # Using numpy's roots function from numpy.polynomial.polynomial\n",
    "    coefficients = [1, a2, a1, a0]  # Coefficients for ^3, ^2, , constant\n",
    "    eigenvalues = np.roots(coefficients)\n",
    "\n",
    "    return eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))\n",
    "slc = slice(50, len(paths))\n",
    "paths = paths[slc]\n",
    "\n",
    "profile = extract_data(paths[0], boxDim, begin = 0, end = 2, nVars = 38)\n",
    "field = profile[1].copy()\n",
    "\n",
    "R_ref = droplet_radius_iso(profile[1])\n",
    "cm = center_of_mass(field)\n",
    "gr = gyration_tensor(cm, field)\n",
    "\n",
    "# egr = eigenvalues_nk(gr)\n",
    "egr = np.linalg.eigvals(gr)\n",
    "\n",
    "da = R_ref*np.power(egr[0], 1/3)/np.power(np.prod(egr[[1,2]]), 1/6) - R_ref\n",
    "db = R_ref*np.power(egr[1], 1/3)/np.power(np.prod(egr[[0,2]]), 1/6) - R_ref\n",
    "dc = R_ref*np.power(egr[2], 1/3)/np.power(np.prod(egr[[0,1]]), 1/6) - R_ref\n",
    "\n",
    "da, db, dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'gyration' # Using the gyration tensor method from the FUS paper listed above\n",
    "# method = 'inertia'\n",
    "\n",
    "paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))\n",
    "slc = slice(40, len(paths))\n",
    "paths = paths[slc]\n",
    "cutoff = 0 # cutoff for setting where the droplet is\n",
    "\n",
    "paths = paths[1:] # Paths that have fluctuations switched on\n",
    "times = np.zeros(len(paths))\n",
    "radiis = np.zeros((len(paths), 3))\n",
    "R_refs = np.zeros(len(paths))\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    t = int(path.split(\"_\")[-1].split(\".\")[0])    \n",
    "    times[i] = t\n",
    "\n",
    "    profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38) # data extraction from output files. rho (c1 + c2) and phi (c1 - c2) are in index 0 and 1 respectively\n",
    "    field = profile[1].copy() # Slicing phi from the output file\n",
    "    field = np.where(field > cutoff, 1, 0) # selecting only the droplet from the output file. Droplet has phi > 0\n",
    "    cm = center_of_mass(field) # Calculating the center of mass of the droplet\n",
    "    \n",
    "    R_ref = droplet_radius_mass(field) # Calculating the droplet radius to be used for further calculations using the mass method\n",
    "    R_refs[i] = R_ref\n",
    "\n",
    "    if method == 'gyration':\n",
    "        # GYRATION TENSOR METHOD ##\n",
    "        gr = gyration_tensor(cm, field) # Calculating the gyration tensor of the droplet\n",
    "        egr = np.linalg.eigvals(gr) # calculating the unordered eigenvalues of the gyration tensor\n",
    "        da = np.power(egr[0], 1/3)/np.power(np.prod(egr[[1,2]]), 1/6) # calculating the variations in dx\n",
    "        db = np.power(egr[1], 1/3)/np.power(np.prod(egr[[0,2]]), 1/6) # calculating the variations in dy\n",
    "        dc = np.power(egr[2], 1/3)/np.power(np.prod(egr[[0,1]]), 1/6) # calculating the variations in dz        \n",
    "\n",
    "        radiis[i] = [da,db,dc]\n",
    "        # GYRATION TENSOR METHOD ##\n",
    "    # elif method == 'inertia':\n",
    "    #     # INERTIA TENSOR METHOD ##\n",
    "    #     I_T = inertia_tensor(cm, field)\n",
    "    #     eit = np.linalg.eigvals(I_T)\n",
    "    #     mass = droplet_mass(field)\n",
    "    #     R = radii_pca(eit, mass)\n",
    "    #     radiis[i] = R - R_ref\n",
    "    #     # INERTIA TENSOR METHOD ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (4*1.25*2, 4))\n",
    "\n",
    "idx_start = 60\n",
    "\n",
    "mean_radii = np.mean(R_refs[idx_start:])\n",
    "pdf, bins, patch = axs[0].hist(R_refs[idx_start:] - mean_radii, bins = 15, density = True)\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid')/w\n",
    "\n",
    "radii_moving = moving_average(R_refs[idx_start:] - mean_radii, 5)\n",
    "time_moving = moving_average(times[idx_start:], 5)\n",
    "\n",
    "axs[1].plot(times[idx_start:], R_refs[idx_start:] - mean_radii)\n",
    "axs[1].set_xlabel(\"Timestep\")\n",
    "axs[1].set_ylabel(\"Timestep\")\n",
    "# axs[1].plot(time_moving, radii_moving)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiis2 = radiis.copy()\n",
    "slc_pca = slice(60, radiis.shape[0])\n",
    "\n",
    "radiis2 = np.mean(R_refs[slc_pca])*(radiis2 - 1)\n",
    "mean_radii = np.mean(radiis2, axis = 0) # calculating mean variation of droplet shape. Ideally should be around 0\n",
    "print(mean_radii)\n",
    "\n",
    "sz = 4\n",
    "ar = 1.25\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "for i in range(3): ax.hist(radiis2[:, i], label = r\"$\\delta$\"+chr(120+i), bins = 25, density = True)\n",
    "ax.set_xlabel(r\"$\\delta a$\")\n",
    "ax.set_ylabel(r\"$pdf$\")\n",
    "ax.legend()\n",
    "\n",
    "guess = 8*np.sqrt(kappa)/(chi/2)*np.power((chi/2 - T)/2, 1.5)\n",
    "sigma_fluct = droplet_fluctuations(radiis2[slc_pca], temp = kbt) # y20 y22\n",
    "print(r\"$\\sigma_{20}$=\"+f\"{sigma_fluct[0]:.4f}\" + r\" $\\sigma_{22}$=\"+f\"{sigma_fluct[1]:.4f}\" + r\" $\\sigma_{YL}$=\"+str(guess))\n",
    "print(np.mean(sigma_fluct), guess/np.mean(sigma_fluct)) # mean surface tension calculated from the spherical harmonics method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_tension_modes(fluctuations, temp = 1e-7):\n",
    "    copy_fluct = fluctuations.T.copy()\n",
    "\n",
    "    zeta_20 = np.zeros_like(copy_fluct)\n",
    "    zeta_22 = np.zeros_like(copy_fluct)\n",
    "\n",
    "    for i in range(3):\n",
    "        zeta_20[i] = np.power(2*copy_fluct[2] - copy_fluct[1] - copy_fluct[0], 2)\n",
    "        zeta_22[i] = np.power(copy_fluct[0] - copy_fluct[1], 2)\n",
    "\n",
    "        copy_fluct = np.roll(copy_fluct, shift = 1, axis = 0)\n",
    "    \n",
    "    zeta_20 = np.mean(zeta_20)\n",
    "    zeta_22 = np.mean(zeta_22)\n",
    "\n",
    "    sigma_20 = 45*temp/(16*np.pi*zeta_20)\n",
    "    sigma_22 = 15*temp/(16*np.pi*zeta_22)\n",
    "\n",
    "    return [sigma_20, sigma_22]\n",
    "\n",
    "y20, y22 = surface_tension_modes(radiis, temp = 1e-7)\n",
    "\n",
    "print(f\"y20:{y20:.5f}, y22:{y22:.5f}, y_avg:{np.mean([y20, y22]):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid variable range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the covariance matrix, certain limits on parameter values are set based upon ensuring that the diagonal remains positive. This limit is set by the term. $5 - c_s^2(k)$ in Xi[5, 5] which corresponds to a maximum allowable $c_s^2(k) = 0.\\bar{5}$. The parameter that controls $c_s^2$ is $T$ as $c_s^2 = T$. $T_c$ or the critical temperature where demixing begins is defined as $T_c = \\lambda/2$. In the expression for calculating $c_s^2(k) = c_s^2 + \\kappa \\rho_0 k^2$, $\\kappa$ also controls the value of $c_s^2(k)$. Therefore this phase diagram will be defined using $\\lambda$ and $\\kappa$. Tested ranges will be $0.1 \\leq \\lambda \\leq 1.1$ and $0.01 \\leq \\kappa \\leq 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "# Newton-Raphson method function\n",
    "def newton_c_ver(initial_guess, chi = 1.1, T = 0.5, tolerance = 1e-4, max_iterations = 1000):\n",
    "    x = initial_guess  # value of phi\n",
    "    rho = 1.0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        fx = calculate_df_dphi(rho, x, chi, T)\n",
    "        dfx = calculate_dmup_dphi(rho, x, chi, T)\n",
    "\n",
    "        # Prevent division by zero\n",
    "        if dfx == 0.0:\n",
    "            # print(\"Divide by 0 encountered in Newton Raphson\")\n",
    "            # sys.exit(-1)\n",
    "            return None\n",
    "\n",
    "        x_next = x - fx / dfx\n",
    "\n",
    "        # Check if the difference between successive iterations is within tolerance\n",
    "        if abs(x_next - x) < tolerance:\n",
    "            return x_next\n",
    "\n",
    "        x = x_next\n",
    "\n",
    "    # print(\"Maximum iteration reached without convergence in Newton Raphson\")\n",
    "    return None\n",
    "\n",
    "@njit()\n",
    "def lattice_fourier_laplacian(kx, ky, kz):\n",
    "    expr1 = np.cos(kx) + np.cos(ky) + np.cos(kz)\n",
    "    expr2 = np.cos(kx)*np.cos(ky) + np.cos(ky)*np.cos(kz) + np.cos(kx)*np.cos(kz)\n",
    "    out = 2/9*expr1 + 2/9*expr2 - 4/3\n",
    "    return -out/(1/3)\n",
    "\n",
    "@njit()\n",
    "def calculate_dmup_drho(rho, phi, chi, T):\n",
    "    out = -T*phi/(rho**2 - phi**2) + chi/2*phi/(rho**2)\n",
    "    return out\n",
    "\n",
    "@njit()\n",
    "def calculate_dmup_dphi(rho, phi, chi, T):\n",
    "    out = T*rho/(rho**2 - phi**2) - chi/(2*rho)\n",
    "    return out\n",
    "\n",
    "@njit()\n",
    "def sound_speed_square(T):\n",
    "    out = T\n",
    "    return out\n",
    "\n",
    "@njit()\n",
    "def calculate_df_dphi(rho, phi, chi, T):\n",
    "    out = -chi/2.*(phi/rho) + T/2.*np.log((1. + phi/rho)/(1. - phi/rho))\n",
    "    return out\n",
    "\n",
    "@njit()\n",
    "def cholesky_decomp(arr_in, n, bstart):\n",
    "    A = arr_in.copy()\n",
    "    # sum = 0\n",
    "    for i in range(bstart, n):\n",
    "        for j in range(bstart, i + 1):\n",
    "            sum = A[i*n + j]\n",
    "            for k in range(j - 1, bstart - 1, -1):\n",
    "                sum -= A[i*n+k]*A[j*n+k]\n",
    "            if i == j:\n",
    "                if sum >= 0:\n",
    "                    A[i*n+j] = np.sqrt(sum)\n",
    "                else:\n",
    "                    A[i*n+j] = 0\n",
    "                    raise ValueError(f\"Row {i} in matrix not spd!\")\n",
    "            else:\n",
    "                if A[j*n+j] > 0:\n",
    "                    A[i*n+j] = sum/A[j*n+j]\n",
    "                else:\n",
    "                    raise ValueError(\"Matrix diagonal is 0\")\n",
    "\n",
    "    for i in range(0, n):\n",
    "        for j in range(i + 1, n):\n",
    "            A[i*n+j] = 0\n",
    "\n",
    "    return A\n",
    "\n",
    "@njit()\n",
    "def covariance_matrix(rho0, phi0, k2, chi = 1.1, T = 0.5, kappa = 0.01, temperature = 1e-7, tau_r = 1, tau_p = 1, Gamma = 1):\n",
    "    ndof = 38\n",
    "    Q = ndof//2\n",
    "    kT = temperature\n",
    "    \n",
    "    cs2 = sound_speed_square(T) + kappa*k2*rho0\n",
    "    mu_rho = calculate_dmup_drho(rho0, phi0, chi, T)\n",
    "    mu_phi = calculate_dmup_dphi(rho0, phi0, chi, T) + k2*kappa\n",
    "    p_phi = k2*kappa*phi0\n",
    "\n",
    "    lambdaLB_r = -1. / tau_r\n",
    "    lambdaLB_p = -1. / tau_p\n",
    "\n",
    "    lambda_r = -lambdaLB_r * (2 + lambdaLB_r) / 2\n",
    "    lambda_p = -lambdaLB_p * (2 + lambdaLB_p) / 2\n",
    "    lambda_rp = -lambdaLB_r * (2 + lambdaLB_p) / 2\n",
    "    lambda_pr = -lambdaLB_p * (2 + lambdaLB_r) / 2\n",
    "\n",
    "    Xi = np.zeros((ndof * ndof,), dtype=float)\n",
    "\n",
    "    Xi[5 * ndof + 5] = 2. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[6 * ndof + 6] = 2. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[7 * ndof + 7] = 2. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[8 * ndof + 8] = 2. * kT * rho0 * (5 - 9 * cs2) * lambda_r\n",
    "    Xi[9 * ndof + 9] = 8. * kT * rho0 * lambda_r\n",
    "    Xi[10 * ndof + 10] = (8.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[11 * ndof + 11] = (2.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[12 * ndof + 12] = (2.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[13 * ndof + 13] = (2.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[14 * ndof + 14] = 4. * kT * rho0 * lambda_r\n",
    "    Xi[15 * ndof + 15] = 4. * kT * rho0 * lambda_r\n",
    "    Xi[16 * ndof + 16] = 4. * kT * rho0 * lambda_r\n",
    "    Xi[17 * ndof + 17] = (4.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[18 * ndof + 18] = (4.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[(Q + 0) * ndof + (Q + 0)] = (4.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[(Q + 1) * ndof + (Q + 1)] = 18. * kT * rho0 * (1 - cs2) * lambda_r\n",
    "    Xi[(Q + 2) * ndof + (Q + 2)] = 8. * kT * rho0 * lambda_r\n",
    "    Xi[(Q + 3) * ndof + (Q + 3)] = (8.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[(Q + 4) * ndof + (Q + 4)] = 2. * Gamma * kT / rho0 * (-9 * Gamma * mu_phi + 5) * lambda_p\n",
    "    Xi[(Q + 5) * ndof + (Q + 5)] = 8. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 6) * ndof + (Q + 6)] = (8.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 7) * ndof + (Q + 7)] = (2.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 8) * ndof + (Q + 8)] = (2.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 9) * ndof + (Q + 9)] = (2.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 10) * ndof + (Q + 10)] = 4. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 11) * ndof + (Q + 11)] = 4. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 12) * ndof + (Q + 12)] = 4. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 13) * ndof + (Q + 13)] = (4.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 14) * ndof + (Q + 14)] = (4.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 15) * ndof + (Q + 15)] = (4.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 16) * ndof + (Q + 16)] = 18. * Gamma * kT / rho0 * (-Gamma * mu_phi + 1) * lambda_p\n",
    "    Xi[(Q + 17) * ndof + (Q + 17)] = 8. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 18) * ndof + (Q + 18)] = (8.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "\n",
    "    Xi[8 * ndof + (Q + 1)] = 6. * kT * rho0 * (3 * cs2 - 1) * lambda_r\n",
    "    Xi[(Q + 1) * ndof + 8] = 6. * kT * rho0 * (3 * cs2 - 1) * lambda_r\n",
    "\n",
    "    Xi[(Q + 4) * ndof + (Q + 16)] = 6. * Gamma * kT / rho0 * (3 * Gamma * mu_phi - 1) * lambda_p\n",
    "    Xi[(Q + 16) * ndof + (Q + 4)] = 6. * Gamma * kT / rho0 * (3 * Gamma * mu_phi - 1) * lambda_p\n",
    "\n",
    "    Xi[8 * ndof + (Q + 4)] = -3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho)\n",
    "    Xi[(Q + 4) * ndof + 8] = -3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(8) * ndof + (Q + 16)] = 3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(Q + 16) * ndof + 8] = 3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "\n",
    "    Xi[(Q + 1) * ndof + (Q + 4)] = 3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(Q + 4) * ndof + (Q + 1)] = 3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(Q + 1) * ndof + (Q + 16)] = -3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(Q + 16) * ndof + (Q + 1)] = -3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "\n",
    "    Xi[(0) * ndof + (Q + 4)] = -3. * Gamma * kT * rho0 * mu_rho / cs2 * lambda_pr\n",
    "    Xi[(Q + 4) * ndof + (0)] = -3. * Gamma * kT * rho0 * mu_rho / cs2 * lambda_pr\n",
    "    Xi[(0) * ndof + (Q + 16)] = 3. * Gamma * kT * rho0 * mu_rho / cs2 * lambda_pr\n",
    "    Xi[(Q + 16) * ndof + (0)] = 3. * Gamma * kT * rho0 * mu_rho / cs2 * lambda_pr\n",
    "\n",
    "    Xi[(1) * ndof + (Q + 1)] = 3. * kT * p_phi / (mu_phi * rho0) * lambda_rp\n",
    "    Xi[(Q + 1) * ndof + (1)] = 3. * kT * p_phi / (mu_phi * rho0) * lambda_rp\n",
    "    Xi[(1) * ndof + (8)] = -3. * kT * p_phi / (mu_phi * rho0) * lambda_rp\n",
    "    Xi[(8) * ndof + (1)] = -3. * kT * p_phi / (mu_phi * rho0) * lambda_rp\n",
    "    Xi[(2) * ndof + (5)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(3) * ndof + (6)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(4) * ndof + (7)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(5) * ndof + (2)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(6) * ndof + (3)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(7) * ndof + (4)] = -phi0 * kT * lambda_pr\n",
    "\n",
    "    return Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def output_spd_homogenous(k2, CHI, KAPPA, T_IN):\n",
    "    SPD = np.zeros_like((CHI))\n",
    "\n",
    "    for x in range(SPD.shape[0]):\n",
    "        for y in range(SPD.shape[1]):\n",
    "            for z in range(SPD.shape[2]):\n",
    "                test_spd = True\n",
    "                for kval in np.nditer(k2.T):\n",
    "                    try:\n",
    "                        Xi = covariance_matrix(1, 0, kval, chi = CHI[x,y,z], T = T_IN[x,y,z], kappa = KAPPA[x, y, z])\n",
    "                        cholesky_decomp(Xi, 38, 5)\n",
    "                    except:\n",
    "                        test_spd = False\n",
    "                        break \n",
    "                SPD[x, y, z] = test_spd\n",
    "                \n",
    "    return SPD\n",
    "\n",
    "@njit\n",
    "def pre_process_inhomogenous_spatially_independent(chi, T, kappa):\n",
    "    # guess = np.sqrt(3*(chi/2 - T)/T)*1/(np.sqrt(2))\n",
    "    phi0_guess = np.arange(0.4, 0.8, 0.1)\n",
    "    for guess in phi0_guess:\n",
    "        phi0 = newton_c_ver(guess, chi = chi, T = T, tolerance = 1e-4, max_iterations = 1000)\n",
    "        if phi0 is not None:\n",
    "            break\n",
    "    print(phi0)\n",
    "    # print(\"phi0:\",phi0, \" T:\",T, \" chi:\",chi, \" kappa:\",kappa)\n",
    "\n",
    "    xi = np.sqrt((0.142*kappa)/((chi/2 - T)-0.31*T*(phi0**2)))\n",
    "    \n",
    "    fit_func = lambda x, b:phi0*np.tanh(0.76*(x - b)/xi)\n",
    "    xraw = np.linspace(-6, 6, 13)\n",
    "    phi_s = fit_func(xraw, -0.5)\n",
    "    return phi_s\n",
    "\n",
    "@njit\n",
    "def output_spd_inhomogenous_spatially_independent(CHI, T_IN, KAPPA):\n",
    "    SPD = np.zeros_like((CHI))\n",
    "    test_spd = True\n",
    "\n",
    "    for x in range(SPD.shape[0]):\n",
    "        for y in range(SPD.shape[1]):\n",
    "            for z in range(SPD.shape[2]):\n",
    "                chi = CHI[x,y,z]\n",
    "                T = T_IN[x,y,z]\n",
    "                kappa = KAPPA[x,y,z]\n",
    "                phi_s = pre_process_inhomogenous_spatially_independent(chi, T, kappa)\n",
    "                for phi in np.nditer(phi_s):\n",
    "                    try:\n",
    "                        Xi = covariance_matrix(1, phi, 0, chi = chi, T = T, kappa = kappa, tau_r = 0.7886751345948129)\n",
    "                        cholesky_decomp(Xi, 38, 5)\n",
    "                    except:\n",
    "                        test_spd = False\n",
    "            \n",
    "                SPD[x,y,z] = test_spd\n",
    "\n",
    "    return SPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = 0.6\n",
    "T = 0.3*chi\n",
    "kappa = 0.0144\n",
    "\n",
    "phi_s = pre_process_inhomogenous_spatially_independent(chi, T, kappa)\n",
    "test_spd = True\n",
    "for phi in np.nditer(phi_s):\n",
    "    try:\n",
    "        Xi = covariance_matrix(1, phi, 0, chi = chi, T = T, kappa = kappa, tau_r = 0.7886751345948129)\n",
    "        cholesky_decomp(Xi, 38, 5)\n",
    "    except:\n",
    "        test_spd = False\n",
    "\n",
    "test_spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_homogenous(points = 10, L = 16):\n",
    "    chimin = 0.2\n",
    "    chimax = 1.2\n",
    "\n",
    "    kappamin = 0.0\n",
    "    kappamax = 0.05\n",
    "\n",
    "    propmin = 0.5\n",
    "    propmax = 0.8\n",
    "\n",
    "    chi_s = np.linspace(chimin, chimax, points)\n",
    "    kappa_s = np.linspace(kappamin, kappamax, points)\n",
    "    prop_s = np.linspace(propmin, propmax, points)\n",
    "    # prop_s[points//2] = 0.5\n",
    "\n",
    "    CHI, KAPPA, PROP = np.meshgrid(*[chi_s, kappa_s, prop_s])\n",
    "    T_IN = CHI*PROP\n",
    "\n",
    "    freqs = fft.fftshift(fft.fftfreq(L))\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "    k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "    \n",
    "    SPD = output_spd_homogenous(k2, CHI, KAPPA, T_IN)\n",
    "    np.savez(\"spd_covariance_homogenous_matrix.npz\", chi = CHI, kappa = KAPPA, T = T_IN, SPD = SPD)\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"spd_covariance_homogenous_matrix.npz\"):\n",
    "    make_plot_homogenous(points = 50)\n",
    "\n",
    "# make_plot(points = 10)\n",
    "# make_plot_homogenous(points = 10)\n",
    "\n",
    "FILE_IN = np.load(\"spd_covariance_homogenous_matrix.npz\")\n",
    "CHI = FILE_IN['chi']\n",
    "KAPPA = FILE_IN['kappa']\n",
    "T_IN = FILE_IN['T']\n",
    "SPD = FILE_IN['SPD']\n",
    "PROPS = T_IN/CHI\n",
    "\n",
    "fig = plt.figure(figsize = (6, 6)) \n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_proj_type('ortho')\n",
    "colors = np.empty(SPD.shape, dtype=object)\n",
    "colors[SPD == 0] = \"w\"\n",
    "colors[SPD == 1] = \"lime\"\n",
    "\n",
    "out = ax.voxels(CHI, T_IN, KAPPA, SPD[:-1, :-1, :-1], facecolors=colors[:-1, :-1, :-1], edgecolor='k')\n",
    "ax.set_xlabel(r\"$\\chi$\")\n",
    "ax.set_ylabel(r\"$T_{in}$\")\n",
    "ax.set_zlabel(r\"$\\kappa$\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# ax.view_init(30, 60, 0) # ax.view_init(elev, azim, roll)\n",
    "ax.view_init(30, 60, 0) # ax.view_init(elev, azim, roll)\n",
    "\n",
    "ax.set_title(\"Homogenous system\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
    "\n",
    "slc_plot = np.s_[10, :, :]\n",
    "im = ax.contourf(CHI[slc_plot], PROPS[slc_plot], SPD[slc_plot], levels = 1, colors = ['tab:red', 'tab:green'])\n",
    "ax.set_xlabel(r\"$\\chi$\")\n",
    "ax.set_ylabel(r\"$T/\\chi$\")\n",
    "curr_prop = np.unique(KAPPA[slc_plot])[0]\n",
    "ax.set_title(f\"$\\kappa = {curr_prop:.3f}$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/valid_homogenous_parameters.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_inhomogenous(points = 10, L = 16):\n",
    "    chimin = 0.3\n",
    "    chimax = 1.0\n",
    "\n",
    "    kappamin = 0.01\n",
    "    kappamax = 0.05\n",
    "\n",
    "    propmin = 0.35\n",
    "    propmax = 0.49\n",
    "\n",
    "    chi_s = np.linspace(chimin, chimax, points)\n",
    "    kappa_s = np.linspace(kappamin, kappamax, points)\n",
    "    prop_s = np.linspace(propmin, propmax, points)\n",
    "\n",
    "    CHI, KAPPA, PROP = np.meshgrid(*[chi_s, kappa_s, prop_s])\n",
    "    T_IN = CHI*PROP\n",
    "\n",
    "    SPD = output_spd_inhomogenous_spatially_independent(CHI, T_IN, KAPPA)\n",
    "    np.savez(\"spd_covariance_inhomogenous_matrix.npz\", chi = CHI, kappa = KAPPA, T = T_IN, SPD = SPD)\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# if not os.path.exists(\"spd_covariance_inhomogenous_matrix.npz\"):\n",
    "    # make_plot_inhomogenous(points = 10)\n",
    "\n",
    "make_plot_inhomogenous(points = 50)\n",
    "FILE_IN = np.load(\"spd_covariance_inhomogenous_matrix.npz\")\n",
    "CHI = FILE_IN['chi']\n",
    "KAPPA = FILE_IN['kappa']\n",
    "T_IN = FILE_IN['T']\n",
    "SPD = FILE_IN['SPD']\n",
    "PROPS = T_IN/CHI\n",
    "\n",
    "fig = plt.figure(figsize = (6, 6)) \n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_proj_type('ortho')\n",
    "colors = np.empty(SPD.shape, dtype=object)\n",
    "colors[SPD == 0] = \"w\"\n",
    "colors[SPD == 1] = \"lime\"\n",
    "\n",
    "out = ax.voxels(CHI, T_IN, KAPPA, SPD[:-1, :-1, :-1], facecolors=colors[:-1, :-1, :-1], edgecolor='k')\n",
    "ax.set_xlabel(r\"$\\chi$\")\n",
    "ax.set_ylabel(r\"$T_{in}$\")\n",
    "ax.set_zlabel(r\"$\\kappa$\")\n",
    "\n",
    "# ax.view_init(30, 60, 0) # ax.view_init(elev, azim, roll)\n",
    "ax.view_init(30, 60, 0)\n",
    "\n",
    "ax.set_title(\"Inhomogenous system\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (3, 3))\n",
    "\n",
    "slc_plot = np.s_[25, :, :]\n",
    "im = ax.contourf(CHI[slc_plot], PROPS[slc_plot], SPD[slc_plot], levels = 1, colors = ['tab:green'])\n",
    "ax.set_xlabel(r\"$\\chi$\")\n",
    "ax.set_ylabel(r\"$T/\\chi$\")\n",
    "curr_prop = np.unique(KAPPA[slc_plot])[0]\n",
    "ax.set_title(f\"$\\kappa = {curr_prop:.3f}$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/valid_inhomogenous_parameters.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
