{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import fft\n",
    "\n",
    "import scipy\n",
    "from scipy.optimize import newton, curve_fit\n",
    "from scipy.ndimage import center_of_mass\n",
    "from skimage import filters, measure\n",
    "\n",
    "from numba import njit\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import yt\n",
    "\n",
    "figures = \"figures/\"\n",
    "figheight = 4\n",
    "os.makedirs(figures, exist_ok = True)\n",
    "DPI = 300\n",
    "\n",
    "import imageio.v3 as iio\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to characterize the data obtained to validate the implementation of thermodynamically consistent fluctuations within a multicomponent lattice boltzmann method based on a free energy formulation. The implementation is written in C++ based on AMReX. The free energy formulation is built using the free energy model proposed in [Swift et al. 1996](https://journals.aps.org/pre/pdf/10.1103/PhysRevE.54.5041) which utilizes a square gradient free energy functional and a bulk free energy defined as two ideal fluids interacting with each other. The modified equilibrium distribution proposed in Swift et al. is utilized.\n",
    "\n",
    "We follow the procedure to develop a formalism fo the fluctuations using the process detailed in [Gross et al. 2010](https://journals.aps.org/pre/pdf/10.1103/PhysRevE.82.056714). They propose spatial correlations of the noise in k space, resulting in a better match to theory especially at higher k values. They state an ansatz which specifies the form of the structure factor of the noise, allowing for the calculation of a covariance matrix that is dependent upon the thermodynamic model utilized. \n",
    "\n",
    "To validate the implementation, the equilibration ratios of the density, order parameter and velocity are calculated for a mixed system of equal volume fractions of each fluid. Next, the interfacial fluctuations are calculated using Eqaution 3.11 in calculated by [Grant and Desai 1983](https://journals.aps.org/pra/pdf/10.1103/PhysRevA.27.2577). Finally, the surface tension calculated from the fluctuations of the shape of a droplet will be compared to that calculated using the Young-Laplace equation as defined in [Benayad et al. 2020](https://doi.org/10.1021/acs.jctc.0c01064)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_data`\n",
    "\n",
    "AMReX can output datafiles with type `h5`. There are 38 fields of data representing the 19 moments of each distribution equation used to describe the hydrodynamics and non-ideal mixing. The ordering of these moments are, $\\rho, \\phi, v_x, v_y, v_z, \\phi v_x, \\phi v_y, \\phi v_z, mf4 ... mf18, mg4 ... mg18$\n",
    "\n",
    "**Input**\n",
    "1. `h5_filepath`: `str` where the `.h5` file as output from AMReX is located\n",
    "2. `dims`: Dimensions of the simulation box input as a `list` or `np.array`\n",
    "3. `begin`: `int` defining the index upon which to start reading the moment fields. \n",
    "4. `end`: `int` defining the index upon which to end reading the moment fields (non inclusive).\n",
    "5. `nVars`: `int` defining the number of data fields that the output file contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(h5_filepath, dims, begin = 0, end = 1, nVars = 38):\n",
    "    if type(dims) == list:\n",
    "        dims = np.array(dims)\n",
    "\n",
    "    with h5py.File(h5_filepath,'r') as h5f:\n",
    "        keys = list(h5f.keys())\n",
    "        test = h5f[keys[-1]]\n",
    "        keys = list(test.keys())\n",
    "        \n",
    "        # boxDims = test[keys[1]][()]\n",
    "        # # print(boxDims)\n",
    "        domain_decomp = test[keys[1]][()]\n",
    "        data = test[keys[2]][()]\n",
    "    \n",
    "    output = np.zeros((end - begin, *dims))\n",
    "    decomp_box_size = [int(domain_decomp[0][5]-domain_decomp[0][2]+1),\n",
    "                       int(domain_decomp[0][4]-domain_decomp[0][1]+1),\n",
    "                       int(domain_decomp[0][3]-domain_decomp[0][0]+1)]\n",
    "    sz = 1\n",
    "    for i in decomp_box_size: sz *= i\n",
    "    revdims = np.flip(dims)\n",
    "\n",
    "    for i in range(begin, end):\n",
    "        currVar = np.zeros(revdims)\n",
    "        for j in range(0, len(domain_decomp)):\n",
    "            curr_decomp = domain_decomp[j]\n",
    "            slc = np.s_[curr_decomp[2]:curr_decomp[5]+1, curr_decomp[1]:curr_decomp[4]+1, curr_decomp[0]:curr_decomp[3]+1]\n",
    "            currVar[slc] = data[(i + j*nVars)*sz:(i+1 + j*nVars)*sz].reshape(*decomp_box_size)\n",
    "    \n",
    "        output[i - begin] = np.moveaxis(currVar, [0, -1], [-1, 0])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBM and thermodynamic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lattice_fourier_laplacian`\n",
    "\n",
    "This function defines the laplacian operator as it appears in k space, defined as the fourier transform of the expression $\\sum_{i \\neq 0} [\\rho(r + c_i) + \\rho(r - c_i) - 2\\rho(r)]/c_s^2$ where $c_s^2$ represents the speed of sound of the lattice kernel used. In practice, this expression becomes, $\\frac{\\frac{2}{9}[\\cos{kx} + \\cos{ky} + \\cos{kz}] + \\frac{2}{9}[\\cos{kx}\\cos{ky} + \\cos{ky}\\cos{kz} + \\cos{kx}\\cos{kz}] - \\frac{4}{3}}{c_s^2}$. To be used as a substitute for any term that contains $\\nabla^2$ in real space.\n",
    "\n",
    "**Input**\n",
    "1. `kx`: Wave vector in the x direction. Can be passed as a `float` or `np.array`\n",
    "1. `ky`: Wave vector in the y direction. Can be passed as a `float` or `np.array`\n",
    "1. `kz`: Wave vector in the z direction. Can be passed as a `float` or `np.array`\n",
    "\n",
    "**Output**\n",
    "1. `k2`: Lattice laplacian value in k space. Output as `float` or `np.array` depending on input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lattice_fourier_laplacian(kx, ky, kz):\n",
    "    expr1 = np.cos(kx) + np.cos(ky) + np.cos(kz)\n",
    "    expr2 = np.cos(kx)*np.cos(ky) + np.cos(ky)*np.cos(kz) + np.cos(kx)*np.cos(kz)\n",
    "    out = 2/9*expr1 + 2/9*expr2 - 4/3\n",
    "    cs2 = 1/3\n",
    "    k2 = -out/cs2\n",
    "    return k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `swift_et_al_1996_thermodynamic_model`\n",
    "\n",
    "Defines the thermodynamic parameters of the swift et al. thermodynamic model as defined in [Swift et al. 1996](https://journals.aps.org/pre/pdf/10.1103/PhysRevE.54.5041).\n",
    "\n",
    "**Input**\n",
    "1. `density`: `float` representing the density of the system\n",
    "2. `C0`: `float` representing the order parameter value\n",
    "3. `chi`: `float` a value corresponding to the width of the double well\n",
    "4. `T`: `float` representing the depth of the double well\n",
    "5. `kappa`: `float` representing the strength of non ideal mixing\n",
    "\n",
    "**Output**\n",
    "1. `model class` with various operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swift_et_al_1996_thermodynamic_model:\n",
    "    def __init__(self, density = 1, C0 = 0, chi = 0.4, T = 0.25, kappa = 0.01):\n",
    "        self.chi = chi\n",
    "        self.T = T\n",
    "        self.kappa = kappa\n",
    "        self.rho = density\n",
    "        self.C0 = C0\n",
    "\n",
    "    def sound_speed_square(self):\n",
    "        out = self.T\n",
    "        return out\n",
    "\n",
    "    def cs2k(self, kx = 0, ky = 0, kz = 0):\n",
    "        thermal_cs2 = self.sound_speed_square()\n",
    "        k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "        out = thermal_cs2 + k2*self.kappa\n",
    "        return out\n",
    "    \n",
    "    def calculate_df_dphi(self):\n",
    "        rho = self.rho\n",
    "        phi = self.C0\n",
    "        chi = self.chi\n",
    "        T   = self.T\n",
    "        out = -chi/2.*(phi/rho) + T/2.*np.log((1. + phi/rho)/(1. - phi/rho))\n",
    "        return out\n",
    "\n",
    "    def calculate_dmup_drho(self):\n",
    "        rho = self.rho\n",
    "        phi = self.C0\n",
    "        chi = self.chi\n",
    "        T   = self.T\n",
    "        out = -T*phi/(rho**2 - phi**2) + chi/2*phi/(rho**2)\n",
    "        return out\n",
    "\n",
    "    def calculate_dmup_dphi(self):\n",
    "        rho = self.rho\n",
    "        phi = self.C0\n",
    "        chi = self.chi\n",
    "        T   = self.T\n",
    "        out = T*rho/(rho**2 - phi**2) - chi/(2*rho)\n",
    "        return out\n",
    "    \n",
    "    def mu_ck(self, kx = 0, ky = 0, kz = 0):\n",
    "        ref_state = self.calculate_dmup_dphi()\n",
    "        k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "        out = ref_state + k2*self.kappa\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `interface_height`\n",
    "\n",
    "To calculate the interface height, three methods are defined in separate functions. These detail three ways to calculate the interface height fluctuations. The first, termed as `direct_old` is a direct implementation identifying the interface height based on the gradient of the order parameter profile. The second, termed `direct` fits the point before and after the location of the interface to a linear expression, followed by identifying the root of the linear expression. The final variant termed `profile-fit`, fits the profile of the order parameter to a profile, $\\phi = \\phi_0\\tanh{\\frac{x - b}{\\sqrt{2} \\xi}}$ profile and uses the fit parameter for $b$. `interface_height` wraps these 3 implementations into a single function so as to make using each implementation easier.\n",
    "\n",
    "**Input**\n",
    "\n",
    "1. `density`: `1D np.array` of the order parameter at each slice of the 3D array\n",
    "2. `chi`: `float` a value corresponding to the width of the double well\n",
    "3. `T`: `float` representing the depth of the double well\n",
    "4. `kappa`: `float` representing the strength of non ideal mixing\n",
    "5. `method`: `str` of which method to use to calculate the interface height. Throws a valueError if invalid method is input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb(phi, l, T, rho = 1):\n",
    "    model = swift_et_al_1996_thermodynamic_model(rho, phi, l, T, kappa = 0)\n",
    "    out = model.calculate_df_dphi()\n",
    "    return out\n",
    "\n",
    "def ih_direct_old(profile):\n",
    "    grad_field_dx = np.abs(np.gradient(profile, axis = 0))\n",
    "    idx_max = np.argmax(grad_field_dx, axis = 0)\n",
    "    return idx_max\n",
    "\n",
    "def ih_direct(profile):\n",
    "    nx, ny, nz = profile.shape\n",
    "    out = np.zeros((ny, nz))\n",
    "    intLoc = (nx - 1)/2\n",
    "\n",
    "    xLo = int(np.floor(intLoc))\n",
    "    xHi = int(np.ceil(intLoc))\n",
    "    \n",
    "    for y in range(ny):\n",
    "        for z in range(nz):\n",
    "            slc = profile[:, y, z]\n",
    "            xslc = [xLo, xHi]\n",
    "            yslc = [slc[xLo], slc[xHi]]\n",
    "            out[y, z] = np.roots(np.polyfit(xslc, yslc, 1))[0]\n",
    "    return out\n",
    "\n",
    "def ih_profile_fit(profile, chi, T, kappa):\n",
    "    nx, ny, nz = profile.shape\n",
    "    out = np.zeros((ny, nz))\n",
    "    phi0 = newton(fb, x0 = (0.6), args = (chi, T))\n",
    "    xi = np.sqrt((0.142*kappa)/((chi/2 - T)-0.31*T*(phi0**2)))\n",
    "    fit_func = lambda x, b:phi0*np.tanh((x - b)/(np.sqrt(2)*xi))\n",
    "\n",
    "    xraw = np.arange(0, nx, 1)\n",
    "\n",
    "    for y in range(ny):\n",
    "        for z in range(nz):\n",
    "            slc = profile[:, y, z]\n",
    "            popt, pcov = curve_fit(fit_func, xraw, slc, p0 = [nx//2])\n",
    "            out[y, z] = popt[0]\n",
    "    return out\n",
    "\n",
    "def interface_height(density, chi, T, kappa, method = \"direct\", zero = False):\n",
    "    height_func = np.zeros(density.shape[1:])\n",
    "\n",
    "    nx, ny, nz = density.shape\n",
    "    lo_min = nx//4\n",
    "    hi_max = 3*(nx//4)\n",
    "    zero_factor = (nx/2 - 1)/2\n",
    "    yraw = density[lo_min:hi_max, :, :]\n",
    "\n",
    "    if method == 'direct':\n",
    "        height_func = ih_direct(yraw)# - zero_factor\n",
    "    elif method == \"profile_fit\":\n",
    "        height_func = ih_profile_fit(yraw, chi, T, kappa)# - zero_factor\n",
    "    elif method == \"direct_old\":\n",
    "        height_func = ih_direct_old(yraw)# - zero_factor\n",
    "    else:\n",
    "        raise ValueError(f'{method} is invalid to calculate interface height')\n",
    "    \n",
    "    height_func = height_func - zero_factor if zero else height_func\n",
    "    \n",
    "    return height_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spherically_averaged_structure_factor`\n",
    "\n",
    "**Input**\n",
    "1. `data`: `np.array` containing the structure factor data for for a moment\n",
    "2. `thermo_model`: `thermodynamics class` for calculation of various parameters directly relevant to the thermodynamic model to be utilized\n",
    "3. `scale_factor`: `float` or `np.array` that the data is divided by\n",
    "4. `func`: `lambda function` that defines some further operations to scale data. Used for spatial correlations\n",
    "5. `shift`: `bool` whether to shift the zero point of the frequencies calculated by `np.fft.fftfreq` to the same order as numpy arrays or as the output of fftw\n",
    "6. `cs`: `bool` whether to use the speed of sound or chemical potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spherically_averaged_structure_factor(data, thermo_model, scale_factor = 1, func = None, shift = True, cs = True):\n",
    "    L = min(data.shape)\n",
    "    S = data.copy()\n",
    "\n",
    "    if shift:\n",
    "        freqs = fft.fftshift(fft.fftfreq(L))\n",
    "    else:\n",
    "        freqs = fft.fftfreq(L)\n",
    "    if len(data.shape) == 3:\n",
    "        kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "        k = np.stack([kx, ky, kz], axis = -1)\n",
    "    elif len(data.shape) == 2:\n",
    "        kx, ky = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L]]), indexing='ij')\n",
    "        k = np.stack([kx, ky], axis = -1)\n",
    "     \n",
    "    k1 = np.linalg.norm(k, axis=-1).flatten()\n",
    "    \n",
    "    if func is not None:\n",
    "        if cs:\n",
    "            S = func(S, thermo_model.cs2k(kx, ky, kz))\n",
    "        else:\n",
    "            S = func(S, thermo_model.mu_ck(kx, ky, kz))\n",
    "    S /= scale_factor\n",
    "\n",
    "    # test[slc] /= test.sum()\n",
    "    # S[L//2, L//2, L//2] /= S.sum()\n",
    "\n",
    "    S1 = S.flatten()\n",
    "    kmin = 2*np.pi/L # sampling frequency\n",
    "    where = np.s_[:]#np.where(k1<=kmax)\n",
    "    bins = np.arange(L//2+1)*kmin # kmax+1 for bin_edges: len(bins)=len(hist)+1\n",
    "    \n",
    "    shells = np.histogram(k1[where], bins, weights=S1[where])[0]\n",
    "    counts = np.histogram(k1[where], bins)[0]\n",
    "    return (bins[:-1]+bins[1:])/2, shells/counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `radial_equilibration`\n",
    "\n",
    "**Input**\n",
    "1. `data`: `np.array` containing the structure factor data for for a moment\n",
    "2. `thermo_model`: `thermodynamics class` for calculation of various parameters directly relevant to the thermodynamic model to be utilized\n",
    "3. `scale_factor`: `float` or `np.array` that the data is divided by\n",
    "4. `func`: `lambda function` that defines some further operations to scale data. Used for spatial correlations\n",
    "5. `shift`: `bool` whether to shift the zero point of the frequencies calculated by `np.fft.fftfreq` to the same order as numpy arrays or as the output of fftw\n",
    "6. `cs`: `bool` whether to use the speed of sound or chemical potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2sph(x,y,z):\n",
    "    azimuth = np.arctan2(y,x)\n",
    "    elevation = np.arctan2(z,np.sqrt(x**2 + y**2))\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    return r, azimuth, elevation\n",
    "\n",
    "def sph2cart(azimuth,elevation,r):\n",
    "    x = r * np.cos(elevation) * np.cos(azimuth)\n",
    "    y = r * np.cos(elevation) * np.sin(azimuth)\n",
    "    z = r * np.sin(elevation)\n",
    "    return x, y, z\n",
    "\n",
    "def radial_equilibration(data, thermo_model, radius = 1, scale_factor = 1, func = None, cs = True):\n",
    "    S = data.copy()\n",
    "    L = min(S.shape)\n",
    "    freqs = fft.fftshift(fft.fftfreq(L))\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "\n",
    "    r, t, p = cart2sph(kx, ky, kz)\n",
    "\n",
    "    if func is not None:\n",
    "        if cs:\n",
    "            S = func(S, thermo_model.cs2k(kx, ky, kz))\n",
    "        else:\n",
    "            S = func(S, thermo_model.mu_ck(kx, ky, kz))\n",
    "    S /= scale_factor\n",
    "    # S[L//2, L//2, L//2] /= S.sum()\n",
    "    \n",
    "    idxs = np.isclose(r, radius, atol = 2*np.pi/L)\n",
    "    t = t[idxs]\n",
    "    p = p[idxs]\n",
    "    out = S[idxs]\n",
    "\n",
    "    return t, p, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `make_bins`\n",
    "\n",
    "**Input**\n",
    "1. `to_bin1`: `np.array` containing data of a list to be binned\n",
    "2. `binsize`: `int` defining how many size of the output array. `len(to_bin1)/binsize` is the number of points averaged over to generate the output\n",
    "3. `to_bin2`: `np.array` containing a 2nd list to be be binned (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bins(to_bin1, binsize, to_bin2 = None):\n",
    "    bins = np.linspace(to_bin1.min(), to_bin1.max(), binsize)\n",
    "\n",
    "    out1 = np.zeros(binsize)\n",
    "    shell = np.digitize(to_bin1, bins = bins, right = True)\n",
    "    np.add.at(out1, shell, to_bin1)\n",
    "    unique, counts = np.unique(shell, return_counts=True)\n",
    "    out1 = out1[unique]\n",
    "    out1 /= counts\n",
    "\n",
    "    if to_bin2 is None:\n",
    "        return bins, out1\n",
    "    else:\n",
    "        out2 = np.zeros(binsize)\n",
    "        np.add.at(out2, shell, to_bin2)\n",
    "        unique, counts = np.unique(shell, return_counts=True)\n",
    "        out2 = out2[unique]\n",
    "        out2 /= counts\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pressure_tensor`\n",
    "\n",
    "**Input**\n",
    "1. `profile`: `np.array` of shape (nx, ny, nz, 2) containing density and order parameter data in the 0th and 1st index of the last dimension respectively\n",
    "2. `T`: `float` defining a thermodynamic parameter\n",
    "3. `kappa`: `float` defining a thermodynamic parameter related to surface tension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pressure_tensor(profile, T, kappa):\n",
    "    rho = profile[0]\n",
    "    phi = profile[1]\n",
    "    dims = len(rho.shape)\n",
    "\n",
    "    out = np.zeros((*rho.shape, dims, dims))\n",
    "\n",
    "    for i in range(dims):\n",
    "        for j in range(dims):\n",
    "            out[..., i, j] += kappa*np.gradient(rho, axis = i)*np.gradient(rho, axis = j) + kappa*np.gradient(phi, axis = i)*np.gradient(phi, axis = j)\n",
    "            if i == j:\n",
    "\n",
    "                laplacian = rho*np.sum([np.gradient(rho, 2, axis = ax) for ax in range(dims)], axis = 0) + phi*np.sum([np.gradient(phi, 2, axis = ax) for ax in range(dims)], axis = 0)\n",
    "                gradients = np.sum([np.gradient(rho, 1, axis = ax)**2 for ax in range(dims)], axis = 0) + np.sum([np.gradient(phi, 1, axis = ax)**2 for ax in range(dims)], axis = 0)\n",
    "                out[..., i, j] += rho*T - kappa*laplacian - kappa/2*gradients\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pressure_jump`\n",
    "\n",
    "**Input**\n",
    "1. `pressure`: `np.ndarray` of shape `[nx, ny, nz]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pressure_jump(pressure):\n",
    "    nx, ny, nz = pressure.shape\n",
    "    center_slc = np.s_[nx//2-1:nx//2+2, ny//2-1:ny//2+2, nz//2-1:nz//2+2]\n",
    "    edge_slc = np.s_[0:nx:nx-1, 0:ny:ny-1, 0:nz:nz-1]\n",
    "    dP = pressure[center_slc].mean() - pressure[edge_slc].mean()\n",
    "    return dP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pressure_jump`\n",
    "\n",
    "**Input**\n",
    "1. `pressure`: `np.ndarray` of shape `[nx, ny, nz]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_mass(OutArray):\n",
    "    sum = np.sum(OutArray)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `droplet_radius_mass`\n",
    "\n",
    "**Input**\n",
    "1. `density`: `np.ndarray` of shape `[nx, ny, nz]` which holds order parameter data of the droplet\n",
    "2. `Vp`: `float` of particle volume if particles are used\n",
    "3. `np_sphere`: `float` of number of particles if particles are used\n",
    "4. `rho_sphere`: `float` of particle density if particles are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_radius_mass(density, Vp = 0, np_sphere = 0, rho_sphere = 1):\n",
    "    nx, ny, nz = density.shape\n",
    "    center_slc = np.s_[nx//2-1:nx//2+2, ny//2-1:ny//2+2, nz//2-1:nz//2+2]\n",
    "    edge_slc = np.s_[0:nx:nx-1, 0:ny:ny-1, 0:nz:nz-1]\n",
    "    if isinstance(density, int):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # center = tuple([ l//2 for l in density.shape ])\n",
    "        rho_d = density[center_slc].mean()\n",
    "        rho_m = density[edge_slc].mean()\n",
    "        # mass = np.sum(density - rho_m) + 0.5*Vp*np_sphere*rho_sphere\n",
    "        mass = droplet_mass(density - rho_m) + 0.5*Vp*np_sphere*rho_sphere\n",
    "        R = (3./4./np.pi*mass/(rho_d-rho_m))**(1./3.)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `droplet_radius_iso`\n",
    "\n",
    "**Input**\n",
    "1. `density`: `np.ndarray` of shape `[nx, ny, nz]` which holds order parameter data of the droplet\n",
    "2. `level`: `float` of isocontour to calculate radius from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_radius_iso(density, level = None):\n",
    "    if level is None:\n",
    "        level = filters.threshold_otsu(density)\n",
    "    verts, faces, normals, values = measure.marching_cubes(density, level = level)\n",
    "    cm = center_of_mass(density)\n",
    "    ri_s = np.linalg.norm(verts - cm, axis = 1)\n",
    "    R = np.mean(ri_s)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `inertia_tensor`\n",
    "\n",
    "**Input**\n",
    "1. `cm`: `np.ndarray` of size `3` which defines the center of mass of the droplet\n",
    "2. `OutArray`: `np.ndarray` of order parameter data that has been pre-processed such that all other points are 0 except anything defining the droplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inertia_tensor(cm,OutArray):\n",
    "    ind = np.transpose(np.indices(OutArray.shape), axes=(1,2,3,0))\n",
    "    pos = ind - cm\n",
    "    r2 = np.einsum('ijkl,ijkl->ijk',pos,pos)          # inner product\n",
    "    rr = np.einsum('ijkm,ijkn->ijkmn',pos,pos)        # outer product\n",
    "    r2 = np.einsum('ijk,mn->ijkmn',r2,np.identity(3)) # multiply with unit matrix\n",
    "    I = np.einsum('ijk,ijkmn->mn',OutArray,r2-rr)     # sum m*(r2-rr)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `radii_pca`\n",
    "\n",
    "**Input**\n",
    "1. `eigvals`: `np.ndarray` of size `3` which defines the eigenvalues of the intertia tensor\n",
    "2. `mass`: `float` describing the droplet mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radii_pca(eigvals, mass):\n",
    "    a = np.sqrt((5/(2*mass))*(eigvals[1]+eigvals[2]-eigvals[0]))\n",
    "    b = np.sqrt((5/(2*mass))*(eigvals[0]+eigvals[2]-eigvals[1]))\n",
    "    c = np.sqrt((5/(2*mass))*(eigvals[0]+eigvals[1]-eigvals[2]))\n",
    "\n",
    "    return np.array([a, b, c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `gyration_tensor`\n",
    "\n",
    "**Input**\n",
    "1. `cm`: `np.ndarray` of size `3` which defines the center of mass of the droplet\n",
    "2. `OutArray`: `np.ndarray` of order parameter data that has been pre-processed such that all other points are 0 except anything defining the droplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gyration_tensor(cm,OutArray):\n",
    "    ind = np.transpose(np.indices(OutArray.shape), axes=(1,2,3,0))\n",
    "    pos = ind - cm\n",
    "    rr = np.einsum('...m,...n->...mn',pos,pos)\n",
    "    S = np.einsum('ijk,ijk...',OutArray,rr)/np.sum(OutArray)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `droplet_fluctuations`\n",
    "\n",
    "(fluctuations, temp = 1e-7)\n",
    "\n",
    "**Input**\n",
    "1. `fluctuations`: `np.ndarray` of size `[data_size, 3]` which defines the fluctuations of the principle radii of the droplet\n",
    "2. `temp`: `float` of the temperature used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_fluctuations(fluctuations, temp = 1e-7):\n",
    "    sums = 0\n",
    "    difs = 0\n",
    "\n",
    "    for i in range(0, 2):\n",
    "        for j in range(i+1, 3):\n",
    "            sums += np.mean(np.power(fluctuations[:, i] + fluctuations[:, j], 2))\n",
    "            difs += np.mean(np.power(fluctuations[:, i] - fluctuations[:, j], 2))\n",
    "\n",
    "    sums *= 1/3\n",
    "    difs *= 1/3\n",
    "\n",
    "    y20 = 5*temp/(16*np.pi*sums)\n",
    "    y22 = 15*temp/(16*np.pi*difs)\n",
    "\n",
    "    return [y20, y22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneous system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 64\n",
    "boxDims = [L, L, L]\n",
    "use_hdf5 = False\n",
    "\n",
    "chi = 0.4\n",
    "T = 0.25\n",
    "kappa = 0.01\n",
    "kbt = 1e-7\n",
    "\n",
    "rho0 = 1.0\n",
    "phi0 = 0.0\n",
    "thermo_vars = swift_et_al_1996_thermodynamic_model(rho0, phi0, chi, T, kappa)\n",
    "\n",
    "# noise_type = \"spatially_independent\"\n",
    "noise_type = \"spatially_dependent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "# save_dir = \"./\"\n",
    "binsize_avg = 16\n",
    "binsize_radial = 16\n",
    "\n",
    "freqs = fft.fftshift(fft.fftfreq(L))\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if use_hdf5:\n",
    "#     paths = sorted(glob.glob(f\"{save_dir}/hydro*.h5\"))[1:]\n",
    "\n",
    "#     S_rho = np.zeros(([L]*3), dtype = complex)\n",
    "#     S_phi = np.zeros([L]*3, dtype = complex)\n",
    "#     S_v = np.zeros((*[L]*3,3,3), dtype = complex)\n",
    "\n",
    "#     for i, h5_filepath in enumerate(paths):\n",
    "#         conserved_moments = extract_data(h5_filepath, boxDims, begin = 0, end = 5, nVars = 38)\n",
    "\n",
    "#         var = conserved_moments[0]\n",
    "#         vark = fft.fftn(var)\n",
    "#         S_rho += vark*np.conj(vark)\n",
    "\n",
    "#         var = conserved_moments[1]\n",
    "#         vark = fft.fftn(var)\n",
    "#         S_phi += vark*np.conj(vark)\n",
    "\n",
    "#         var = conserved_moments[2:]\n",
    "#         vark = fft.fftn(var, axes = [1, 2, 3])\n",
    "#         S_v += np.einsum('i..., j...->...ij',vark, np.conj(vark))\n",
    "\n",
    "\n",
    "#     S_rho /= (len(paths)*L**3*kbt)\n",
    "#     S_phi /= (len(paths)*L**3*kbt)\n",
    "#     S_v /= (len(paths)*L**3*kbt)\n",
    "\n",
    "#     data_rho = [S_rho.real]\n",
    "#     data_phi = [S_phi.real]\n",
    "#     data_v = [S_v[..., 0, 0].real, S_v[..., 1, 1].real, S_v[..., 2, 2].real]\n",
    "# else:\n",
    "#     ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "#     ds = ts[-1]\n",
    "#     ad = ds.all_data()\n",
    "\n",
    "#     data_rho = [np.array(ad[('boxlib', 'struct_fact_density_density')]).reshape(boxDims)/kbt]\n",
    "#     data_phi = [np.array(ad[('boxlib', 'struct_fact_phi_phi')]).reshape(boxDims)/kbt]\n",
    "#     data_v = [np.array(ad[('boxlib', 'struct_fact_ux_ux')]).reshape(boxDims)/kbt, \n",
    "#               np.array(ad[('boxlib', 'struct_fact_uy_uy')]).reshape(boxDims)/kbt,\n",
    "#               np.array(ad[('boxlib', 'struct_fact_uz_uz')]).reshape(boxDims)/kbt]\n",
    "\n",
    "#     # ds.field_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_independent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_rho = [np.array(ad[('boxlib', 'struct_fact_density_density')]).reshape(boxDims)/kbt]\n",
    "\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_rho\n",
    "experiment_muck = thermo_vars.cs2k(kx, ky, kz)\n",
    "\n",
    "test = data[0].copy()\n",
    "# test /= kbt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "ax = axs[0]\n",
    "test *= (experiment_muck)\n",
    "# test[slc] /= test.sum()\n",
    "im = ax.imshow(test[L//2, :, :])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.imshow(test[:, L//2, :])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(test[:, :, L//2])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc = np.s_[L//2, L//2, L//2]\n",
    "\n",
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$\\rho$\"]\n",
    "\n",
    "rho_scale = lambda a, c: a*c\n",
    "scale_factor = 1\n",
    "\n",
    "for d in data:\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = 1, func = rho_scale)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[0], color = colors[0],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[0])\n",
    "\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim([0.95, 1.065])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/rho-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1.5, 2.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "\n",
    "# rho_scale = None\n",
    "# scale_factor = 1/cs2\n",
    "\n",
    "for d in data:\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        # t, p, sf = radial_equilibration(d, rho0, phi0, radius = r, func=rho_scale, scale_factor = scale_factor)\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r, func=rho_scale, scale_factor = scale_factor)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "    ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", va = \"bottom\", ha = 'right', fontsize = 14, rotation = 'horizontal')\n",
    "    ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig(f\"./{figures}/rho-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/rho-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_dependent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_rho = [np.array(ad[('boxlib', 'struct_fact_density_density')]).reshape(boxDims)/kbt]\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_rho\n",
    "experiment_muck = thermo_vars.cs2k(kx, ky, kz)\n",
    "\n",
    "test = data[0].copy()\n",
    "# test /= kbt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "ax = axs[0]\n",
    "test *= (experiment_muck)\n",
    "# test[slc] /= test.sum()\n",
    "im = ax.imshow(test[L//2, :, :])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.imshow(test[:, L//2, :])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(test[:, :, L//2])\n",
    "plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc = np.s_[L//2, L//2, L//2]\n",
    "\n",
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$\\rho$\"]\n",
    "\n",
    "rho_scale = lambda a, c: a*c\n",
    "scale_factor = 1\n",
    "\n",
    "for d in data:\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = 1, func = rho_scale)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[0], color = colors[0],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[0])\n",
    "\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim([0.95, 1.05])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/rho-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1.5, 2.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "binsize_temp = 16\n",
    "\n",
    "# rho_scale = None\n",
    "# scale_factor = 1/cs2\n",
    "\n",
    "for d in data:\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        # t, p, sf = radial_equilibration(d, rho0, phi0, radius = r, func=rho_scale, scale_factor = scale_factor)\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r, func=rho_scale, scale_factor = scale_factor)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "    ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | \\rho(k) | ^2 \\rangle }{S(k)}$\", va = \"bottom\", ha = 'right', fontsize = 14, rotation = 'horizontal')\n",
    "    ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig(f\"./{figures}/rho-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/rho-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_independent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_phi = [np.array(ad[('boxlib', 'struct_fact_phi_phi')]).reshape(boxDims)/kbt]\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_phi\n",
    "\n",
    "# freqs = fft.fftshift(fft.fftfreq(L))\n",
    "# kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "# k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "experiment_muck = thermo_vars.mu_ck(kx, ky, kz)\n",
    "\n",
    "test = data[0].copy()\n",
    "# test[slc] = (test.sum() - test[slc])/(L**3)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "ax = axs[0]\n",
    "# test[slc] = (test.sum() - test[slc])/32**3\n",
    "test *= (experiment_muck)\n",
    "# test /= kbt\n",
    "im = ax.imshow(test[L//2, :, :])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.imshow(test[:, L//2, :])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(test[:, :, L//2])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$\\phi$\"]\n",
    "\n",
    "rho_func = lambda a, c: a*c\n",
    "scale_factor = 1\n",
    "\n",
    "for d in data:\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = scale_factor, func = rho_func, cs = False)\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[0], color = colors[0],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[0])\n",
    "\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "# print(x, y)\n",
    "# ax.set_ylim([0.9, 1.1])\n",
    "ax.set_ylim([0.95, 1.055])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/phi-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1.5, 2.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "binsize_temp = 16\n",
    "\n",
    "# rho_scale = None\n",
    "# scale_factor = 1/cs2\n",
    "\n",
    "for d in data:\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r, func=rho_scale, scale_factor = scale_factor, cs = False)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "    ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", va = \"bottom\", ha = 'right', fontsize = 14, rotation = 'horizontal')\n",
    "    ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig(f\"./{figures}/phi-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/phi-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_dependent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_phi = [np.array(ad[('boxlib', 'struct_fact_phi_phi')]).reshape(boxDims)/kbt]\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_phi\n",
    "\n",
    "# freqs = fft.fftshift(fft.fftfreq(L))\n",
    "# kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "# k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "experiment_muck = thermo_vars.mu_ck(kx, ky, kz)\n",
    "\n",
    "test = data[0].copy()\n",
    "# test[slc] = (test.sum() - test[slc])/(L**3)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "\n",
    "ax = axs[0]\n",
    "# test[slc] = (test.sum() - test[slc])/32**3\n",
    "test *= (experiment_muck)\n",
    "# test /= kbt\n",
    "im = ax.imshow(test[L//2, :, :])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.imshow(test[:, L//2, :])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(test[:, :, L//2])\n",
    "plt.colorbar(im, ax = ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$\\phi$\"]\n",
    "\n",
    "rho_func = lambda a, c: a*c\n",
    "scale_factor = 1\n",
    "\n",
    "for d in data:\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = scale_factor, func = rho_func, cs = False)\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[0], color = colors[0],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[0])\n",
    "\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "# print(x, y)\n",
    "ax.set_ylim([0.95, 1.05])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/phi-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1.5, 2.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "\n",
    "# rho_scale = None\n",
    "# scale_factor = 1/cs2\n",
    "\n",
    "for d in data:\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r, func=rho_scale, scale_factor = scale_factor, cs = False)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", fontsize = 14)\n",
    "    ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | \\phi(k) | ^2 \\rangle }{S(k)}$\", va = \"bottom\", ha = 'right', fontsize = 14, rotation = 'horizontal')\n",
    "    ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig(f\"./{figures}/phi-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/phi-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_independent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_v = [np.array(ad[('boxlib', 'struct_fact_ux_ux')]).reshape(boxDims)/kbt, \n",
    "          np.array(ad[('boxlib', 'struct_fact_uy_uy')]).reshape(boxDims)/kbt,\n",
    "          np.array(ad[('boxlib', 'struct_fact_uz_uz')]).reshape(boxDims)/kbt]\n",
    "\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_v\n",
    "slc_s = [np.s_[L//2, :, :], np.s_[:, L//2, :], np.s_[:, :, L//2]]\n",
    "labels = ['yz', 'xz', 'xy']\n",
    "fig, axs = plt.subplots(3, 3, figsize = (9, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    d = data[i].copy()\n",
    "    # d /= kbt\n",
    "    # d[slc] = (d.sum() - d[slc])/(L**3)\n",
    "    for j in range(3):\n",
    "        ax = axs[i, j]\n",
    "        im = ax.imshow(d[slc_s[j]], vmin = 0.8, vmax = 1.2)\n",
    "        plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "        ax.set_title(f\"$S_{{u_{chr(120+i)}u_{chr(120+i)}}}$ {labels[j]}\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "binsize = 8\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$u_x$\", r\"$u_y$\", r\"$u_z$\"]\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = 1)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN\n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[i], color = colors[i],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[i])\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | u_{\\alpha}(k) | ^2 \\rangle }{\\rho_{0}k_b T}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim([0.95, 1.05])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/vel-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "# fig1, tax = plt.subplots(1, 3, figsize = (sz*3, sz), subplot_kw={'projection': 'polar'})\n",
    "# fig2, pax = plt.subplots(1, 3, figsize = (sz*3, sz), subplot_kw={'projection': 'polar'})\n",
    "data = data_v[:1]\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1, 1.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "\n",
    "for j, d in enumerate(data):\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        # t, p, sf = radial_equilibration(d, rho0, phi0, radius = r)\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | u_{x} | ^2 \\rangle }{\\rho_0 k_B T}$\", fontsize = 14)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | u_{x} | ^2 \\rangle }{\\rho_0 k_B T}$\", fontsize = 14, ha = 'right', va = \"top\", rotation = 'horizontal')\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "\n",
    "fig1.savefig(f\"./{figures}/vel-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/vel-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatially dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = \"spatially_dependent\"\n",
    "save_dir = f\"validation/equilibration_tests/{noise_type}\"\n",
    "ts = yt.load(f\"{save_dir}/SF_plt_mag*\")\n",
    "ds = ts[-1]\n",
    "ad = ds.all_data()\n",
    "\n",
    "data_v = [np.array(ad[('boxlib', 'struct_fact_ux_ux')]).reshape(boxDims)/kbt, \n",
    "          np.array(ad[('boxlib', 'struct_fact_uy_uy')]).reshape(boxDims)/kbt,\n",
    "          np.array(ad[('boxlib', 'struct_fact_uz_uz')]).reshape(boxDims)/kbt]\n",
    "\n",
    "if \"in\" in noise_type:\n",
    "    kx, ky, kz = [0, 0, 0]\n",
    "else:\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_v\n",
    "slc_s = [np.s_[L//2, :, :], np.s_[:, L//2, :], np.s_[:, :, L//2]]\n",
    "labels = ['yz', 'xz', 'xy']\n",
    "fig, axs = plt.subplots(3, 3, figsize = (9, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    d = data[i].copy()\n",
    "    # d /= kbt\n",
    "    # d[slc] = (d.sum() - d[slc])/(L**3)\n",
    "    for j in range(3):\n",
    "        ax = axs[i, j]\n",
    "        im = ax.imshow(d[slc_s[j]], vmin = 0.8, vmax = 1.2)\n",
    "        plt.colorbar(im, ax = ax, shrink = 0.8)\n",
    "        ax.set_title(f\"$S_{{u_{chr(120+i)}u_{chr(120+i)}}}$ {labels[j]}\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = 1.25\n",
    "sz = figheight\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "labels = [r\"$u_x$\", r\"$u_y$\", r\"$u_z$\"]\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "        currData = d.copy()\n",
    "        # currData /= kbt\n",
    "        x, y = spherically_averaged_structure_factor(currData, thermo_vars, scale_factor = 1)\n",
    "        # y[0] = 1\n",
    "        y[0] = np.NaN        \n",
    "        x, y = make_bins(x, binsize_avg, to_bin2 = y)\n",
    "\n",
    "        ax.plot(x, y, \n",
    "                marker = markers[i], color = colors[i],\n",
    "                markerfacecolor = \"None\", markersize = 10, \n",
    "                linestyle = \"None\", label = labels[i])\n",
    "ax.plot(x, [1]*x.size, 'lime', lw = 2)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 14)\n",
    "ax.set_ylabel(r\"$\\frac{ \\langle | u_{\\alpha}(k) | ^2 \\rangle }{\\rho_{0}k_b T}$\", fontsize = 14)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim([0.95, 1.05])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/vel-ER-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = figheight\n",
    "# fig1, tax = plt.subplots(1, 3, figsize = (sz*3, sz), subplot_kw={'projection': 'polar'})\n",
    "# fig2, pax = plt.subplots(1, 3, figsize = (sz*3, sz), subplot_kw={'projection': 'polar'})\n",
    "data = data_v[:1]\n",
    "fig1, tax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "fig2, pax = plt.subplots(1, 1, figsize = (sz, sz), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "colors = ['b', \"r\", \"k\"]\n",
    "markers = [\"o\", \"s\", '^']\n",
    "\n",
    "radii = [0.5, 1, 1.5]\n",
    "\n",
    "t_angle = 0\n",
    "p_angle = 0 \n",
    "\n",
    "for j, d in enumerate(data):\n",
    "    ax1 = tax\n",
    "    ax2 = pax\n",
    "\n",
    "    currData = d.copy()\n",
    "    # currData /= kbt\n",
    "    for i, r in enumerate(radii):\n",
    "        # t, p, sf = radial_equilibration(d, rho0, phi0, radius = r)\n",
    "        t, p, sf = radial_equilibration(currData, thermo_vars, radius = r)\n",
    "\n",
    "        idxs = np.isclose(np.abs(t), t_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(p)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax1.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "        idxs = np.isclose(np.abs(p), p_angle/180*np.pi, atol = np.pi/L)\n",
    "        angles = np.abs(t)[idxs]\n",
    "        segment = sf[idxs]\n",
    "        angles, segment =  make_bins(angles, binsize_radial, to_bin2 = segment)\n",
    "        ax2.plot(angles, segment, color = colors[i], label = f\"R = {r}\",lw = 2)\n",
    "\n",
    "    ax1.set_rticks([0.5, 1.0])\n",
    "    ax1.set_thetalim([0, np.pi/2])\n",
    "    ax1.set_ylabel(r\"$\\frac{ \\langle | u_{x} | ^2 \\rangle }{\\rho_0 k_B T}$\", fontsize = 14)\n",
    "    # ax1.set_title(r\"$\\theta = {{{0}}}^{{\\circ}}$\".format(t_angle))\n",
    "\n",
    "    ax2.set_rticks([0.5, 1.0])\n",
    "    ax2.set_thetalim([0, np.pi])\n",
    "    ax2.set_ylabel(r\"$\\frac{ \\langle | u_{x} | ^2 \\rangle }{\\rho_0 k_B T}$\", fontsize = 14, ha = 'right', va = \"top\", rotation = 'horizontal')\n",
    "    # ax2.set_title(r\"$\\psi = {{{0}}}^{{\\circ}}$\".format(p_angle))\n",
    "\n",
    "ax1.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "ax2.legend(loc = 'upper right', bbox_to_anchor=(1.1, 1.1), fancybox=True)\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "\n",
    "fig1.savefig(f\"./{figures}/vel-ER-{noise_type}-polar.png\", dpi = 300)\n",
    "fig2.savefig(f\"./{figures}/vel-ER-{noise_type}-azimuth.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure compositing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent composited figure\n",
    "# %%capture\n",
    "fig, axs = plt.subplots(2, 3, figsize=(3*figheight, 2*figheight))\n",
    "\n",
    "noise_type = \"spatially_independent\"\n",
    "ordering = ['rho', 'phi', 'vel']\n",
    "\n",
    "downsize = 2\n",
    "for i, ax in enumerate(axs[0]):\n",
    "    pic_path = f\"{figures}/{ordering[i]}-ER-{noise_type}-avg.png\"\n",
    "    img = iio.imread(pic_path)\n",
    "    if downsize is not None:\n",
    "        img = ski.transform.resize(img, (img.shape[0]//downsize, img.shape[1]//downsize), anti_aliasing=True)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.0, 0.9, f\"({chr(97+i)})\", transform=ax.transAxes)\n",
    "\n",
    "paths = [f\"{figures}/rho-ER-{noise_type}-polar.png\", f\"{figures}/phi-ER-{noise_type}-polar.png\", f\"{figures}/vel-ER-{noise_type}-polar.png\"]\n",
    "\n",
    "for i, ax in enumerate(axs[1]):\n",
    "    pic_path = paths[i]\n",
    "    # print(pic_path)\n",
    "    img = iio.imread(pic_path)\n",
    "    if downsize is not None:\n",
    "        img = ski.transform.resize(img, (img.shape[0]//downsize, img.shape[1]//downsize), anti_aliasing=True)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.0, 0.9, f\"({chr(97+3+i)})\", transform=ax.transAxes)\n",
    "\n",
    "fig.subplots_adjust(wspace=-0.1, hspace=0)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figures}/{noise_type}-summary.png\", dpi=DPI)#, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependent composited figure\n",
    "# %%capture\n",
    "fig, axs = plt.subplots(2, 3, figsize=(3*figheight, 2*figheight))\n",
    "\n",
    "noise_type = \"spatially_dependent\"\n",
    "ordering = ['rho', 'phi', 'vel']\n",
    "\n",
    "downsize = None\n",
    "for i, ax in enumerate(axs[0]):\n",
    "    pic_path = f\"{figures}/{ordering[i]}-ER-{noise_type}-avg.png\"\n",
    "    img = iio.imread(pic_path)\n",
    "    if downsize is not None:\n",
    "        img = ski.transform.resize(img, (img.shape[0]//downsize, img.shape[1]//downsize), anti_aliasing=True)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.0, 0.9, f\"({chr(97+i)})\", transform=ax.transAxes)\n",
    "\n",
    "paths = [f\"{figures}/rho-ER-{noise_type}-polar.png\", f\"{figures}/phi-ER-{noise_type}-polar.png\", f\"{figures}/vel-ER-{noise_type}-polar.png\"]\n",
    "\n",
    "for i, ax in enumerate(axs[1]):\n",
    "    pic_path = paths[i]\n",
    "    # print(pic_path)\n",
    "    img = iio.imread(pic_path)\n",
    "    if downsize is not None:\n",
    "        img = ski.transform.resize(img, (img.shape[0]//downsize, img.shape[1]//downsize), anti_aliasing=True)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.0, 0.9, f\"({chr(97+3+i)})\", transform=ax.transAxes)\n",
    "\n",
    "fig.subplots_adjust(wspace=-0.1, hspace=0)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figures}/{noise_type}-summary.png\", dpi=DPI)#, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfacial fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 256\n",
    "ny = 1\n",
    "nz = 2048\n",
    "noise_type = \"spatially_independent\"\n",
    "# noise_type = \"spatially_dependent\"\n",
    "savedir = f\"./validation/interface/{noise_type}\"\n",
    "\n",
    "# nx = 64\n",
    "# ny = 2\n",
    "# nz = 512\n",
    "# savedir = \"./\"\n",
    "\n",
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "kappa = 0.03\n",
    "kbt = 1e-7\n",
    "u0 = 0\n",
    "cs2 = 1/3\n",
    "gamma = 1.0\n",
    "\n",
    "chi = 0.5\n",
    "T = 0.2\n",
    "\n",
    "idx = -1\n",
    "\n",
    "output_file = \"hydro_plt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "# profile = extract_data(savedir + sorted(glob.glob(\"./*.h5\"))[-1], [nx, ny, nz], begin = 1, end = 2, nVars = 38)\n",
    "path = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[idx]\n",
    "profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38)\n",
    "\n",
    "# ts = yt.load(f\"{savedir}/{output_file}*\")\n",
    "# ds = ts[-1]\n",
    "# ad = ds.all_data()\n",
    "# profile = np.array([np.array(ad[('boxlib', 'density')]).reshape(boxDim), np.array(ad[('boxlib', 'phi')]).reshape(boxDim)])\n",
    "\n",
    "phi0 = newton(fb, x0 = (0.6), args = (chi, T))\n",
    "xi = np.sqrt((0.142*kappa)/((chi/2 - T)-0.31*T*(phi0**2)))\n",
    "# phi0 = np.sqrt((3*(chi/2 - T))/(2*T))\n",
    "# xi = 4*np.sqrt(kappa*(chi/2 - T))\n",
    "fit_func = lambda x, b:phi0*np.tanh((x - b)/(np.sqrt(2)*xi))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize = (8, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "ax = axs[0]\n",
    "im = ax.imshow(profile[0, :, : , nz//2])\n",
    "ax.set_xlabel(\"y\")\n",
    "ax.set_ylabel(\"x\")\n",
    "plt.colorbar(im, ax = ax, label = r\"$\\rho$\")\n",
    "\n",
    "ax = axs[1]\n",
    "x = np.arange(nx//4, 3*nx//4, 1)\n",
    "im = ax.plot(x, profile[0, nx//4:3*nx//4, ny//2 , nz//2], 'rx', label = \"profile\")\n",
    "# ax.plot(x, np.ones(x.size), 'ko', label = \"reference\", markerfacecolor=\"None\")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(r\"$\\rho$\")\n",
    "ax.legend(ncol = 1, fontsize = 'small')\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(profile[1, :, : , nz//2])\n",
    "ax.set_xlabel(\"y\")\n",
    "ax.set_ylabel(\"x\")\n",
    "plt.colorbar(im, ax = ax, label = r\"$\\phi$\")\n",
    "\n",
    "ax = axs[3]\n",
    "x = np.arange(nx//4, 3*nx//4, 1)\n",
    "im = ax.plot(x, profile[1, nx//4:3*nx//4, ny//2 , nz//2], 'rx', label = \"profile\")\n",
    "\n",
    "x = np.linspace(0, nx - 1, nx)\n",
    "# b = -(chi**2.350)/(kappa**0.640 * T**5.559*489.435)\n",
    "# b = \n",
    "# y = newton(fb, x0 = (0.6), args = (chi, T))*np.tanh(b*(x - (nx - 1)/2))\n",
    "y = fit_func(x, (nx - 1)/2)\n",
    "ax.plot(x, y, 'ko', label = \"referece\", markerfacecolor=\"None\")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "ax.legend(ncol = 1, fontsize = 'small')\n",
    "\n",
    "t = int(path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "fig.suptitle(f\"$\\kappa$ = {kappa}, $\\chi = {chi}, T = {T}, t = {t}$\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlo = nx//4\n",
    "xhi = 3*nx//4\n",
    "intLoc = (nx - 1)/2\n",
    "\n",
    "yraw = profile[1, :, 0, nz//2]\n",
    "\n",
    "## Raw data ##\n",
    "plt.plot(yraw, 'rx', label = 'raw data')\n",
    "## Raw data ##\n",
    "\n",
    "## tanh fit ##\n",
    "phi0 = newton(fb, x0 = (0.6), args = (chi, T))\n",
    "xi = np.sqrt((0.142*kappa)/((chi/2 - T)-0.31*T*(phi0**2)))\n",
    "# phi0 = np.sqrt((3*(chi/2 - T))/(2*T))\n",
    "# xi = 4*np.sqrt(np.sqrt(2)*kappa*(chi/2 - T))\n",
    "\n",
    "xfit1 = np.arange(xlo, xhi, 1)\n",
    "fit_func = lambda x, b:phi0*np.tanh((x - b)/(np.sqrt(2)*xi))\n",
    "popt, pcov = curve_fit(fit_func, xfit1, yraw[xlo:xhi], p0 = (intLoc))\n",
    "yfit1 = fit_func(xfit1, *popt)\n",
    "intHeight_prof = popt[0]\n",
    "plt.plot(xfit1, yfit1, 'b--', label = \"tanh fit\", lw = 0.6)\n",
    "plt.plot(intHeight_prof, 0, 'bo', ms = 8)\n",
    "## tanh fit ##\n",
    "\n",
    "## direct fit ##\n",
    "xslc = [int(np.floor(intLoc)), int(np.ceil(intLoc))]\n",
    "yslc = [yraw[xslc[0]], yraw[xslc[1]]]\n",
    "plt.plot(xslc, yslc, linestyle = '-', marker = \"None\", color = 'tab:orange', label = 'direct fit', lw = 1)\n",
    "intHeight_dir = np.roots(np.polyfit(xslc, yslc, 1))[0]\n",
    "plt.plot(intHeight_dir, 0, marker = \"o\", color = \"tab:orange\", ms = 8)\n",
    "## direct fit ##\n",
    "\n",
    "plt.ylabel(r\"$\\phi$\")\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.title(\"Fluctuations on\")\n",
    "plt.legend()\n",
    "plt.xlim([123, 133])\n",
    "\n",
    "print(f\"profile fit:{intHeight_prof:.3f}, direct fit:{intHeight_dir:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[1]\n",
    "profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38)\n",
    "\n",
    "methods = [\"direct\", \"profile_fit\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (5, 4))\n",
    "\n",
    "colors = ['tab:orange', 'black']\n",
    "ls = []\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    h = interface_height(profile[1], chi, T, kappa, method = method)\n",
    "    h = np.mean(h, axis = 0)\n",
    "    ax.plot(h, label = method, color = colors[i])\n",
    "    ls.append(h)\n",
    "\n",
    "ax.set_ylabel(\"Height fluctuations\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"direct\"\n",
    "fft_mode = 'ortho'\n",
    "\n",
    "# method = \"profile_fit\"\n",
    "# fft_mode = 'ortho'\n",
    "\n",
    "heights_k = np.zeros((nz), dtype = np.complex128)\n",
    "# h5_paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[102:]\n",
    "data_paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[1:102]\n",
    "\n",
    "# data_paths = yt.load(f\"{savedir}/{output_file}*\")[1:]\n",
    "# ds = ts[-1]\n",
    "# ad = ds.all_data()\n",
    "# profile = np.array([np.array(ad[('boxlib', 'density')]).reshape(boxDim), np.array(ad[('boxlib', 'phi')]).reshape(boxDim)])\n",
    "\n",
    "\n",
    "for path in data_paths:\n",
    "    phi = extract_data(path, boxDim, begin = 1, end = 2, nVars = 38)[0]\n",
    "    # ad = path.all_data()\n",
    "    # phi = np.array(ad[('boxlib', 'phi')]).reshape(boxDim)\n",
    "    \n",
    "    h = interface_height(phi, chi, T, kappa, method = method)[0]*np.sqrt(2)\n",
    "    \n",
    "    h_k = fft.fft(h, norm = fft_mode)\n",
    "\n",
    "    heights_k += h_k*h_k.conjugate()\n",
    "    # t = int(path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "    # print(f\"Timestep {t} processed\")\n",
    "\n",
    "heights_k = np.abs(heights_k)\n",
    "heights_k /= len(data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPERIMENTAL RESULTS ##\n",
    "L = nz\n",
    "k1 = fft.fftfreq(L)*2*np.pi\n",
    "S1 = heights_k.copy()\n",
    "\n",
    "slc = slice(1, L//2)\n",
    "xraw = k1[slc]\n",
    "yraw = S1[slc]\n",
    "\n",
    "binsize = L//4\n",
    "kmin = 2*np.pi/binsize\n",
    "bins = np.arange(binsize//2+1)*kmin # kmax+1 for bin_edges: len(bins)=len(hist)+1\n",
    "shells = np.histogram(k1[slc], bins, weights=S1[slc])[0]\n",
    "counts = np.histogram(k1[slc], bins)[0]\n",
    "\n",
    "xbin = (bins[:-1]+bins[1:])/2\n",
    "ybin = shells/counts\n",
    "## EXPERIMENTAL RESULTS ##\n",
    "\n",
    "## THEORETICAL RESULTS ##\n",
    "sigma = 0.0172\n",
    "freqs_theory = np.linspace(xraw[0], xraw[-1], 1001)\n",
    "interface_fluct_theory = kbt/(sigma*np.power(freqs_theory, 2))\n",
    "## THEORETICAL RESULTS ##\n",
    "\n",
    "sz = figheight\n",
    "ar = 1.25\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "# ax.loglog(xraw, yraw, \"ks\", label = \"Simulation raw\", ms = 5, markerfacecolor = \"None\")\n",
    "ax.loglog(xbin, ybin, \"bo\", label = \"Simulation\", ms = 3)\n",
    "ax.loglog(freqs_theory, interface_fluct_theory, 'r-', lw = 2, label = \"Theory\")\n",
    "\n",
    "ax.set_xlim(left = 1e-2)\n",
    "ax.set_xlabel(r\"$k$\", fontsize = 15)\n",
    "ax.set_ylabel(r\"$\\langle |h(k)|^2 \\rangle$\", fontsize = 15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "ax.legend(fontsize = 12, loc = 'lower left')\n",
    "# # ax.set_title(f\"L = {nz}\")\n",
    "# ax.set_title(f\"{method}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figures}/interface_height_flucuations-{noise_type}.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droplet fluctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources\n",
    "1. [Simulation of FUS Protein Condensates with an adapted coarse grained model](https://pubs.acs.org/doi/10.1021/acs.jctc.0c01064)\n",
    "2. [Effect of nanoparticles and surfactants on droplets in shear flows](https://doi.org/10.1039/C2SM25209K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Young Laplace fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 64\n",
    "ny = 64\n",
    "nz = 64\n",
    "\n",
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "chi = 0.5\n",
    "T = 0.2\n",
    "kappa = 0.03\n",
    "kbt = 1e-7\n",
    "\n",
    "u0 = 0\n",
    "cs2 = 1/3\n",
    "gamma = 1.0\n",
    "\n",
    "idx = -1\n",
    "savedir = f\"./validation/droplet_fluctuations/young_laplace\"\n",
    "# R_s = [\"0.2\", \"0.25\", \"0.3\", \"0.35\"]\n",
    "R_s = [\"0.25\", \"0.3\", \"0.35\"]\n",
    "output_file = \"hydro_plt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0\n",
    "\n",
    "all_radii = []\n",
    "all_times = []\n",
    "all_press = []\n",
    "\n",
    "for R in R_s:\n",
    "    paths = sorted(glob.glob(f\"{savedir}/R_{R}/{output_file}*.h5\"))\n",
    "\n",
    "    curr_radii = np.zeros(len(paths))    \n",
    "    curr_times = np.zeros(len(paths))\n",
    "    curr_press = np.zeros(len(paths))\n",
    "    for i, path in enumerate(paths):\n",
    "        t = int(path.split(\"_\")[-1].split(\".\")[0])    \n",
    "        curr_times[i] = t\n",
    "\n",
    "        profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38)\n",
    "\n",
    "        curr_radii[i] = droplet_radius_mass(profile[1])\n",
    "\n",
    "        pressure = pressure_tensor(profile, T, kappa)\n",
    "        scalar_pressure = np.einsum('ijkmn,mn->ijk',pressure,np.identity(boxDim.size))/3\n",
    "        curr_press[i] = pressure_jump(scalar_pressure)\n",
    "        \n",
    "    \n",
    "    all_radii.append(curr_radii)\n",
    "    all_times.append(curr_times)\n",
    "    all_press.append(curr_press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 4\n",
    "ar = 1.25\n",
    "fig, axs = plt.subplots(1, 2, figsize = (sz*ar*2, sz))\n",
    "axs2 = [ax.twinx() for ax in axs]\n",
    "\n",
    "cols = ['r', 'b', 'k', 'g']\n",
    "markers = ['s', 'o', '^', '*']\n",
    "linestyles = ['-', '--', ':', 'dashdot']\n",
    "\n",
    "for i, R in enumerate(R_s):\n",
    "    x = all_times[i]\n",
    "    y = all_radii[i]\n",
    "    y2 = all_press[i]\n",
    "    if len(x) > 1:\n",
    "        plotx = x[1:]\n",
    "        ploty = y[1:]\n",
    "        ploty2 = y2[1:]\n",
    "\n",
    "        ax = axs[0]\n",
    "        ax.plot(plotx, ploty, label = f'R = {R}', marker = markers[i], linestyle = \"None\", color = cols[i], markerfacecolor = \"None\", ms = 8)\n",
    "\n",
    "        ax2 = axs2[0]\n",
    "        ax2.plot(plotx, ploty2, label = f'R = {R}', marker = \"None\", linestyle = linestyles[i], color = cols[i], markerfacecolor = \"None\", ms = 8)\n",
    "\n",
    "        ax = axs[1]\n",
    "        ploty = (ploty - ploty.min())/(ploty.max() - ploty.min())\n",
    "        ax.plot(plotx, ploty, label = f'R = {R}', marker = markers[i], linestyle = \"None\", color = cols[i], markerfacecolor = \"None\", ms = 8)\n",
    "\n",
    "        ax2 = axs2[1]\n",
    "        ploty = (ploty2 - ploty2.min())/(ploty2.max() - ploty2.min())\n",
    "        ax2.plot(plotx, ploty, label = f'R = {R}', marker = \"None\", linestyle = linestyles[i], color = cols[i], markerfacecolor = \"None\", ms = 8)\n",
    "    \n",
    "ax = axs[0]\n",
    "\n",
    "ax.set_xlabel(\"Timesteps\")\n",
    "ax.set_ylabel(r\"$R$\")\n",
    "ax.set_xscale(\"log\")\n",
    "# ax.legend(loc = 'center right')\n",
    "\n",
    "ax2 = axs2[0]\n",
    "ax2.set_ylabel(r\"$\\Delta P$\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_xlabel(\"Timesteps\")\n",
    "ax.set_ylabel(r\"$\\frac{R - R_{min}}{R_{max} - R_{min}}$\")\n",
    "ax.set_xscale(\"log\")\n",
    "# ax.legend(loc = 'center right')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "\n",
    "ax2 = axs2[1]\n",
    "ax2.set_ylabel(r\"$\\frac{\\Delta P - \\Delta P_{min}}{\\Delta P_{max} - \\Delta P_{min}}$\")\n",
    "\n",
    "\n",
    "fig.suptitle(\"Droplet radius evolution over time\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "young_laplace = lambda x, sigma: sigma*x\n",
    "\n",
    "xraw = []\n",
    "yraw = []\n",
    "for i in range(len(R_s)):\n",
    "    ls = all_radii[i]\n",
    "    if len(ls) > 1:\n",
    "        xraw.append(2/all_radii[i][-1])\n",
    "        yraw.append(all_press[i][-1])\n",
    "\n",
    "sz = figheight\n",
    "ar = 1.25\n",
    "fig, ax = plt.subplots(1, 1, figsize = (sz*ar, sz))\n",
    "\n",
    "ax.plot(xraw, yraw, 'bo', ms = 8, linestyle = \"None\", label = \"Raw data\", markerfacecolor = \"None\")\n",
    "\n",
    "popt, pcov = curve_fit(young_laplace, xraw, yraw, p0 = [0.0170])\n",
    "xfit = np.linspace(min(xraw), max(xraw), 101)\n",
    "yfit = young_laplace(xfit, *popt)\n",
    "ax.plot(xfit, yfit, 'r-', lw = 1, label = \"Fit data\")\n",
    "\n",
    "ax.text(0.12, 0.002, r\"$\\sigma$=\"+f\"{popt[0]:.4f}\", fontsize = 12)\n",
    "ax.set_ylabel(r\"$\\Delta P$\", fontsize = 15)\n",
    "ax.set_xlabel(r\"$\\frac{2}{R_d}$\", fontsize = 15)\n",
    "# ax.set_title(f\"$\\chi$={chi}, $T$={T}, $\\kappa$={kappa}\", fontsize = 18)\n",
    "# ax.legend(fontsize = 12)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figures}/young_laplace_sigma.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluctuations of droplet shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 64\n",
    "ny = 64\n",
    "nz = 64\n",
    "\n",
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "kappa = 0.03\n",
    "kbt = 1e-7\n",
    "u0 = 0\n",
    "cs2 = 1/3\n",
    "gamma = 1.0\n",
    "\n",
    "chi = 0.5\n",
    "T = 0.2\n",
    "\n",
    "idx = 50\n",
    "\n",
    "# noise_type = \"spatially_dependent\"\n",
    "noise_type = \"spatially_independent\"\n",
    "savedir = f\"./validation/droplet_fluctuations/{noise_type}\"\n",
    "output_file = \"hydro_plt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxDim = np.array([nx, ny, nz])\n",
    "\n",
    "path = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[idx]\n",
    "profile = extract_data(path, boxDim, begin = 0, end = 2, nVars = 38)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize = (8, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "ax = axs[0]\n",
    "im = ax.imshow(profile[0, :, : , nz//2])\n",
    "ax.set_xlabel(\"y\")\n",
    "ax.set_ylabel(\"x\")\n",
    "plt.colorbar(im, ax = ax, label = r\"$\\rho$\")\n",
    "\n",
    "ax = axs[1]\n",
    "x = np.arange(0, nx, 1)\n",
    "im = ax.plot(x, profile[0, :, ny//2 , nz//2], 'rx', label = \"profile\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(r\"$\\rho$\")\n",
    "ax.legend(ncol = 1, fontsize = 'small')\n",
    "\n",
    "ax = axs[2]\n",
    "im = ax.imshow(profile[1, :, : , nz//2])\n",
    "ax.set_xlabel(\"y\")\n",
    "ax.set_ylabel(\"x\")\n",
    "plt.colorbar(im, ax = ax, label = r\"$\\phi$\")\n",
    "\n",
    "ax = axs[3]\n",
    "x = np.arange(0, nx, 1)\n",
    "im = ax.plot(x, profile[1, :, ny//2 , nz//2], 'rx', label = \"profile\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "ax.legend(ncol = 1, fontsize = 'small')\n",
    "\n",
    "t = int(path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "fig.suptitle(f\"$\\kappa$ = {kappa}, $\\chi = {chi}, T = {T}, t = {t}$\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import filters\n",
    "\n",
    "paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))\n",
    "\n",
    "profile = extract_data(paths[50], boxDim, begin = 0, end = 2, nVars = 38)\n",
    "field = profile[1].copy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (9, 3))\n",
    "colors = ['lime', 'magenta', 'blue', 'orange', 'red', 'k']\n",
    "cutoffs = [filters.threshold_otsu(field, nbins = 2**4), filters.threshold_minimum(field),\n",
    "           filters.threshold_li(field, initial_guess = 0), filters.threshold_mean(field),\n",
    "           filters.threshold_triangle(field), filters.threshold_yen(field, nbins = 2**4)]\n",
    "\n",
    "labels = ['otsu', 'min', 'li', 'mean', 'triangle', 'yen']\n",
    "\n",
    "y_slc = 15 # edit me to change which slice of data we are looking at\n",
    "slc_2D = np.s_[:, y_slc, :]\n",
    "slc_1D = np.s_[:, y_slc, nz//2]\n",
    "\n",
    "ax = axs[0]\n",
    "ax.hist(field.ravel(), bins=2**4, density = True)\n",
    "for i in range(len(colors)):\n",
    "    ax.axvline(cutoffs[i], color=colors[i], label = labels[i])\n",
    "\n",
    "ax.set_title(\"Comparing thresholding techniques\")\n",
    "ax.legend(ncol = 1)\n",
    "\n",
    "ax = axs[1]\n",
    "# field = np.where(field > cutoff, field, -0.03)\n",
    "im = ax.imshow(field[slc_2D])\n",
    "plt.colorbar(im, ax = ax)\n",
    "ax.plot(np.arange(0, nz, 1), np.ones(nz)*ny//2, 'r-', lw = 1, label = 'slice')\n",
    "ax.set_title(\"2D vis of data\\n after mask application\")\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "ax = axs[2]\n",
    "ax.plot(field[slc_1D], color = 'bisque', label = 'raw', markerfacecolor = \"None\", marker = 'o', linestyle = \"None\")\n",
    "\n",
    "for i in range(len(colors)):\n",
    "    ax.plot(np.arange(0, nz, 1), np.ones(nz)*cutoffs[i], color=colors[i], label = labels[i])\n",
    "ax.set_title(\"Comparing slice of data\\n and mask position\")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "# cm = center_of_mass(field)\n",
    "# gr = gyration_tensor(cm, field)\n",
    "# egr = np.linalg.eigvals(gr)\n",
    "\n",
    "# a = R_ref*np.power(egr[0], 1/3)/np.power(np.prod(egr[1:]), 1/6) - R_ref\n",
    "# b = R_ref*np.power(egr[1], 1/3)/np.power(np.prod(egr[[0, 2]]), 1/6) - R_ref\n",
    "# c = R_ref*np.power(egr[2], 1/3)/np.power(np.prod(egr[0:2]), 1/6) - R_ref\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = filters.try_all_threshold(profile[1][32], figsize=(10, 6), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho = phi = profile[0]\n",
    "# phi = profile[1]\n",
    "\n",
    "# print(f\"center phi:{phi[nx//2, ny//2, nz//2]}, edge:phi:{phi[0, 0, 0]}\")\n",
    "\n",
    "# L, L, L = phi.shape\n",
    "# dims = [L, L, L]\n",
    "# slc = np.s_[:L, :L, L//2]\n",
    "\n",
    "# ## Convolving FFT with kernel ##\n",
    "# kernel = np.ones(dims)\n",
    "# rhok = fft.fftn(rho)\n",
    "# phik = fft.fftn(phi)\n",
    "# mode = \"full\"\n",
    "# # mode = \"same\"\n",
    "# rho_convolve = scipy.signal.convolve(rhok, kernel, mode = mode)/np.prod(dims)\n",
    "# phi_convolve = scipy.signal.convolve(phik, kernel, mode = mode)/np.prod(dims)\n",
    "# ## Convolving FFT with kernel ##\n",
    "\n",
    "# ## Multiplying convolution with its adjoint ##\n",
    "# complex_adjoint = rho_convolve.conj()\n",
    "# rho_convolve = rho_convolve*complex_adjoint\n",
    "# complex_adjoint = phi_convolve.conj()\n",
    "# phi_convolve = phi_convolve*complex_adjoint\n",
    "# ## Multiplying convolution with its adjoint ##\n",
    "\n",
    "# sz = 4\n",
    "# ar = 1\n",
    "# row = 2\n",
    "# col = 4\n",
    "# fig = plt.figure(1, figsize=(sz*col*ar, sz*row))\n",
    "# # numbers are in row-col-figure with figure number being row major\n",
    "\n",
    "# fig.add_subplot(241)\n",
    "# plt.imshow(rho[slc])\n",
    "# plt.colorbar()\n",
    "# plt.title(r\"$\\rho(r)$\")\n",
    "\n",
    "# fig.add_subplot(245)\n",
    "# plt.imshow(phi[slc])\n",
    "# plt.colorbar()\n",
    "# plt.title(r\"$\\phi(r)$\")\n",
    "\n",
    "# fig.add_subplot(242)\n",
    "# plt.imshow(rhok.real[slc])\n",
    "# plt.colorbar()\n",
    "# plt.title(r\"$\\rho(k)$\")\n",
    "\n",
    "# fig.add_subplot(246)\n",
    "# plt.imshow(phik.real[slc])\n",
    "# plt.colorbar()\n",
    "# plt.title(r\"$\\phi(k)$\")\n",
    "\n",
    "# fig.add_subplot(243)\n",
    "# plt.imshow(rho_convolve[slc].real, vmin = 1, vmax = 1)\n",
    "# plt.colorbar()\n",
    "# plt.title(r\"$real(\\rho_k^{conv})$\")\n",
    "\n",
    "# fig.add_subplot(247)\n",
    "# plt.imshow(phi_convolve[slc].real, vmin = phi_convolve.real[slc].min(), vmax = phi_convolve.real[slc].max())\n",
    "# plt.colorbar()\n",
    "# plt.title(r\"$real(\\phi_k^{conv})$\")\n",
    "\n",
    "# fig.add_subplot(244)\n",
    "# plt.imshow(rho_convolve[slc].imag, vmin = 0, vmax = 0)\n",
    "# plt.colorbar()\n",
    "# plt.title(r\"$imag(\\rho_k^{conv}$)\")\n",
    "\n",
    "# fig.add_subplot(248)\n",
    "# plt.imshow(phi_convolve[slc].imag, vmin = 0, vmax = 0)\n",
    "# plt.colorbar()\n",
    "# plt.title(r\"$imag(\\phi_k^{conv}$)\")\n",
    "\n",
    "# fig.tight_layout()\n",
    "# print(rho_convolve.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))[:51]\n",
    " \n",
    "R_s = np.zeros(len(paths))\n",
    "times = np.zeros(len(paths))\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    t = int(path.split(\"_\")[-1].split(\".\")[0])    \n",
    "    times[i] = t\n",
    "    \n",
    "    profile = extract_data(path, boxDim, begin = 1, end = 2, nVars = 38)[0]\n",
    "    field = profile.copy()\n",
    "\n",
    "    R_s[i] = droplet_radius_mass(field)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (4, 3))\n",
    "\n",
    "ls = []\n",
    "ln, = ax.plot(times[1:], R_s[1:], 'g*', markerfacecolor = \"None\", ms = 8, label = 'R')\n",
    "ls.append(ln)\n",
    "\n",
    "print(R_s[-1])\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Timesteps\")\n",
    "ax.set_ylabel(r\"$R_{mass}$\")\n",
    "ax.set_title(f\"t = {t}\")\n",
    "\n",
    "ax.legend(handles = ls)\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/droplet_radius.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'gyration'\n",
    "# method = 'inertia'\n",
    "\n",
    "paths = sorted(glob.glob(f\"{savedir}/{output_file}*.h5\"))\n",
    "slc = slice(50, len(paths))\n",
    "paths = paths[slc]\n",
    "profile = extract_data(paths[0], boxDim, begin = 0, end = 2, nVars = 38)\n",
    "field = profile[1].copy()\n",
    "# cutoff = filters.threshold_otsu(field, nbins = 2**4)\n",
    "cutoff = 0\n",
    "\n",
    "if method == 'gyration':\n",
    "    # GYRATION TENSOR METHOD ##\n",
    "    R_ref = droplet_radius_iso(field)\n",
    "    print(R_ref, cutoff)\n",
    "    # GYRATION TENSOR METHOD ##\n",
    "elif method == 'inertia':\n",
    "    # INERTIA TENSOR METHOD ##\n",
    "    field = np.where(field >= cutoff, field, 0)\n",
    "    I_T = inertia_tensor(center_of_mass(field), field)\n",
    "    R_ref = radii_pca(np.linalg.eigvals(I_T), droplet_mass(field))\n",
    "    print(R_ref, cutoff)\n",
    "    # INERTIA TENSOR METHOD ##\n",
    "\n",
    "paths = paths[1:]\n",
    "times = np.zeros(len(paths))\n",
    "radiis = np.zeros((len(paths), 3))\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    t = int(path.split(\"_\")[-1].split(\".\")[0])    \n",
    "    times[i] = t\n",
    "\n",
    "    profile = extract_data(path, boxDim, begin = 1, end = 2, nVars = 38)[0]\n",
    "    field = profile.copy()\n",
    "    field = np.where(field >= cutoff, field, 0)\n",
    "    cm = center_of_mass(field)\n",
    "    \n",
    "    if method == 'gyration':\n",
    "        # GYRATION TENSOR METHOD ##\n",
    "        # R_ref = droplet_radius_iso(field)\n",
    "        gr = gyration_tensor(cm, field)\n",
    "        egr = np.linalg.eigvals(gr)\n",
    "        \n",
    "        da = R_ref*np.power(egr[0], 1/3)/np.power(np.prod(egr[[1,2]]), 1/6) - R_ref\n",
    "        db = R_ref*np.power(egr[1], 1/3)/np.power(np.prod(egr[[0,2]]), 1/6) - R_ref\n",
    "        dc = R_ref*np.power(egr[2], 1/3)/np.power(np.prod(egr[[0,1]]), 1/6) - R_ref\n",
    "\n",
    "        radiis[i] = [da,db,dc]\n",
    "        # GYRATION TENSOR METHOD ##\n",
    "    elif method == 'inertia':\n",
    "        # INERTIA TENSOR METHOD ##\n",
    "        I_T = inertia_tensor(cm, field)\n",
    "        eit = np.linalg.eigvals(I_T)\n",
    "        mass = droplet_mass(field)\n",
    "        R = radii_pca(eit, mass)\n",
    "        radiis[i] = R - R_ref\n",
    "        # INERTIA TENSOR METHOD ##\n",
    "\n",
    "print(np.mean(radiis, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droplet_fluctuations(fluctuations, temp = 1e-7):\n",
    "    sums = 0\n",
    "    difs = 0\n",
    "\n",
    "    for i in range(0, 2):\n",
    "        for j in range(i+1, 3):\n",
    "            sums += np.mean(np.power(fluctuations[:, i] + fluctuations[:, j], 2))\n",
    "            difs += np.mean(np.power(fluctuations[:, i] - fluctuations[:, j], 2))\n",
    "\n",
    "    sums *= 1/3\n",
    "    difs *= 1/3\n",
    "\n",
    "    print(sums, difs)\n",
    "\n",
    "    # y20 = 15*temp/(16*np.pi*sums)\n",
    "    # y22 = 45*temp/(16*np.pi*difs)\n",
    "\n",
    "    y20 = 5*temp/(16*np.pi*sums)\n",
    "    y22 = 15*temp/(16*np.pi*difs)\n",
    "\n",
    "    return [y20, y22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def droplet_fluctuations(fluctuations, temp = 1e-7):\n",
    "#     sz, dims = fluctuations.shape\n",
    "#     sums = np.zeros(sz)\n",
    "#     difs = np.zeros(sz)\n",
    "\n",
    "#     for i in range(sz):\n",
    "#         curr_sum = 0\n",
    "#         curr_dif = 0\n",
    "#         for j in range(0, dims - 1):\n",
    "#             for k in range(j + 1, dims):\n",
    "#                 curr_sum += np.power(fluctuations[i, j] + fluctuations[i, k], 2)\n",
    "#                 curr_dif += np.power(fluctuations[i, j] - fluctuations[i, k], 2)\n",
    "\n",
    "#         sums[i] = curr_sum/dims\n",
    "#         difs[i] = curr_dif/dims\n",
    "\n",
    "#     sums = sums.mean()\n",
    "#     difs = difs.mean()\n",
    "\n",
    "#     print(sums, difs)\n",
    "\n",
    "#     # y20 = 15*temp/(16*np.pi*sums)\n",
    "#     # y22 = 45*temp/(16*np.pi*difs)\n",
    "\n",
    "#     y20 = 5*temp/(16*np.pi*sums)\n",
    "#     y22 = 15*temp/(16*np.pi*difs)\n",
    "\n",
    "#     return [y20, y22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (4, 3))\n",
    "\n",
    "marker_cols = ['rx', 'bo', 'ks']\n",
    "labels = [r\"$\\delta R_{x}$\", r\"$\\delta R_{y}$\", r\"$\\delta R_{z}$\"]\n",
    "\n",
    "slc_pca = slice(50, radiis.shape[0])\n",
    "\n",
    "for i in range(3):\n",
    "    ax.plot(times[slc_pca], radiis[slc_pca, i], marker_cols[i], label = labels[i], markerfacecolor = 'none')\n",
    "\n",
    "ax.set_xlabel(\"Timesteps\")\n",
    "# ax.set_ylabel(r\"$R_{PCA} - R_{ref}$\")\n",
    "ax.set_ylabel(r\"$\\delta R_{\\alpha}$\")\n",
    "ax.set_title(f\"{method}\")\n",
    "ax.set_ylim(top = radiis[slc_pca].max() + 0.0015)\n",
    "ax.legend(ncol = 3)\n",
    "\n",
    "sigma_fluct = droplet_fluctuations(radiis[slc_pca], temp = kbt) # y20 y22\n",
    "print(r\"$\\sigma_{20}$=\"+f\"{sigma_fluct[0]:.4f}\" + r\" $\\sigma_{22}$=\"+f\"{sigma_fluct[1]:.4f}\" + r\" $\\sigma_{YL}$=0.017\")\n",
    "print(np.mean(sigma_fluct))\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(f\"./{figures}/droplet_shape_fluctuations-{noise_type}-avg.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid variable range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the covariance matrix, certain limits on parameter values are set based upon ensuring that the diagonal remains positive. This limit is set by the term. $5 - c_s^2(k)$ in Xi[5, 5] which corresponds to a maximum allowable $c_s^2(k) = 0.\\bar{5}$. The parameter that controls $c_s^2$ is $T$ as $c_s^2 = T$. $T_c$ or the critical temperature where demixing begins is defined as $T_c = \\lambda/2$. In the expression for calculating $c_s^2(k) = c_s^2 + \\kappa \\rho_0 k^2$, $\\kappa$ also controls the value of $c_s^2(k)$. Therefore this phase diagram will be defined using $\\lambda$ and $\\kappa$. Tested ranges will be $0.1 \\leq \\lambda \\leq 1.1$ and $0.01 \\leq \\kappa \\leq 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "# Newton-Raphson method function\n",
    "def newton_c_ver(initial_guess, chi = 1.1, T = 0.5, tolerance = 1e-4, max_iterations = 1000):\n",
    "    x = initial_guess  # value of phi\n",
    "    rho = 1.0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        fx = calculate_df_dphi(rho, x, chi, T)\n",
    "        dfx = calculate_dmup_dphi(rho, x, chi, T)\n",
    "\n",
    "        # Prevent division by zero\n",
    "        if dfx == 0.0:\n",
    "            # print(\"Divide by 0 encountered in Newton Raphson\")\n",
    "            # sys.exit(-1)\n",
    "            return None\n",
    "\n",
    "        x_next = x - fx / dfx\n",
    "\n",
    "        # Check if the difference between successive iterations is within tolerance\n",
    "        if abs(x_next - x) < tolerance:\n",
    "            return x_next\n",
    "\n",
    "        x = x_next\n",
    "\n",
    "    # print(\"Maximum iteration reached without convergence in Newton Raphson\")\n",
    "    return None\n",
    "\n",
    "@njit()\n",
    "def lattice_fourier_laplacian(kx, ky, kz):\n",
    "    expr1 = np.cos(kx) + np.cos(ky) + np.cos(kz)\n",
    "    expr2 = np.cos(kx)*np.cos(ky) + np.cos(ky)*np.cos(kz) + np.cos(kx)*np.cos(kz)\n",
    "    out = 2/9*expr1 + 2/9*expr2 - 4/3\n",
    "    return -out/(1/3)\n",
    "\n",
    "@njit()\n",
    "def calculate_dmup_drho(rho, phi, chi, T):\n",
    "    out = -T*phi/(rho**2 - phi**2) + chi/2*phi/(rho**2)\n",
    "    return out\n",
    "\n",
    "@njit()\n",
    "def calculate_dmup_dphi(rho, phi, chi, T):\n",
    "    out = T*rho/(rho**2 - phi**2) - chi/(2*rho)\n",
    "    return out\n",
    "\n",
    "@njit()\n",
    "def sound_speed_square(T):\n",
    "    out = T\n",
    "    return out\n",
    "\n",
    "@njit()\n",
    "def calculate_df_dphi(rho, phi, chi, T):\n",
    "    out = -chi/2.*(phi/rho) + T/2.*np.log((1. + phi/rho)/(1. - phi/rho))\n",
    "    return out\n",
    "\n",
    "@njit()\n",
    "def cholesky_decomp(arr_in, n, bstart):\n",
    "    A = arr_in.copy()\n",
    "    # sum = 0\n",
    "    for i in range(bstart, n):\n",
    "        for j in range(bstart, i + 1):\n",
    "            sum = A[i*n + j]\n",
    "            for k in range(j - 1, bstart - 1, -1):\n",
    "                sum -= A[i*n+k]*A[j*n+k]\n",
    "            if i == j:\n",
    "                if sum >= 0:\n",
    "                    A[i*n+j] = np.sqrt(sum)\n",
    "                else:\n",
    "                    A[i*n+j] = 0\n",
    "                    raise ValueError(f\"Row {i} in matrix not spd!\")\n",
    "            else:\n",
    "                if A[j*n+j] > 0:\n",
    "                    A[i*n+j] = sum/A[j*n+j]\n",
    "                else:\n",
    "                    raise ValueError(\"Matrix diagonal is 0\")\n",
    "\n",
    "    for i in range(0, n):\n",
    "        for j in range(i + 1, n):\n",
    "            A[i*n+j] = 0\n",
    "\n",
    "    return A\n",
    "\n",
    "@njit()\n",
    "def covariance_matrix(rho0, phi0, k2, chi = 1.1, T = 0.5, kappa = 0.01, temperature = 1e-7, tau_r = 1, tau_p = 1, Gamma = 1):\n",
    "    ndof = 38\n",
    "    Q = ndof//2\n",
    "    kT = temperature\n",
    "    \n",
    "    cs2 = sound_speed_square(T) + kappa*k2*rho0\n",
    "    mu_rho = calculate_dmup_drho(rho0, phi0, chi, T)\n",
    "    mu_phi = calculate_dmup_dphi(rho0, phi0, chi, T) + k2*kappa\n",
    "    p_phi = k2*kappa*phi0\n",
    "\n",
    "    lambdaLB_r = -1. / tau_r\n",
    "    lambdaLB_p = -1. / tau_p\n",
    "\n",
    "    lambda_r = -lambdaLB_r * (2 + lambdaLB_r) / 2\n",
    "    lambda_p = -lambdaLB_p * (2 + lambdaLB_p) / 2\n",
    "    lambda_rp = -lambdaLB_r * (2 + lambdaLB_p) / 2\n",
    "    lambda_pr = -lambdaLB_p * (2 + lambdaLB_r) / 2\n",
    "\n",
    "    Xi = np.zeros((ndof * ndof,), dtype=float)\n",
    "\n",
    "    Xi[5 * ndof + 5] = 2. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[6 * ndof + 6] = 2. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[7 * ndof + 7] = 2. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[8 * ndof + 8] = 2. * kT * rho0 * (5 - 9 * cs2) * lambda_r\n",
    "    Xi[9 * ndof + 9] = 8. * kT * rho0 * lambda_r\n",
    "    Xi[10 * ndof + 10] = (8.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[11 * ndof + 11] = (2.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[12 * ndof + 12] = (2.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[13 * ndof + 13] = (2.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[14 * ndof + 14] = 4. * kT * rho0 * lambda_r\n",
    "    Xi[15 * ndof + 15] = 4. * kT * rho0 * lambda_r\n",
    "    Xi[16 * ndof + 16] = 4. * kT * rho0 * lambda_r\n",
    "    Xi[17 * ndof + 17] = (4.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[18 * ndof + 18] = (4.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[(Q + 0) * ndof + (Q + 0)] = (4.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[(Q + 1) * ndof + (Q + 1)] = 18. * kT * rho0 * (1 - cs2) * lambda_r\n",
    "    Xi[(Q + 2) * ndof + (Q + 2)] = 8. * kT * rho0 * lambda_r\n",
    "    Xi[(Q + 3) * ndof + (Q + 3)] = (8.0 / 3.0) * kT * rho0 * lambda_r\n",
    "    Xi[(Q + 4) * ndof + (Q + 4)] = 2. * Gamma * kT / rho0 * (-9 * Gamma * mu_phi + 5) * lambda_p\n",
    "    Xi[(Q + 5) * ndof + (Q + 5)] = 8. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 6) * ndof + (Q + 6)] = (8.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 7) * ndof + (Q + 7)] = (2.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 8) * ndof + (Q + 8)] = (2.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 9) * ndof + (Q + 9)] = (2.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 10) * ndof + (Q + 10)] = 4. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 11) * ndof + (Q + 11)] = 4. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 12) * ndof + (Q + 12)] = 4. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 13) * ndof + (Q + 13)] = (4.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 14) * ndof + (Q + 14)] = (4.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 15) * ndof + (Q + 15)] = (4.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 16) * ndof + (Q + 16)] = 18. * Gamma * kT / rho0 * (-Gamma * mu_phi + 1) * lambda_p\n",
    "    Xi[(Q + 17) * ndof + (Q + 17)] = 8. * Gamma * kT / rho0 * lambda_p\n",
    "    Xi[(Q + 18) * ndof + (Q + 18)] = (8.0 / 3.0) * Gamma * kT / rho0 * lambda_p\n",
    "\n",
    "    Xi[8 * ndof + (Q + 1)] = 6. * kT * rho0 * (3 * cs2 - 1) * lambda_r\n",
    "    Xi[(Q + 1) * ndof + 8] = 6. * kT * rho0 * (3 * cs2 - 1) * lambda_r\n",
    "\n",
    "    Xi[(Q + 4) * ndof + (Q + 16)] = 6. * Gamma * kT / rho0 * (3 * Gamma * mu_phi - 1) * lambda_p\n",
    "    Xi[(Q + 16) * ndof + (Q + 4)] = 6. * Gamma * kT / rho0 * (3 * Gamma * mu_phi - 1) * lambda_p\n",
    "\n",
    "    Xi[8 * ndof + (Q + 4)] = -3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho)\n",
    "    Xi[(Q + 4) * ndof + 8] = -3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(8) * ndof + (Q + 16)] = 3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(Q + 16) * ndof + 8] = 3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "\n",
    "    Xi[(Q + 1) * ndof + (Q + 4)] = 3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(Q + 4) * ndof + (Q + 1)] = 3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(Q + 1) * ndof + (Q + 16)] = -3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "    Xi[(Q + 16) * ndof + (Q + 1)] = -3. * kT * (Gamma * mu_phi * (rho0 ** 2) * (3 * cs2 - 1) * mu_rho * lambda_pr + cs2 * (3 * Gamma * mu_phi - 1) * p_phi * lambda_rp) / (cs2 * mu_phi * rho0)\n",
    "\n",
    "    Xi[(0) * ndof + (Q + 4)] = -3. * Gamma * kT * rho0 * mu_rho / cs2 * lambda_pr\n",
    "    Xi[(Q + 4) * ndof + (0)] = -3. * Gamma * kT * rho0 * mu_rho / cs2 * lambda_pr\n",
    "    Xi[(0) * ndof + (Q + 16)] = 3. * Gamma * kT * rho0 * mu_rho / cs2 * lambda_pr\n",
    "    Xi[(Q + 16) * ndof + (0)] = 3. * Gamma * kT * rho0 * mu_rho / cs2 * lambda_pr\n",
    "\n",
    "    Xi[(1) * ndof + (Q + 1)] = 3. * kT * p_phi / (mu_phi * rho0) * lambda_rp\n",
    "    Xi[(Q + 1) * ndof + (1)] = 3. * kT * p_phi / (mu_phi * rho0) * lambda_rp\n",
    "    Xi[(1) * ndof + (8)] = -3. * kT * p_phi / (mu_phi * rho0) * lambda_rp\n",
    "    Xi[(8) * ndof + (1)] = -3. * kT * p_phi / (mu_phi * rho0) * lambda_rp\n",
    "    Xi[(2) * ndof + (5)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(3) * ndof + (6)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(4) * ndof + (7)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(5) * ndof + (2)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(6) * ndof + (3)] = -phi0 * kT * lambda_pr\n",
    "    Xi[(7) * ndof + (4)] = -phi0 * kT * lambda_pr\n",
    "\n",
    "    return Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def output_spd_homogenous(k2, CHI, KAPPA, T_IN):\n",
    "    SPD = np.zeros_like((CHI))\n",
    "\n",
    "    for x in range(SPD.shape[0]):\n",
    "        for y in range(SPD.shape[1]):\n",
    "            for z in range(SPD.shape[2]):\n",
    "                test_spd = True\n",
    "                for kval in np.nditer(k2.T):\n",
    "                    try:\n",
    "                        Xi = covariance_matrix(1, 0, kval, chi = CHI[x,y,z], T = T_IN[x,y,z], kappa = KAPPA[x, y, z])\n",
    "                        cholesky_decomp(Xi, 38, 5)\n",
    "                    except:\n",
    "                        test_spd = False\n",
    "                        break \n",
    "                SPD[x, y, z] = test_spd\n",
    "                \n",
    "    return SPD\n",
    "\n",
    "@njit\n",
    "def pre_process_inhomogenous_spatially_independent(chi, T, kappa):\n",
    "    # guess = np.sqrt(3*(chi/2 - T)/T)*1/(np.sqrt(2))\n",
    "    phi0_guess = np.arange(0.4, 0.8, 0.1)\n",
    "    for guess in phi0_guess:\n",
    "        phi0 = newton_c_ver(guess, chi = chi, T = T, tolerance = 1e-4, max_iterations = 1000)\n",
    "        if phi0 is not None:\n",
    "            break\n",
    "    print(phi0)\n",
    "    # print(\"phi0:\",phi0, \" T:\",T, \" chi:\",chi, \" kappa:\",kappa)\n",
    "\n",
    "    xi = np.sqrt((0.142*kappa)/((chi/2 - T)-0.31*T*(phi0**2)))\n",
    "    \n",
    "    fit_func = lambda x, b:phi0*np.tanh(0.76*(x - b)/xi)\n",
    "    xraw = np.linspace(-6, 6, 13)\n",
    "    phi_s = fit_func(xraw, -0.5)\n",
    "    return phi_s\n",
    "\n",
    "@njit\n",
    "def output_spd_inhomogenous_spatially_independent(CHI, T_IN, KAPPA):\n",
    "    SPD = np.zeros_like((CHI))\n",
    "    test_spd = True\n",
    "\n",
    "    for x in range(SPD.shape[0]):\n",
    "        for y in range(SPD.shape[1]):\n",
    "            for z in range(SPD.shape[2]):\n",
    "                chi = CHI[x,y,z]\n",
    "                T = T_IN[x,y,z]\n",
    "                kappa = KAPPA[x,y,z]\n",
    "                phi_s = pre_process_inhomogenous_spatially_independent(chi, T, kappa)\n",
    "                for phi in np.nditer(phi_s):\n",
    "                    try:\n",
    "                        Xi = covariance_matrix(1, phi, 0, chi = chi, T = T, kappa = kappa, tau_r = 0.7886751345948129)\n",
    "                        cholesky_decomp(Xi, 38, 5)\n",
    "                    except:\n",
    "                        test_spd = False\n",
    "            \n",
    "                SPD[x,y,z] = test_spd\n",
    "\n",
    "    return SPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = 0.6\n",
    "T = 0.3*chi\n",
    "kappa = 0.0144\n",
    "\n",
    "phi_s = pre_process_inhomogenous_spatially_independent(chi, T, kappa)\n",
    "test_spd = True\n",
    "for phi in np.nditer(phi_s):\n",
    "    try:\n",
    "        Xi = covariance_matrix(1, phi, 0, chi = chi, T = T, kappa = kappa, tau_r = 0.7886751345948129)\n",
    "        cholesky_decomp(Xi, 38, 5)\n",
    "    except:\n",
    "        test_spd = False\n",
    "\n",
    "test_spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_homogenous(points = 10, L = 16):\n",
    "    chimin = 0.2\n",
    "    chimax = 1.2\n",
    "\n",
    "    kappamin = 0.0\n",
    "    kappamax = 0.05\n",
    "\n",
    "    propmin = 0.5\n",
    "    propmax = 0.8\n",
    "\n",
    "    chi_s = np.linspace(chimin, chimax, points)\n",
    "    kappa_s = np.linspace(kappamin, kappamax, points)\n",
    "    prop_s = np.linspace(propmin, propmax, points)\n",
    "    # prop_s[points//2] = 0.5\n",
    "\n",
    "    CHI, KAPPA, PROP = np.meshgrid(*[chi_s, kappa_s, prop_s])\n",
    "    T_IN = CHI*PROP\n",
    "\n",
    "    freqs = fft.fftshift(fft.fftfreq(L))\n",
    "    kx, ky, kz = np.meshgrid(*tuple([2*np.pi*freqs for L in [L, L, L]]), indexing='ij')\n",
    "    k2 = lattice_fourier_laplacian(kx, ky, kz)\n",
    "    \n",
    "    SPD = output_spd_homogenous(k2, CHI, KAPPA, T_IN)\n",
    "    np.savez(\"spd_covariance_homogenous_matrix.npz\", chi = CHI, kappa = KAPPA, T = T_IN, SPD = SPD)\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"spd_covariance_homogenous_matrix.npz\"):\n",
    "    make_plot_homogenous(points = 50)\n",
    "\n",
    "# make_plot(points = 10)\n",
    "# make_plot_homogenous(points = 10)\n",
    "\n",
    "FILE_IN = np.load(\"spd_covariance_homogenous_matrix.npz\")\n",
    "CHI = FILE_IN['chi']\n",
    "KAPPA = FILE_IN['kappa']\n",
    "T_IN = FILE_IN['T']\n",
    "SPD = FILE_IN['SPD']\n",
    "PROPS = T_IN/CHI\n",
    "\n",
    "fig = plt.figure(figsize = (6, 6)) \n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_proj_type('ortho')\n",
    "colors = np.empty(SPD.shape, dtype=object)\n",
    "colors[SPD == 0] = \"w\"\n",
    "colors[SPD == 1] = \"lime\"\n",
    "\n",
    "out = ax.voxels(CHI, T_IN, KAPPA, SPD[:-1, :-1, :-1], facecolors=colors[:-1, :-1, :-1], edgecolor='k')\n",
    "ax.set_xlabel(r\"$\\chi$\")\n",
    "ax.set_ylabel(r\"$T_{in}$\")\n",
    "ax.set_zlabel(r\"$\\kappa$\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# ax.view_init(30, 60, 0) # ax.view_init(elev, azim, roll)\n",
    "ax.view_init(30, 60, 0) # ax.view_init(elev, azim, roll)\n",
    "\n",
    "ax.set_title(\"Homogenous system\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
    "\n",
    "slc_plot = np.s_[10, :, :]\n",
    "im = ax.contourf(CHI[slc_plot], PROPS[slc_plot], SPD[slc_plot], levels = 1, colors = ['tab:red', 'tab:green'])\n",
    "ax.set_xlabel(r\"$\\chi$\")\n",
    "ax.set_ylabel(r\"$T/\\chi$\")\n",
    "curr_prop = np.unique(KAPPA[slc_plot])[0]\n",
    "ax.set_title(f\"$\\kappa = {curr_prop:.3f}$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/valid_homogenous_parameters.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_inhomogenous(points = 10, L = 16):\n",
    "    chimin = 0.3\n",
    "    chimax = 1.0\n",
    "\n",
    "    kappamin = 0.01\n",
    "    kappamax = 0.05\n",
    "\n",
    "    propmin = 0.35\n",
    "    propmax = 0.49\n",
    "\n",
    "    chi_s = np.linspace(chimin, chimax, points)\n",
    "    kappa_s = np.linspace(kappamin, kappamax, points)\n",
    "    prop_s = np.linspace(propmin, propmax, points)\n",
    "\n",
    "    CHI, KAPPA, PROP = np.meshgrid(*[chi_s, kappa_s, prop_s])\n",
    "    T_IN = CHI*PROP\n",
    "\n",
    "    SPD = output_spd_inhomogenous_spatially_independent(CHI, T_IN, KAPPA)\n",
    "    np.savez(\"spd_covariance_inhomogenous_matrix.npz\", chi = CHI, kappa = KAPPA, T = T_IN, SPD = SPD)\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# if not os.path.exists(\"spd_covariance_inhomogenous_matrix.npz\"):\n",
    "    # make_plot_inhomogenous(points = 10)\n",
    "\n",
    "make_plot_inhomogenous(points = 50)\n",
    "FILE_IN = np.load(\"spd_covariance_inhomogenous_matrix.npz\")\n",
    "CHI = FILE_IN['chi']\n",
    "KAPPA = FILE_IN['kappa']\n",
    "T_IN = FILE_IN['T']\n",
    "SPD = FILE_IN['SPD']\n",
    "PROPS = T_IN/CHI\n",
    "\n",
    "fig = plt.figure(figsize = (6, 6)) \n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_proj_type('ortho')\n",
    "colors = np.empty(SPD.shape, dtype=object)\n",
    "colors[SPD == 0] = \"w\"\n",
    "colors[SPD == 1] = \"lime\"\n",
    "\n",
    "out = ax.voxels(CHI, T_IN, KAPPA, SPD[:-1, :-1, :-1], facecolors=colors[:-1, :-1, :-1], edgecolor='k')\n",
    "ax.set_xlabel(r\"$\\chi$\")\n",
    "ax.set_ylabel(r\"$T_{in}$\")\n",
    "ax.set_zlabel(r\"$\\kappa$\")\n",
    "\n",
    "# ax.view_init(30, 60, 0) # ax.view_init(elev, azim, roll)\n",
    "ax.view_init(30, 60, 0)\n",
    "\n",
    "ax.set_title(\"Inhomogenous system\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (3, 3))\n",
    "\n",
    "slc_plot = np.s_[25, :, :]\n",
    "im = ax.contourf(CHI[slc_plot], PROPS[slc_plot], SPD[slc_plot], levels = 1, colors = ['tab:green'])\n",
    "ax.set_xlabel(r\"$\\chi$\")\n",
    "ax.set_ylabel(r\"$T/\\chi$\")\n",
    "curr_prop = np.unique(KAPPA[slc_plot])[0]\n",
    "ax.set_title(f\"$\\kappa = {curr_prop:.3f}$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./{figures}/valid_inhomogenous_parameters.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
